{"traceEvents": [{"ph": "M", "pid": 11572, "tid": 11572, "name": "process_name", "args": {"name": "MainProcess"}}, {"ph": "M", "pid": 11572, "tid": 17656, "name": "thread_name", "args": {"name": "MainThread"}}, {"pid": 11572, "tid": 17656, "ts": 65160479928.3, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160479928.599, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.hasattr"}, {"pid": 11572, "tid": 17656, "ts": 65160479928.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 11572, "tid": 17656, "ts": 65160479933.699, "ph": "X", "cat": "fee", "dur": 0.02, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160479933.9, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160479934.199, "ph": "X", "cat": "fee", "dur": 0.4, "name": "str.startswith"}, {"pid": 11572, "tid": 17656, "ts": 65160479934.699, "ph": "X", "cat": "fee", "dur": 0.2, "name": "str.replace"}, {"pid": 11572, "tid": 17656, "ts": 65160479935.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160479935.4, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160479935.6, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160479935.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.replace"}, {"pid": 11572, "tid": 17656, "ts": 65160479935.199, "ph": "X", "cat": "fee", "dur": 1.4, "name": "splitdrive (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:124)"}, {"pid": 11572, "tid": 17656, "ts": 65160479936.8, "ph": "X", "cat": "fee", "dur": 0.099, "name": "str.startswith"}, {"pid": 11572, "tid": 17656, "ts": 65160479937.3, "ph": "X", "cat": "fee", "dur": 0.199, "name": "str.lstrip"}, {"pid": 11572, "tid": 17656, "ts": 65160479937.7, "ph": "X", "cat": "fee", "dur": 0.5, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65160479938.3, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160479938.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160479939.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160479939.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160479939.499, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160479939.7, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160479939.799, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160479940.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160479940.299, "ph": "X", "cat": "fee", "dur": 0.3, "name": "str.join"}, {"pid": 11572, "tid": 17656, "ts": 65160479933.5, "ph": "X", "cat": "fee", "dur": 7.199, "name": "normpath (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:450)"}, {"pid": 11572, "tid": 17656, "ts": 65160479941.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160479941.4, "ph": "X", "cat": "fee", "dur": 0.7, "name": "nt.getcwd"}, {"pid": 11572, "tid": 17656, "ts": 65160479942.5, "ph": "X", "cat": "fee", "dur": 0.02, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160479942.6, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160479942.799, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.replace"}, {"pid": 11572, "tid": 17656, "ts": 65160479943.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "str.lower"}, {"pid": 11572, "tid": 17656, "ts": 65160479942.4, "ph": "X", "cat": "fee", "dur": 0.8, "name": "normcase (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:44)"}, {"pid": 11572, "tid": 17656, "ts": 65160479943.5, "ph": "X", "cat": "fee", "dur": 0.02, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160479943.599, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160479943.7, "ph": "X", "cat": "fee", "dur": 0.1, "name": "str.replace"}, {"pid": 11572, "tid": 17656, "ts": 65160479943.9, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 11572, "tid": 17656, "ts": 65160479943.4, "ph": "X", "cat": "fee", "dur": 0.599, "name": "normcase (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:44)"}, {"pid": 11572, "tid": 17656, "ts": 65160479944.2, "ph": "X", "cat": "fee", "dur": 0.1, "name": "str.startswith"}, {"pid": 11572, "tid": 17656, "ts": 65160479944.7, "ph": "X", "cat": "fee", "dur": 0.02, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160479944.8, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160479944.92, "ph": "X", "cat": "fee", "dur": 0.079, "name": "str.replace"}, {"pid": 11572, "tid": 17656, "ts": 65160479945.099, "ph": "X", "cat": "fee", "dur": 0.1, "name": "str.startswith"}, {"pid": 11572, "tid": 17656, "ts": 65160479945.5, "ph": "X", "cat": "fee", "dur": 0.02, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160479945.599, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160479945.8, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160479946.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.replace"}, {"pid": 11572, "tid": 17656, "ts": 65160479945.4, "ph": "X", "cat": "fee", "dur": 2.699, "name": "splitdrive (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:124)"}, {"pid": 11572, "tid": 17656, "ts": 65160479948.3, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160479948.8, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160479948.7, "ph": "X", "cat": "fee", "dur": 0.219, "name": "_get_bothseps (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:34)"}, {"pid": 11572, "tid": 17656, "ts": 65160479944.599, "ph": "X", "cat": "fee", "dur": 4.5, "name": "isabs (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:61)"}, {"pid": 11572, "tid": 17656, "ts": 65160479949.3, "ph": "X", "cat": "fee", "dur": 55.4, "name": "nt._getfinalpathname"}, {"pid": 11572, "tid": 17656, "ts": 65160480005.399, "ph": "X", "cat": "fee", "dur": 0.5, "name": "str.startswith"}, {"pid": 11572, "tid": 17656, "ts": 65160480006.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "str.startswith"}, {"pid": 11572, "tid": 17656, "ts": 65160480006.3, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160480006.9, "ph": "X", "cat": "fee", "dur": 45.0, "name": "nt._getfinalpathname"}, {"pid": 11572, "tid": 17656, "ts": 65160479933.199, "ph": "X", "cat": "fee", "dur": 119.3, "name": "realpath (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:625)"}, {"pid": 11572, "tid": 17656, "ts": 65160480053.9, "ph": "X", "cat": "fee", "dur": 0.099, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160480054.4, "ph": "X", "cat": "fee", "dur": 0.199, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160480054.3, "ph": "X", "cat": "fee", "dur": 0.4, "name": "_get_bothseps (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:34)"}, {"pid": 11572, "tid": 17656, "ts": 65160480055.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160480055.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160480055.4, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160480055.599, "ph": "X", "cat": "fee", "dur": 0.2, "name": "str.replace"}, {"pid": 11572, "tid": 17656, "ts": 65160480054.9, "ph": "X", "cat": "fee", "dur": 1.8, "name": "splitdrive (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:124)"}, {"pid": 11572, "tid": 17656, "ts": 65160480056.8, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160480058.8, "ph": "X", "cat": "fee", "dur": 0.2, "name": "str.rstrip"}, {"pid": 11572, "tid": 17656, "ts": 65160480053.7, "ph": "X", "cat": "fee", "dur": 5.6, "name": "split (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:180)"}, {"pid": 11572, "tid": 17656, "ts": 65160480053.3, "ph": "X", "cat": "fee", "dur": 6.3, "name": "dirname (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:221)"}, {"pid": 11572, "tid": 17656, "ts": 65160480060.4, "ph": "X", "cat": "fee", "dur": 0.1, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160480060.6, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160480060.8, "ph": "X", "cat": "fee", "dur": 0.1, "name": "str.replace"}, {"pid": 11572, "tid": 17656, "ts": 65160480061.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "str.lower"}, {"pid": 11572, "tid": 17656, "ts": 65160480060.3, "ph": "X", "cat": "fee", "dur": 1.0, "name": "normcase (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:44)"}, {"pid": 11572, "tid": 17656, "ts": 65160480061.699, "ph": "X", "cat": "fee", "dur": 0.1, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160480061.82, "ph": "X", "cat": "fee", "dur": 0.08, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160480062.4, "ph": "X", "cat": "fee", "dur": 0.02, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160480062.5, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160480062.6, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160480062.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.replace"}, {"pid": 11572, "tid": 17656, "ts": 65160480062.3, "ph": "X", "cat": "fee", "dur": 1.0, "name": "splitdrive (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:124)"}, {"pid": 11572, "tid": 17656, "ts": 65160480064.22, "ph": "X", "cat": "fee", "dur": 0.08, "name": "nt.fspath"}, {"pid": 11572, "tid": 17656, "ts": 65160480064.32, "ph": "X", "cat": "fee", "dur": 0.079, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65160480064.499, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65160480064.7, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.replace"}, {"pid": 11572, "tid": 17656, "ts": 65160480064.2, "ph": "X", "cat": "fee", "dur": 1.0, "name": "splitdrive (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:124)"}, {"pid": 11572, "tid": 17656, "ts": 65160480061.6, "ph": "X", "cat": "fee", "dur": 4.6, "name": "join (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:77)"}, {"pid": 11572, "tid": 17656, "ts": 65160480066.499, "ph": "X", "cat": "fee", "dur": 47.0, "name": "nt.listdir"}, {"pid": 11572, "tid": 17656, "ts": 65160480114.3, "ph": "X", "cat": "fee", "dur": 0.4, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65160480115.6, "ph": "X", "cat": "fee", "dur": 0.099, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65160480116.1, "ph": "X", "cat": "fee", "dur": 50.4, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65160480209.8, "ph": "X", "cat": "fee", "dur": 2.699, "name": "_locale._getdefaultlocale"}, {"pid": 11572, "tid": 17656, "ts": 65160480208.699, "ph": "X", "cat": "fee", "dur": 4.1, "name": "getpreferredencoding (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_bootlocale.py:11)"}, {"pid": 11572, "tid": 17656, "ts": 65160480218.0, "ph": "X", "cat": "fee", "dur": 0.599, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\codecs.py:260)"}, {"pid": 11572, "tid": 17656, "ts": 65160480168.5, "ph": "X", "cat": "fee", "dur": 52.599, "name": "io.open"}, {"pid": 11572, "tid": 17656, "ts": 65160503159.3, "ph": "X", "cat": "fee", "dur": 106459.5, "name": "_codecs.charmap_decode"}, {"pid": 11572, "tid": 17656, "ts": 65160503157.4, "ph": "X", "cat": "fee", "dur": 106463.5, "name": "decode (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\encodings\\cp1252.py:22)"}, {"pid": 11572, "tid": 17656, "ts": 65160480222.7, "ph": "X", "cat": "fee", "dur": 222839.699, "name": "_io.TextIOWrapper.read"}, {"pid": 11572, "tid": 17656, "ts": 65160703064.6, "ph": "X", "cat": "fee", "dur": 29.999, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 11572, "tid": 17656, "ts": 65160480168.1, "ph": "X", "cat": "fee", "dur": 222927.0, "name": "readInData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:44)"}, {"pid": 11572, "tid": 17656, "ts": 65160703104.2, "ph": "X", "cat": "fee", "dur": 770232.1, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65161473338.399, "ph": "X", "cat": "fee", "dur": 235158.5, "name": "str.join"}, {"pid": 11572, "tid": 17656, "ts": 65161876159.4, "ph": "X", "cat": "fee", "dur": 2.4, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876168.8, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876171.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876170.3, "ph": "X", "cat": "fee", "dur": 1.0, "name": "isstring (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:595)"}, {"pid": 11572, "tid": 17656, "ts": 65161876173.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876172.899, "ph": "X", "cat": "fee", "dur": 0.5, "name": "isstring (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:595)"}, {"pid": 11572, "tid": 17656, "ts": 65161876175.8, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876177.5, "ph": "X", "cat": "fee", "dur": 1.199, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876175.6, "ph": "X", "cat": "fee", "dur": 3.2, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:224)"}, {"pid": 11572, "tid": 17656, "ts": 65161876180.1, "ph": "X", "cat": "fee", "dur": 1.1, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:76)"}, {"pid": 11572, "tid": 17656, "ts": 65161876184.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876183.7, "ph": "X", "cat": "fee", "dur": 0.7, "name": "tell (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:286)"}, {"pid": 11572, "tid": 17656, "ts": 65161876186.099, "ph": "X", "cat": "fee", "dur": 1.2, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:111)"}, {"pid": 11572, "tid": 17656, "ts": 65161876189.399, "ph": "X", "cat": "fee", "dur": 0.3, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876188.9, "ph": "X", "cat": "fee", "dur": 0.899, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65161876190.6, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876190.5, "ph": "X", "cat": "fee", "dur": 0.22, "name": "tell (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:286)"}, {"pid": 11572, "tid": 17656, "ts": 65161876191.6, "ph": "X", "cat": "fee", "dur": 0.299, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876191.3, "ph": "X", "cat": "fee", "dur": 0.619, "name": "match (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65161876192.399, "ph": "X", "cat": "fee", "dur": 0.3, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876192.2, "ph": "X", "cat": "fee", "dur": 0.52, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65161876193.3, "ph": "X", "cat": "fee", "dur": 0.6, "name": "builtins.ord"}, {"pid": 11572, "tid": 17656, "ts": 65161876194.4, "ph": "X", "cat": "fee", "dur": 0.2, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876194.199, "ph": "X", "cat": "fee", "dur": 0.5, "name": "match (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65161876195.1, "ph": "X", "cat": "fee", "dur": 0.5, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876194.9, "ph": "X", "cat": "fee", "dur": 0.799, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65161876196.0, "ph": "X", "cat": "fee", "dur": 0.199, "name": "builtins.ord"}, {"pid": 11572, "tid": 17656, "ts": 65161876196.999, "ph": "X", "cat": "fee", "dur": 0.3, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876197.7, "ph": "X", "cat": "fee", "dur": 0.299, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876197.6, "ph": "X", "cat": "fee", "dur": 0.419, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65161876198.3, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.ord"}, {"pid": 11572, "tid": 17656, "ts": 65161876198.9, "ph": "X", "cat": "fee", "dur": 0.3, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876198.7, "ph": "X", "cat": "fee", "dur": 0.52, "name": "match (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65161876199.7, "ph": "X", "cat": "fee", "dur": 0.7, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876199.499, "ph": "X", "cat": "fee", "dur": 1.0, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65161876200.7, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.ord"}, {"pid": 11572, "tid": 17656, "ts": 65161876201.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876201.6, "ph": "X", "cat": "fee", "dur": 0.199, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876201.5, "ph": "X", "cat": "fee", "dur": 1.9, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65161876204.599, "ph": "X", "cat": "fee", "dur": 0.3, "name": "dict.get"}, {"pid": 11572, "tid": 17656, "ts": 65161876205.099, "ph": "X", "cat": "fee", "dur": 0.3, "name": "dict.get"}, {"pid": 11572, "tid": 17656, "ts": 65161876204.099, "ph": "X", "cat": "fee", "dur": 1.6, "name": "_class_escape (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:295)"}, {"pid": 11572, "tid": 17656, "ts": 65161876206.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "match (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65161876206.5, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876207.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876206.8, "ph": "X", "cat": "fee", "dur": 0.5, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65161876208.7, "ph": "X", "cat": "fee", "dur": 1.799, "name": "type.fromkeys"}, {"pid": 11572, "tid": 17656, "ts": 65161876207.8, "ph": "X", "cat": "fee", "dur": 3.899, "name": "_uniq (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:432)"}, {"pid": 11572, "tid": 17656, "ts": 65161876211.8, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876212.3, "ph": "X", "cat": "fee", "dur": 0.399, "name": "list.insert"}, {"pid": 11572, "tid": 17656, "ts": 65161876213.4, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876213.199, "ph": "X", "cat": "fee", "dur": 0.32, "name": "append (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:172)"}, {"pid": 11572, "tid": 17656, "ts": 65161876214.1, "ph": "X", "cat": "fee", "dur": 1.399, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65161876213.9, "ph": "X", "cat": "fee", "dur": 1.619, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65161876216.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876216.2, "ph": "X", "cat": "fee", "dur": 0.4, "name": "tell (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:286)"}, {"pid": 11572, "tid": 17656, "ts": 65161876217.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876217.6, "ph": "X", "cat": "fee", "dur": 0.3, "name": "__len__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:160)"}, {"pid": 11572, "tid": 17656, "ts": 65161876219.299, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876220.299, "ph": "X", "cat": "fee", "dur": 0.2, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:111)"}, {"pid": 11572, "tid": 17656, "ts": 65161876218.6, "ph": "X", "cat": "fee", "dur": 2.0, "name": "__getitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:164)"}, {"pid": 11572, "tid": 17656, "ts": 65161876221.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876221.0, "ph": "X", "cat": "fee", "dur": 0.22, "name": "__len__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:160)"}, {"pid": 11572, "tid": 17656, "ts": 65161876221.52, "ph": "X", "cat": "fee", "dur": 0.18, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876221.5, "ph": "X", "cat": "fee", "dur": 0.299, "name": "__getitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:164)"}, {"pid": 11572, "tid": 17656, "ts": 65161876222.32, "ph": "X", "cat": "fee", "dur": 0.08, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876222.3, "ph": "X", "cat": "fee", "dur": 0.12, "name": "__getitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:164)"}, {"pid": 11572, "tid": 17656, "ts": 65161876223.099, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876223.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "__getitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:164)"}, {"pid": 11572, "tid": 17656, "ts": 65161876223.599, "ph": "X", "cat": "fee", "dur": 0.2, "name": "match (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65161876224.5, "ph": "X", "cat": "fee", "dur": 0.3, "name": "__setitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:168)"}, {"pid": 11572, "tid": 17656, "ts": 65161876225.5, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876225.4, "ph": "X", "cat": "fee", "dur": 0.219, "name": "__len__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:160)"}, {"pid": 11572, "tid": 17656, "ts": 65161876225.2, "ph": "X", "cat": "fee", "dur": 0.5, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876228.5, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876228.399, "ph": "X", "cat": "fee", "dur": 0.3, "name": "__getitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:164)"}, {"pid": 11572, "tid": 17656, "ts": 65161876185.1, "ph": "X", "cat": "fee", "dur": 43.799, "name": "_parse (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:493)"}, {"pid": 11572, "tid": 17656, "ts": 65161876229.6, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876229.9, "ph": "X", "cat": "fee", "dur": 0.1, "name": "match (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65161876230.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876182.5, "ph": "X", "cat": "fee", "dur": 47.8, "name": "_parse_sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:435)"}, {"pid": 11572, "tid": 17656, "ts": 65161876231.199, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876231.0, "ph": "X", "cat": "fee", "dur": 1.199, "name": "fix_flags (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:921)"}, {"pid": 11572, "tid": 17656, "ts": 65161876174.399, "ph": "X", "cat": "fee", "dur": 58.2, "name": "parse (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:937)"}, {"pid": 11572, "tid": 17656, "ts": 65161876238.0, "ph": "X", "cat": "fee", "dur": 0.799, "name": "builtins.min"}, {"pid": 11572, "tid": 17656, "ts": 65161876238.9, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.min"}, {"pid": 11572, "tid": 17656, "ts": 65161876236.9, "ph": "X", "cat": "fee", "dur": 2.3, "name": "getwidth (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:174)"}, {"pid": 11572, "tid": 17656, "ts": 65161876240.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.min"}, {"pid": 11572, "tid": 17656, "ts": 65161876240.299, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.min"}, {"pid": 11572, "tid": 17656, "ts": 65161876235.8, "ph": "X", "cat": "fee", "dur": 4.699, "name": "getwidth (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:174)"}, {"pid": 11572, "tid": 17656, "ts": 65161876242.599, "ph": "X", "cat": "fee", "dur": 0.3, "name": "_get_iscased (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:453)"}, {"pid": 11572, "tid": 17656, "ts": 65161876241.7, "ph": "X", "cat": "fee", "dur": 1.6, "name": "_get_literal_prefix (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:461)"}, {"pid": 11572, "tid": 17656, "ts": 65161876244.5, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_iscased (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:453)"}, {"pid": 11572, "tid": 17656, "ts": 65161876244.0, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_get_charset_prefix (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:492)"}, {"pid": 11572, "tid": 17656, "ts": 65161876245.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876245.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876245.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876245.5, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876245.7, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876245.899, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.min"}, {"pid": 11572, "tid": 17656, "ts": 65161876246.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876246.3, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876235.2, "ph": "X", "cat": "fee", "dur": 11.3, "name": "_compile_info (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:536)"}, {"pid": 11572, "tid": 17656, "ts": 65161876249.3, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876249.199, "ph": "X", "cat": "fee", "dur": 0.22, "name": "__len__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:160)"}, {"pid": 11572, "tid": 17656, "ts": 65161876248.9, "ph": "X", "cat": "fee", "dur": 0.6, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876249.82, "ph": "X", "cat": "fee", "dur": 0.08, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876249.8, "ph": "X", "cat": "fee", "dur": 0.2, "name": "__getitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:164)"}, {"pid": 11572, "tid": 17656, "ts": 65161876248.8, "ph": "X", "cat": "fee", "dur": 1.6, "name": "_simple (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:423)"}, {"pid": 11572, "tid": 17656, "ts": 65161876250.6, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876250.699, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876250.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876250.9, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876251.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876252.62, "ph": "X", "cat": "fee", "dur": 0.08, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876252.6, "ph": "X", "cat": "fee", "dur": 0.2, "name": "__getitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:164)"}, {"pid": 11572, "tid": 17656, "ts": 65161876255.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876258.9, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876259.599, "ph": "X", "cat": "fee", "dur": 1.1, "name": "bytearray.find"}, {"pid": 11572, "tid": 17656, "ts": 65161876260.9, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876261.099, "ph": "X", "cat": "fee", "dur": 0.2, "name": "bytearray.find"}, {"pid": 11572, "tid": 17656, "ts": 65161876261.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876261.599, "ph": "X", "cat": "fee", "dur": 0.1, "name": "bytearray.find"}, {"pid": 11572, "tid": 17656, "ts": 65161876261.8, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876262.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "bytearray.find"}, {"pid": 11572, "tid": 17656, "ts": 65161876262.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876262.4, "ph": "X", "cat": "fee", "dur": 0.199, "name": "bytearray.find"}, {"pid": 11572, "tid": 17656, "ts": 65161876263.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876263.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876263.7, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876263.8, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876253.4, "ph": "X", "cat": "fee", "dur": 11.4, "name": "_optimize_charset (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:276)"}, {"pid": 11572, "tid": 17656, "ts": 65161876265.6, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876265.7, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876265.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876266.5, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876266.699, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876267.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876267.199, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876267.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876267.5, "ph": "X", "cat": "fee", "dur": 0.299, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876267.82, "ph": "X", "cat": "fee", "dur": 0.08, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876268.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876268.8, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876269.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876266.3, "ph": "X", "cat": "fee", "dur": 2.82, "name": "_compile_charset (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65161876269.3, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876269.8, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876269.699, "ph": "X", "cat": "fee", "dur": 0.4, "name": "__getitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:164)"}, {"pid": 11572, "tid": 17656, "ts": 65161876251.6, "ph": "X", "cat": "fee", "dur": 18.899, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:71)"}, {"pid": 11572, "tid": 17656, "ts": 65161876270.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876270.9, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876247.1, "ph": "X", "cat": "fee", "dur": 24.0, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:71)"}, {"pid": 11572, "tid": 17656, "ts": 65161876271.3, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65161876234.2, "ph": "X", "cat": "fee", "dur": 37.22, "name": "_code (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:598)"}, {"pid": 11572, "tid": 17656, "ts": 65161876272.6, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876272.4, "ph": "X", "cat": "fee", "dur": 0.3, "name": "groups (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:81)"}, {"pid": 11572, "tid": 17656, "ts": 65161876273.2, "ph": "X", "cat": "fee", "dur": 0.2, "name": "dict.items"}, {"pid": 11572, "tid": 17656, "ts": 65161876274.6, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876274.5, "ph": "X", "cat": "fee", "dur": 0.2, "name": "groups (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:81)"}, {"pid": 11572, "tid": 17656, "ts": 65161876275.299, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_sre.compile"}, {"pid": 11572, "tid": 17656, "ts": 65161876172.6, "ph": "X", "cat": "fee", "dur": 103.9, "name": "compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:759)"}, {"pid": 11572, "tid": 17656, "ts": 65161876278.8, "ph": "X", "cat": "fee", "dur": 0.4, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65161876282.3, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__new__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:670)"}, {"pid": 11572, "tid": 17656, "ts": 65161876280.599, "ph": "X", "cat": "fee", "dur": 2.7, "name": "__call__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:358)"}, {"pid": 11572, "tid": 17656, "ts": 65161876284.3, "ph": "X", "cat": "fee", "dur": 0.2, "name": "__new__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:670)"}, {"pid": 11572, "tid": 17656, "ts": 65161876284.0, "ph": "X", "cat": "fee", "dur": 0.6, "name": "__call__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:358)"}, {"pid": 11572, "tid": 17656, "ts": 65161876278.5, "ph": "X", "cat": "fee", "dur": 6.199, "name": "__and__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:977)"}, {"pid": 11572, "tid": 17656, "ts": 65161876285.0, "ph": "X", "cat": "fee", "dur": 0.199, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65161876158.6, "ph": "X", "cat": "fee", "dur": 127.2, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65161876286.3, "ph": "X", "cat": "fee", "dur": 1909088.3, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65161876157.699, "ph": "X", "cat": "fee", "dur": 1909218.7, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65163785378.6, "ph": "X", "cat": "fee", "dur": 641757.699, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65160703103.3, "ph": "X", "cat": "fee", "dur": 3727894.8, "name": "cleanAndTokenize (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:61)"}, {"pid": 11572, "tid": 17656, "ts": 65164432996.199, "ph": "X", "cat": "fee", "dur": 0.5, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433001.4, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433004.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433004.0, "ph": "X", "cat": "fee", "dur": 3.6, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433003.799, "ph": "X", "cat": "fee", "dur": 4.0, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164433008.899, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433008.3, "ph": "X", "cat": "fee", "dur": 1.3, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433008.2, "ph": "X", "cat": "fee", "dur": 1.5, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164433010.8, "ph": "X", "cat": "fee", "dur": 0.099, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433009.919, "ph": "X", "cat": "fee", "dur": 1.38, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433009.899, "ph": "X", "cat": "fee", "dur": 1.42, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164433012.5, "ph": "X", "cat": "fee", "dur": 0.099, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433011.62, "ph": "X", "cat": "fee", "dur": 1.78, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433011.6, "ph": "X", "cat": "fee", "dur": 1.82, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164433014.4, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433013.719, "ph": "X", "cat": "fee", "dur": 1.28, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433013.699, "ph": "X", "cat": "fee", "dur": 1.32, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164433016.2, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433017.9, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433019.5, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433018.6, "ph": "X", "cat": "fee", "dur": 1.5, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433018.499, "ph": "X", "cat": "fee", "dur": 1.62, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164433017.2, "ph": "X", "cat": "fee", "dur": 3.099, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433017.1, "ph": "X", "cat": "fee", "dur": 3.3, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164433015.32, "ph": "X", "cat": "fee", "dur": 5.379, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433015.3, "ph": "X", "cat": "fee", "dur": 5.419, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164433021.7, "ph": "X", "cat": "fee", "dur": 0.099, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433021.0, "ph": "X", "cat": "fee", "dur": 1.2, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433020.9, "ph": "X", "cat": "fee", "dur": 1.4, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164433023.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433022.599, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433022.5, "ph": "X", "cat": "fee", "dur": 1.099, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164433000.299, "ph": "X", "cat": "fee", "dur": 23.6, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433000.2, "ph": "X", "cat": "fee", "dur": 23.72, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164433025.3, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)"}, {"pid": 11572, "tid": 17656, "ts": 65164433024.22, "ph": "X", "cat": "fee", "dur": 1.679, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164433024.2, "ph": "X", "cat": "fee", "dur": 1.719, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164432994.1, "ph": "X", "cat": "fee", "dur": 32.1, "name": "_abc._abc_subclasscheck"}, {"pid": 11572, "tid": 17656, "ts": 65164432993.9, "ph": "X", "cat": "fee", "dur": 32.32, "name": "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)"}, {"pid": 11572, "tid": 17656, "ts": 65164432990.0, "ph": "X", "cat": "fee", "dur": 36.399, "name": "_abc._abc_instancecheck"}, {"pid": 11572, "tid": 17656, "ts": 65164432989.8, "ph": "X", "cat": "fee", "dur": 36.619, "name": "__instancecheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:117)"}, {"pid": 11572, "tid": 17656, "ts": 65164432987.9, "ph": "X", "cat": "fee", "dur": 38.699, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65164433026.899, "ph": "X", "cat": "fee", "dur": 1291644.1, "name": "_collections._count_elements"}, {"pid": 11572, "tid": 17656, "ts": 65164432986.4, "ph": "X", "cat": "fee", "dur": 1291686.399, "name": "update (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:649)"}, {"pid": 11572, "tid": 17656, "ts": 65164432981.3, "ph": "X", "cat": "fee", "dur": 1291693.799, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:581)"}, {"pid": 11572, "tid": 17656, "ts": 65160480167.8, "ph": "X", "cat": "fee", "dur": 5244508.4, "name": "getWordCount (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:78)"}, {"pid": 11572, "tid": 17656, "ts": 65165845290.699, "ph": "X", "cat": "fee", "dur": 0.9, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65165845303.5, "ph": "X", "cat": "fee", "dur": 214.2, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65165845522.099, "ph": "X", "cat": "fee", "dur": 0.3, "name": "Counter.values"}, {"pid": 11572, "tid": 17656, "ts": 65165845522.5, "ph": "X", "cat": "fee", "dur": 1966.8, "name": "builtins.sum"}, {"pid": 11572, "tid": 17656, "ts": 65165847492.5, "ph": "X", "cat": "fee", "dur": 0.1, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65165845520.1, "ph": "X", "cat": "fee", "dur": 47321.199, "name": "getWordFrequencies (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:96)"}, {"pid": 11572, "tid": 17656, "ts": 65160480115.4, "ph": "X", "cat": "fee", "dur": 5412727.6, "name": "getWordData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:122)"}, {"pid": 11572, "tid": 17656, "ts": 65165892847.8, "ph": "X", "cat": "fee", "dur": 0.4, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65165892849.5, "ph": "X", "cat": "fee", "dur": 120.2, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65165893066.099, "ph": "X", "cat": "fee", "dur": 3.8, "name": "_locale._getdefaultlocale"}, {"pid": 11572, "tid": 17656, "ts": 65165893064.7, "ph": "X", "cat": "fee", "dur": 5.8, "name": "getpreferredencoding (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_bootlocale.py:11)"}, {"pid": 11572, "tid": 17656, "ts": 65165893075.499, "ph": "X", "cat": "fee", "dur": 0.4, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\codecs.py:260)"}, {"pid": 11572, "tid": 17656, "ts": 65165892972.9, "ph": "X", "cat": "fee", "dur": 105.7, "name": "io.open"}, {"pid": 11572, "tid": 17656, "ts": 65165949574.8, "ph": "X", "cat": "fee", "dur": 256386.1, "name": "_codecs.charmap_decode"}, {"pid": 11572, "tid": 17656, "ts": 65165949572.899, "ph": "X", "cat": "fee", "dur": 256390.2, "name": "decode (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\encodings\\cp1252.py:22)"}, {"pid": 11572, "tid": 17656, "ts": 65165893080.9, "ph": "X", "cat": "fee", "dur": 539998.6, "name": "_io.TextIOWrapper.read"}, {"pid": 11572, "tid": 17656, "ts": 65166433081.6, "ph": "X", "cat": "fee", "dur": 31.0, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 11572, "tid": 17656, "ts": 65165892971.6, "ph": "X", "cat": "fee", "dur": 540141.599, "name": "readInData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:44)"}, {"pid": 11572, "tid": 17656, "ts": 65166433120.6, "ph": "X", "cat": "fee", "dur": 1738505.8, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65168171628.4, "ph": "X", "cat": "fee", "dur": 606344.299, "name": "str.join"}, {"pid": 11572, "tid": 17656, "ts": 65169141393.0, "ph": "X", "cat": "fee", "dur": 2.2, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65169141392.4, "ph": "X", "cat": "fee", "dur": 5.3, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65169141398.399, "ph": "X", "cat": "fee", "dur": 4530426.0, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65169141391.1, "ph": "X", "cat": "fee", "dur": 4530435.199, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65173671828.5, "ph": "X", "cat": "fee", "dur": 1423791.4, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65166433119.7, "ph": "X", "cat": "fee", "dur": 8671780.799, "name": "cleanAndTokenize (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:61)"}, {"pid": 11572, "tid": 17656, "ts": 65175109713.4, "ph": "X", "cat": "fee", "dur": 2.3, "name": "_abc._abc_instancecheck"}, {"pid": 11572, "tid": 17656, "ts": 65175109713.1, "ph": "X", "cat": "fee", "dur": 2.8, "name": "__instancecheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:117)"}, {"pid": 11572, "tid": 17656, "ts": 65175109711.6, "ph": "X", "cat": "fee", "dur": 4.7, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65175109716.6, "ph": "X", "cat": "fee", "dur": 3325686.4, "name": "_collections._count_elements"}, {"pid": 11572, "tid": 17656, "ts": 65175109710.6, "ph": "X", "cat": "fee", "dur": 3325694.2, "name": "update (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:649)"}, {"pid": 11572, "tid": 17656, "ts": 65175109705.2, "ph": "X", "cat": "fee", "dur": 3325701.7, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:581)"}, {"pid": 11572, "tid": 17656, "ts": 65165892971.1, "ph": "X", "cat": "fee", "dur": 12542437.099, "name": "getWordCount (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:78)"}, {"pid": 11572, "tid": 17656, "ts": 65178735928.4, "ph": "X", "cat": "fee", "dur": 0.8, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65178735935.5, "ph": "X", "cat": "fee", "dur": 279.1, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65178736218.099, "ph": "X", "cat": "fee", "dur": 0.3, "name": "Counter.values"}, {"pid": 11572, "tid": 17656, "ts": 65178736218.5, "ph": "X", "cat": "fee", "dur": 3803.7, "name": "builtins.sum"}, {"pid": 11572, "tid": 17656, "ts": 65178740023.2, "ph": "X", "cat": "fee", "dur": 0.1, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65178736216.799, "ph": "X", "cat": "fee", "dur": 94731.6, "name": "getWordFrequencies (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:96)"}, {"pid": 11572, "tid": 17656, "ts": 65165892846.599, "ph": "X", "cat": "fee", "dur": 12938103.6, "name": "getWordData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:122)"}, {"pid": 11572, "tid": 17656, "ts": 65178830954.4, "ph": "X", "cat": "fee", "dur": 0.399, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65178830956.0, "ph": "X", "cat": "fee", "dur": 123.2, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65178831169.9, "ph": "X", "cat": "fee", "dur": 3.899, "name": "_locale._getdefaultlocale"}, {"pid": 11572, "tid": 17656, "ts": 65178831168.6, "ph": "X", "cat": "fee", "dur": 5.9, "name": "getpreferredencoding (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_bootlocale.py:11)"}, {"pid": 11572, "tid": 17656, "ts": 65178831179.0, "ph": "X", "cat": "fee", "dur": 0.8, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\codecs.py:260)"}, {"pid": 11572, "tid": 17656, "ts": 65178831082.299, "ph": "X", "cat": "fee", "dur": 100.2, "name": "io.open"}, {"pid": 11572, "tid": 17656, "ts": 65178894949.999, "ph": "X", "cat": "fee", "dur": 294394.9, "name": "_codecs.charmap_decode"}, {"pid": 11572, "tid": 17656, "ts": 65178894948.4, "ph": "X", "cat": "fee", "dur": 294398.799, "name": "decode (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\encodings\\cp1252.py:22)"}, {"pid": 11572, "tid": 17656, "ts": 65178831184.5, "ph": "X", "cat": "fee", "dur": 619880.599, "name": "_io.TextIOWrapper.read"}, {"pid": 11572, "tid": 17656, "ts": 65179451067.3, "ph": "X", "cat": "fee", "dur": 26.8, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 11572, "tid": 17656, "ts": 65178831081.1, "ph": "X", "cat": "fee", "dur": 620015.599, "name": "readInData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:44)"}, {"pid": 11572, "tid": 17656, "ts": 65179451104.899, "ph": "X", "cat": "fee", "dur": 1866222.8, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65181317337.299, "ph": "X", "cat": "fee", "dur": 695867.9, "name": "str.join"}, {"pid": 11572, "tid": 17656, "ts": 65182386988.5, "ph": "X", "cat": "fee", "dur": 2.399, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65182386987.699, "ph": "X", "cat": "fee", "dur": 5.4, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65182386993.799, "ph": "X", "cat": "fee", "dur": 5230309.1, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65182386986.8, "ph": "X", "cat": "fee", "dur": 5230317.7, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65187617306.3, "ph": "X", "cat": "fee", "dur": 1505172.5, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65179451103.899, "ph": "X", "cat": "fee", "dur": 9681991.9, "name": "cleanAndTokenize (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:61)"}, {"pid": 11572, "tid": 17656, "ts": 65189138613.099, "ph": "X", "cat": "fee", "dur": 2.2, "name": "_abc._abc_instancecheck"}, {"pid": 11572, "tid": 17656, "ts": 65189138612.799, "ph": "X", "cat": "fee", "dur": 2.7, "name": "__instancecheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:117)"}, {"pid": 11572, "tid": 17656, "ts": 65189138611.2, "ph": "X", "cat": "fee", "dur": 4.6, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65189138616.0, "ph": "X", "cat": "fee", "dur": 3828151.0, "name": "_collections._count_elements"}, {"pid": 11572, "tid": 17656, "ts": 65189138610.0, "ph": "X", "cat": "fee", "dur": 3828158.7, "name": "update (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:649)"}, {"pid": 11572, "tid": 17656, "ts": 65189138605.1, "ph": "X", "cat": "fee", "dur": 3828165.6, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:581)"}, {"pid": 11572, "tid": 17656, "ts": 65178831080.5, "ph": "X", "cat": "fee", "dur": 14135691.3, "name": "getWordCount (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:78)"}, {"pid": 11572, "tid": 17656, "ts": 65193315891.0, "ph": "X", "cat": "fee", "dur": 3.099, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65193315914.599, "ph": "X", "cat": "fee", "dur": 246.4, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65193316165.0, "ph": "X", "cat": "fee", "dur": 0.299, "name": "Counter.values"}, {"pid": 11572, "tid": 17656, "ts": 65193316165.4, "ph": "X", "cat": "fee", "dur": 4469.4, "name": "builtins.sum"}, {"pid": 11572, "tid": 17656, "ts": 65193320635.899, "ph": "X", "cat": "fee", "dur": 0.1, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65193316163.1, "ph": "X", "cat": "fee", "dur": 113336.0, "name": "getWordFrequencies (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:96)"}, {"pid": 11572, "tid": 17656, "ts": 65178830952.9, "ph": "X", "cat": "fee", "dur": 14598548.399, "name": "getWordData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:122)"}, {"pid": 11572, "tid": 17656, "ts": 65193429505.0, "ph": "X", "cat": "fee", "dur": 0.4, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65193429506.7, "ph": "X", "cat": "fee", "dur": 117.199, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65193429714.7, "ph": "X", "cat": "fee", "dur": 4.2, "name": "_locale._getdefaultlocale"}, {"pid": 11572, "tid": 17656, "ts": 65193429713.4, "ph": "X", "cat": "fee", "dur": 6.1, "name": "getpreferredencoding (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_bootlocale.py:11)"}, {"pid": 11572, "tid": 17656, "ts": 65193429724.2, "ph": "X", "cat": "fee", "dur": 0.5, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\codecs.py:260)"}, {"pid": 11572, "tid": 17656, "ts": 65193429626.799, "ph": "X", "cat": "fee", "dur": 100.5, "name": "io.open"}, {"pid": 11572, "tid": 17656, "ts": 65193487681.1, "ph": "X", "cat": "fee", "dur": 270180.7, "name": "_codecs.charmap_decode"}, {"pid": 11572, "tid": 17656, "ts": 65193487679.0, "ph": "X", "cat": "fee", "dur": 270185.499, "name": "decode (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\encodings\\cp1252.py:22)"}, {"pid": 11572, "tid": 17656, "ts": 65193429729.199, "ph": "X", "cat": "fee", "dur": 577245.9, "name": "_io.TextIOWrapper.read"}, {"pid": 11572, "tid": 17656, "ts": 65194006977.1, "ph": "X", "cat": "fee", "dur": 28.9, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 11572, "tid": 17656, "ts": 65193429625.8, "ph": "X", "cat": "fee", "dur": 577380.599, "name": "readInData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:44)"}, {"pid": 11572, "tid": 17656, "ts": 65194007013.8, "ph": "X", "cat": "fee", "dur": 1703382.199, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65195710398.8, "ph": "X", "cat": "fee", "dur": 633282.4, "name": "str.join"}, {"pid": 11572, "tid": 17656, "ts": 65196665067.2, "ph": "X", "cat": "fee", "dur": 2.6, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65196665066.6, "ph": "X", "cat": "fee", "dur": 5.999, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65196665073.399, "ph": "X", "cat": "fee", "dur": 4805074.2, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65196665065.7, "ph": "X", "cat": "fee", "dur": 4805084.5, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65201470152.099, "ph": "X", "cat": "fee", "dur": 1385197.9, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65194007013.1, "ph": "X", "cat": "fee", "dur": 8858114.6, "name": "cleanAndTokenize (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:61)"}, {"pid": 11572, "tid": 17656, "ts": 65202870173.9, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_abc._abc_instancecheck"}, {"pid": 11572, "tid": 17656, "ts": 65202870173.6, "ph": "X", "cat": "fee", "dur": 2.4, "name": "__instancecheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:117)"}, {"pid": 11572, "tid": 17656, "ts": 65202870172.1, "ph": "X", "cat": "fee", "dur": 4.3, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65202870176.6, "ph": "X", "cat": "fee", "dur": 3572441.799, "name": "_collections._count_elements"}, {"pid": 11572, "tid": 17656, "ts": 65202870170.9, "ph": "X", "cat": "fee", "dur": 3572449.3, "name": "update (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:649)"}, {"pid": 11572, "tid": 17656, "ts": 65202870165.8, "ph": "X", "cat": "fee", "dur": 3572458.799, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:581)"}, {"pid": 11572, "tid": 17656, "ts": 65193429625.2, "ph": "X", "cat": "fee", "dur": 13013000.6, "name": "getWordCount (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:78)"}, {"pid": 11572, "tid": 17656, "ts": 65206772030.8, "ph": "X", "cat": "fee", "dur": 0.899, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65206772039.5, "ph": "X", "cat": "fee", "dur": 300.9, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65206772343.499, "ph": "X", "cat": "fee", "dur": 0.3, "name": "Counter.values"}, {"pid": 11572, "tid": 17656, "ts": 65206772343.9, "ph": "X", "cat": "fee", "dur": 4357.3, "name": "builtins.sum"}, {"pid": 11572, "tid": 17656, "ts": 65206776702.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65206772342.199, "ph": "X", "cat": "fee", "dur": 111901.2, "name": "getWordFrequencies (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:96)"}, {"pid": 11572, "tid": 17656, "ts": 65193429504.099, "ph": "X", "cat": "fee", "dur": 13454740.8, "name": "getWordData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:122)"}, {"pid": 11572, "tid": 17656, "ts": 65206884248.9, "ph": "X", "cat": "fee", "dur": 0.4, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65206884250.4, "ph": "X", "cat": "fee", "dur": 120.3, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65206884464.7, "ph": "X", "cat": "fee", "dur": 3.699, "name": "_locale._getdefaultlocale"}, {"pid": 11572, "tid": 17656, "ts": 65206884463.0, "ph": "X", "cat": "fee", "dur": 6.0, "name": "getpreferredencoding (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_bootlocale.py:11)"}, {"pid": 11572, "tid": 17656, "ts": 65206884474.499, "ph": "X", "cat": "fee", "dur": 0.4, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\codecs.py:260)"}, {"pid": 11572, "tid": 17656, "ts": 65206884373.7, "ph": "X", "cat": "fee", "dur": 103.599, "name": "io.open"}, {"pid": 11572, "tid": 17656, "ts": 65206940240.6, "ph": "X", "cat": "fee", "dur": 249507.5, "name": "_codecs.charmap_decode"}, {"pid": 11572, "tid": 17656, "ts": 65206940238.6, "ph": "X", "cat": "fee", "dur": 249511.599, "name": "decode (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\encodings\\cp1252.py:22)"}, {"pid": 11572, "tid": 17656, "ts": 65206884479.8, "ph": "X", "cat": "fee", "dur": 528791.5, "name": "_io.TextIOWrapper.read"}, {"pid": 11572, "tid": 17656, "ts": 65207413273.699, "ph": "X", "cat": "fee", "dur": 26.7, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 11572, "tid": 17656, "ts": 65206884372.6, "ph": "X", "cat": "fee", "dur": 528928.4, "name": "readInData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:44)"}, {"pid": 11572, "tid": 17656, "ts": 65207413308.699, "ph": "X", "cat": "fee", "dur": 1556015.5, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65208969326.9, "ph": "X", "cat": "fee", "dur": 598522.2, "name": "str.join"}, {"pid": 11572, "tid": 17656, "ts": 65209869953.8, "ph": "X", "cat": "fee", "dur": 2.4, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65209869953.099, "ph": "X", "cat": "fee", "dur": 5.4, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65209869959.5, "ph": "X", "cat": "fee", "dur": 4450199.3, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65209869952.2, "ph": "X", "cat": "fee", "dur": 4450208.5, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65214320163.0, "ph": "X", "cat": "fee", "dur": 1267782.5, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65207413307.899, "ph": "X", "cat": "fee", "dur": 8183691.8, "name": "cleanAndTokenize (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:61)"}, {"pid": 11572, "tid": 17656, "ts": 65215601656.499, "ph": "X", "cat": "fee", "dur": 2.2, "name": "_abc._abc_instancecheck"}, {"pid": 11572, "tid": 17656, "ts": 65215601656.2, "ph": "X", "cat": "fee", "dur": 2.599, "name": "__instancecheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:117)"}, {"pid": 11572, "tid": 17656, "ts": 65215601654.8, "ph": "X", "cat": "fee", "dur": 4.499, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65215601659.5, "ph": "X", "cat": "fee", "dur": 3327938.1, "name": "_collections._count_elements"}, {"pid": 11572, "tid": 17656, "ts": 65215601653.5, "ph": "X", "cat": "fee", "dur": 3327946.399, "name": "update (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:649)"}, {"pid": 11572, "tid": 17656, "ts": 65215601648.399, "ph": "X", "cat": "fee", "dur": 3327953.9, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:581)"}, {"pid": 11572, "tid": 17656, "ts": 65206884372.0, "ph": "X", "cat": "fee", "dur": 12045231.1, "name": "getWordCount (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:78)"}, {"pid": 11572, "tid": 17656, "ts": 65219231207.4, "ph": "X", "cat": "fee", "dur": 1.0, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65219231216.0, "ph": "X", "cat": "fee", "dur": 211.6, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65219231431.0, "ph": "X", "cat": "fee", "dur": 0.299, "name": "Counter.values"}, {"pid": 11572, "tid": 17656, "ts": 65219231431.4, "ph": "X", "cat": "fee", "dur": 4284.899, "name": "builtins.sum"}, {"pid": 11572, "tid": 17656, "ts": 65219235716.899, "ph": "X", "cat": "fee", "dur": 0.1, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65219231429.5, "ph": "X", "cat": "fee", "dur": 115411.1, "name": "getWordFrequencies (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:96)"}, {"pid": 11572, "tid": 17656, "ts": 65206884247.9, "ph": "X", "cat": "fee", "dur": 12462594.5, "name": "getWordData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:122)"}, {"pid": 11572, "tid": 17656, "ts": 65219346846.3, "ph": "X", "cat": "fee", "dur": 0.5, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65219346848.5, "ph": "X", "cat": "fee", "dur": 82.2, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65219347019.1, "ph": "X", "cat": "fee", "dur": 3.599, "name": "_locale._getdefaultlocale"}, {"pid": 11572, "tid": 17656, "ts": 65219347017.3, "ph": "X", "cat": "fee", "dur": 6.0, "name": "getpreferredencoding (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_bootlocale.py:11)"}, {"pid": 11572, "tid": 17656, "ts": 65219347029.7, "ph": "X", "cat": "fee", "dur": 0.5, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\codecs.py:260)"}, {"pid": 11572, "tid": 17656, "ts": 65219346933.8, "ph": "X", "cat": "fee", "dur": 98.999, "name": "io.open"}, {"pid": 11572, "tid": 17656, "ts": 65219399029.5, "ph": "X", "cat": "fee", "dur": 243300.4, "name": "_codecs.charmap_decode"}, {"pid": 11572, "tid": 17656, "ts": 65219399027.6, "ph": "X", "cat": "fee", "dur": 243304.7, "name": "decode (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\encodings\\cp1252.py:22)"}, {"pid": 11572, "tid": 17656, "ts": 65219347035.0, "ph": "X", "cat": "fee", "dur": 509051.799, "name": "_io.TextIOWrapper.read"}, {"pid": 11572, "tid": 17656, "ts": 65219856089.0, "ph": "X", "cat": "fee", "dur": 29.1, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 11572, "tid": 17656, "ts": 65219346932.6, "ph": "X", "cat": "fee", "dur": 509186.2, "name": "readInData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:44)"}, {"pid": 11572, "tid": 17656, "ts": 65219856126.7, "ph": "X", "cat": "fee", "dur": 1538124.0, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65221394252.899, "ph": "X", "cat": "fee", "dur": 571936.8, "name": "str.join"}, {"pid": 11572, "tid": 17656, "ts": 65222263086.3, "ph": "X", "cat": "fee", "dur": 2.199, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65222263085.6, "ph": "X", "cat": "fee", "dur": 5.3, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65222263091.799, "ph": "X", "cat": "fee", "dur": 4366465.6, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65222263084.699, "ph": "X", "cat": "fee", "dur": 4366475.2, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65226629564.0, "ph": "X", "cat": "fee", "dur": 1237073.6, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65219856125.9, "ph": "X", "cat": "fee", "dur": 8019304.8, "name": "cleanAndTokenize (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:61)"}, {"pid": 11572, "tid": 17656, "ts": 65227880004.7, "ph": "X", "cat": "fee", "dur": 2.7, "name": "_abc._abc_instancecheck"}, {"pid": 11572, "tid": 17656, "ts": 65227880004.0, "ph": "X", "cat": "fee", "dur": 3.599, "name": "__instancecheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:117)"}, {"pid": 11572, "tid": 17656, "ts": 65227880001.1, "ph": "X", "cat": "fee", "dur": 6.9, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65227880008.4, "ph": "X", "cat": "fee", "dur": 3250491.199, "name": "_collections._count_elements"}, {"pid": 11572, "tid": 17656, "ts": 65227879998.8, "ph": "X", "cat": "fee", "dur": 3250502.599, "name": "update (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:649)"}, {"pid": 11572, "tid": 17656, "ts": 65227879992.0, "ph": "X", "cat": "fee", "dur": 3250511.699, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:581)"}, {"pid": 11572, "tid": 17656, "ts": 65219346931.699, "ph": "X", "cat": "fee", "dur": 11783573.2, "name": "getWordCount (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:78)"}, {"pid": 11572, "tid": 17656, "ts": 65231427837.799, "ph": "X", "cat": "fee", "dur": 1.5, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65231427846.199, "ph": "X", "cat": "fee", "dur": 261.2, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65231428111.0, "ph": "X", "cat": "fee", "dur": 0.7, "name": "Counter.values"}, {"pid": 11572, "tid": 17656, "ts": 65231428111.799, "ph": "X", "cat": "fee", "dur": 4398.5, "name": "builtins.sum"}, {"pid": 11572, "tid": 17656, "ts": 65231432511.199, "ph": "X", "cat": "fee", "dur": 0.1, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65231428109.299, "ph": "X", "cat": "fee", "dur": 111215.0, "name": "getWordFrequencies (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:96)"}, {"pid": 11572, "tid": 17656, "ts": 65219346845.4, "ph": "X", "cat": "fee", "dur": 12192480.9, "name": "getWordData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:122)"}, {"pid": 11572, "tid": 17656, "ts": 65231539330.8, "ph": "X", "cat": "fee", "dur": 0.5, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65231539332.5, "ph": "X", "cat": "fee", "dur": 81.9, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65231539502.7, "ph": "X", "cat": "fee", "dur": 4.8, "name": "_locale._getdefaultlocale"}, {"pid": 11572, "tid": 17656, "ts": 65231539500.699, "ph": "X", "cat": "fee", "dur": 7.4, "name": "getpreferredencoding (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_bootlocale.py:11)"}, {"pid": 11572, "tid": 17656, "ts": 65231539517.4, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\codecs.py:260)"}, {"pid": 11572, "tid": 17656, "ts": 65231539417.0, "ph": "X", "cat": "fee", "dur": 104.2, "name": "io.open"}, {"pid": 11572, "tid": 17656, "ts": 65231595284.5, "ph": "X", "cat": "fee", "dur": 259254.899, "name": "_codecs.charmap_decode"}, {"pid": 11572, "tid": 17656, "ts": 65231595282.599, "ph": "X", "cat": "fee", "dur": 259259.1, "name": "decode (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\encodings\\cp1252.py:22)"}, {"pid": 11572, "tid": 17656, "ts": 65231539522.9, "ph": "X", "cat": "fee", "dur": 542760.2, "name": "_io.TextIOWrapper.read"}, {"pid": 11572, "tid": 17656, "ts": 65232082285.5, "ph": "X", "cat": "fee", "dur": 28.9, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 11572, "tid": 17656, "ts": 65231539415.7, "ph": "X", "cat": "fee", "dur": 542899.4, "name": "readInData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:44)"}, {"pid": 11572, "tid": 17656, "ts": 65232082323.2, "ph": "X", "cat": "fee", "dur": 1602113.7, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65233684438.9, "ph": "X", "cat": "fee", "dur": 602660.7, "name": "str.join"}, {"pid": 11572, "tid": 17656, "ts": 65234614025.6, "ph": "X", "cat": "fee", "dur": 2.899, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65234614024.5, "ph": "X", "cat": "fee", "dur": 6.799, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65234614032.0, "ph": "X", "cat": "fee", "dur": 4678256.099, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65234614023.5, "ph": "X", "cat": "fee", "dur": 4678266.7, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65239292292.2, "ph": "X", "cat": "fee", "dur": 1313894.9, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65232082321.9, "ph": "X", "cat": "fee", "dur": 8533256.199, "name": "cleanAndTokenize (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:61)"}, {"pid": 11572, "tid": 17656, "ts": 65240620430.6, "ph": "X", "cat": "fee", "dur": 2.599, "name": "_abc._abc_instancecheck"}, {"pid": 11572, "tid": 17656, "ts": 65240620430.2, "ph": "X", "cat": "fee", "dur": 3.399, "name": "__instancecheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:117)"}, {"pid": 11572, "tid": 17656, "ts": 65240620428.7, "ph": "X", "cat": "fee", "dur": 5.3, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65240620434.3, "ph": "X", "cat": "fee", "dur": 3504948.3, "name": "_collections._count_elements"}, {"pid": 11572, "tid": 17656, "ts": 65240620427.499, "ph": "X", "cat": "fee", "dur": 3504957.0, "name": "update (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:649)"}, {"pid": 11572, "tid": 17656, "ts": 65240620421.8, "ph": "X", "cat": "fee", "dur": 3504965.0, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:581)"}, {"pid": 11572, "tid": 17656, "ts": 65231539415.4, "ph": "X", "cat": "fee", "dur": 12585972.4, "name": "getWordCount (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:78)"}, {"pid": 11572, "tid": 17656, "ts": 65244443220.6, "ph": "X", "cat": "fee", "dur": 0.8, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65244443227.9, "ph": "X", "cat": "fee", "dur": 403.8, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65244443635.2, "ph": "X", "cat": "fee", "dur": 0.3, "name": "Counter.values"}, {"pid": 11572, "tid": 17656, "ts": 65244443635.6, "ph": "X", "cat": "fee", "dur": 4825.0, "name": "builtins.sum"}, {"pid": 11572, "tid": 17656, "ts": 65244448461.6, "ph": "X", "cat": "fee", "dur": 0.1, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65244443633.899, "ph": "X", "cat": "fee", "dur": 124261.6, "name": "getWordFrequencies (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:96)"}, {"pid": 11572, "tid": 17656, "ts": 65231539329.899, "ph": "X", "cat": "fee", "dur": 13028567.2, "name": "getWordData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:122)"}, {"pid": 11572, "tid": 17656, "ts": 65244567901.3, "ph": "X", "cat": "fee", "dur": 0.4, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65244567902.7, "ph": "X", "cat": "fee", "dur": 80.699, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65244568068.7, "ph": "X", "cat": "fee", "dur": 3.8, "name": "_locale._getdefaultlocale"}, {"pid": 11572, "tid": 17656, "ts": 65244568067.5, "ph": "X", "cat": "fee", "dur": 5.6, "name": "getpreferredencoding (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_bootlocale.py:11)"}, {"pid": 11572, "tid": 17656, "ts": 65244568077.9, "ph": "X", "cat": "fee", "dur": 0.5, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\codecs.py:260)"}, {"pid": 11572, "tid": 17656, "ts": 65244567985.9, "ph": "X", "cat": "fee", "dur": 94.699, "name": "io.open"}, {"pid": 11572, "tid": 17656, "ts": 65244623308.8, "ph": "X", "cat": "fee", "dur": 257522.2, "name": "_codecs.charmap_decode"}, {"pid": 11572, "tid": 17656, "ts": 65244623307.1, "ph": "X", "cat": "fee", "dur": 257526.2, "name": "decode (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\encodings\\cp1252.py:22)"}, {"pid": 11572, "tid": 17656, "ts": 65244568082.7, "ph": "X", "cat": "fee", "dur": 538911.099, "name": "_io.TextIOWrapper.read"}, {"pid": 11572, "tid": 17656, "ts": 65245106995.7, "ph": "X", "cat": "fee", "dur": 28.3, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 11572, "tid": 17656, "ts": 65244567984.9, "ph": "X", "cat": "fee", "dur": 539039.7, "name": "readInData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:44)"}, {"pid": 11572, "tid": 17656, "ts": 65245107032.5, "ph": "X", "cat": "fee", "dur": 1596239.5, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65246703274.4, "ph": "X", "cat": "fee", "dur": 624164.6, "name": "str.join"}, {"pid": 11572, "tid": 17656, "ts": 65247648289.9, "ph": "X", "cat": "fee", "dur": 2.3, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65247648289.299, "ph": "X", "cat": "fee", "dur": 5.2, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65247648295.2, "ph": "X", "cat": "fee", "dur": 4680080.2, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65247648288.4, "ph": "X", "cat": "fee", "dur": 4680088.999, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65252328379.399, "ph": "X", "cat": "fee", "dur": 1293577.8, "name": "str.split"}, {"pid": 11572, "tid": 17656, "ts": 65245107031.7, "ph": "X", "cat": "fee", "dur": 8524225.999, "name": "cleanAndTokenize (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:61)"}, {"pid": 11572, "tid": 17656, "ts": 65253636107.6, "ph": "X", "cat": "fee", "dur": 2.3, "name": "_abc._abc_instancecheck"}, {"pid": 11572, "tid": 17656, "ts": 65253636107.1, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__instancecheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:117)"}, {"pid": 11572, "tid": 17656, "ts": 65253636105.7, "ph": "X", "cat": "fee", "dur": 4.9, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65253636110.9, "ph": "X", "cat": "fee", "dur": 3716437.5, "name": "_collections._count_elements"}, {"pid": 11572, "tid": 17656, "ts": 65253636104.6, "ph": "X", "cat": "fee", "dur": 3716445.899, "name": "update (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:649)"}, {"pid": 11572, "tid": 17656, "ts": 65253636099.2, "ph": "X", "cat": "fee", "dur": 3716453.299, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:581)"}, {"pid": 11572, "tid": 17656, "ts": 65244567984.4, "ph": "X", "cat": "fee", "dur": 12784569.1, "name": "getWordCount (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:78)"}, {"pid": 11572, "tid": 17656, "ts": 65257680897.7, "ph": "X", "cat": "fee", "dur": 1.4, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65257680906.1, "ph": "X", "cat": "fee", "dur": 266.799, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65257681176.1, "ph": "X", "cat": "fee", "dur": 0.3, "name": "Counter.values"}, {"pid": 11572, "tid": 17656, "ts": 65257681176.6, "ph": "X", "cat": "fee", "dur": 5426.2, "name": "builtins.sum"}, {"pid": 11572, "tid": 17656, "ts": 65257686603.6, "ph": "X", "cat": "fee", "dur": 0.1, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65257681174.7, "ph": "X", "cat": "fee", "dur": 146231.599, "name": "getWordFrequencies (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:96)"}, {"pid": 11572, "tid": 17656, "ts": 65244567900.0, "ph": "X", "cat": "fee", "dur": 13259507.699, "name": "getWordData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:122)"}, {"pid": 11572, "tid": 17656, "ts": 65257827410.199, "ph": "X", "cat": "fee", "dur": 0.5, "name": "time.perf_counter"}, {"pid": 11572, "tid": 17656, "ts": 65257827417.1, "ph": "X", "cat": "fee", "dur": 240.999, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65257827662.3, "ph": "X", "cat": "fee", "dur": 0.3, "name": "dict.items"}, {"pid": 11572, "tid": 17656, "ts": 65257827668.8, "ph": "X", "cat": "fee", "dur": 0.399, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65257827674.2, "ph": "X", "cat": "fee", "dur": 0.5, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257827675.099, "ph": "X", "cat": "fee", "dur": 0.3, "name": "builtins.iter"}, {"pid": 11572, "tid": 17656, "ts": 65257827679.2, "ph": "X", "cat": "fee", "dur": 4.999, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:563)"}, {"pid": 11572, "tid": 17656, "ts": 65257827685.4, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_heapq.heapify"}, {"pid": 11572, "tid": 17656, "ts": 65257827687.3, "ph": "X", "cat": "fee", "dur": 0.299, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827688.7, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827689.2, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827689.7, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827691.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827693.5, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827694.099, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827696.1, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827696.6, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827697.2, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827698.3, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827699.4, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827701.699, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827702.4, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827703.3, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827706.9, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257827709.4, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860480.9, "ph": "X", "cat": "fee", "dur": 2.499, "name": "list.sort"}, {"pid": 11572, "tid": 17656, "ts": 65257860486.199, "ph": "X", "cat": "fee", "dur": 1.4, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:577)"}, {"pid": 11572, "tid": 17656, "ts": 65257827673.2, "ph": "X", "cat": "fee", "dur": 32814.8, "name": "nlargest (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:521)"}, {"pid": 11572, "tid": 17656, "ts": 65257827666.499, "ph": "X", "cat": "fee", "dur": 32823.3, "name": "most_common (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:600)"}, {"pid": 11572, "tid": 17656, "ts": 65257860494.2, "ph": "X", "cat": "fee", "dur": 1.599, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65257860500.099, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65257860503.399, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65257860502.7, "ph": "X", "cat": "fee", "dur": 1.0, "name": "isstring (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:595)"}, {"pid": 11572, "tid": 17656, "ts": 65257860505.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65257860505.0, "ph": "X", "cat": "fee", "dur": 0.219, "name": "isstring (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:595)"}, {"pid": 11572, "tid": 17656, "ts": 65257860509.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65257860511.7, "ph": "X", "cat": "fee", "dur": 1.2, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65257860509.4, "ph": "X", "cat": "fee", "dur": 3.6, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:224)"}, {"pid": 11572, "tid": 17656, "ts": 65257860514.299, "ph": "X", "cat": "fee", "dur": 1.7, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:76)"}, {"pid": 11572, "tid": 17656, "ts": 65257860519.7, "ph": "X", "cat": "fee", "dur": 0.199, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860519.3, "ph": "X", "cat": "fee", "dur": 0.7, "name": "tell (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:286)"}, {"pid": 11572, "tid": 17656, "ts": 65257860522.3, "ph": "X", "cat": "fee", "dur": 1.3, "name": "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:111)"}, {"pid": 11572, "tid": 17656, "ts": 65257860525.8, "ph": "X", "cat": "fee", "dur": 0.399, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65257860525.4, "ph": "X", "cat": "fee", "dur": 0.9, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65257860527.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860526.999, "ph": "X", "cat": "fee", "dur": 3.4, "name": "tell (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:286)"}, {"pid": 11572, "tid": 17656, "ts": 65257860531.6, "ph": "X", "cat": "fee", "dur": 0.399, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65257860531.299, "ph": "X", "cat": "fee", "dur": 0.9, "name": "match (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65257860532.6, "ph": "X", "cat": "fee", "dur": 0.299, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65257860532.4, "ph": "X", "cat": "fee", "dur": 0.6, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65257860534.0, "ph": "X", "cat": "fee", "dur": 0.3, "name": "builtins.ord"}, {"pid": 11572, "tid": 17656, "ts": 65257860534.8, "ph": "X", "cat": "fee", "dur": 0.299, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65257860534.599, "ph": "X", "cat": "fee", "dur": 0.52, "name": "match (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65257860535.599, "ph": "X", "cat": "fee", "dur": 0.2, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65257860535.4, "ph": "X", "cat": "fee", "dur": 0.5, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65257860536.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 11572, "tid": 17656, "ts": 65257860537.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860537.6, "ph": "X", "cat": "fee", "dur": 2.1, "name": "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)"}, {"pid": 11572, "tid": 17656, "ts": 65257860537.5, "ph": "X", "cat": "fee", "dur": 2.3, "name": "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)"}, {"pid": 11572, "tid": 17656, "ts": 65257860541.699, "ph": "X", "cat": "fee", "dur": 1.0, "name": "type.fromkeys"}, {"pid": 11572, "tid": 17656, "ts": 65257860540.8, "ph": "X", "cat": "fee", "dur": 2.899, "name": "_uniq (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:432)"}, {"pid": 11572, "tid": 17656, "ts": 65257860543.8, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860544.499, "ph": "X", "cat": "fee", "dur": 0.4, "name": "list.insert"}, {"pid": 11572, "tid": 17656, "ts": 65257860545.6, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860545.499, "ph": "X", "cat": "fee", "dur": 0.3, "name": "append (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:172)"}, {"pid": 11572, "tid": 17656, "ts": 65257860547.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860546.9, "ph": "X", "cat": "fee", "dur": 0.32, "name": "__len__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:160)"}, {"pid": 11572, "tid": 17656, "ts": 65257860546.2, "ph": "X", "cat": "fee", "dur": 1.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860551.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65257860550.4, "ph": "X", "cat": "fee", "dur": 0.899, "name": "__getitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:164)"}, {"pid": 11572, "tid": 17656, "ts": 65257860521.0, "ph": "X", "cat": "fee", "dur": 30.9, "name": "_parse (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:493)"}, {"pid": 11572, "tid": 17656, "ts": 65257860552.5, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860552.9, "ph": "X", "cat": "fee", "dur": 0.199, "name": "match (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65257860553.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860517.3, "ph": "X", "cat": "fee", "dur": 36.2, "name": "_parse_sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:435)"}, {"pid": 11572, "tid": 17656, "ts": 65257860554.9, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65257860554.5, "ph": "X", "cat": "fee", "dur": 1.6, "name": "fix_flags (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:921)"}, {"pid": 11572, "tid": 17656, "ts": 65257860507.4, "ph": "X", "cat": "fee", "dur": 49.2, "name": "parse (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:937)"}, {"pid": 11572, "tid": 17656, "ts": 65257860561.0, "ph": "X", "cat": "fee", "dur": 0.799, "name": "builtins.min"}, {"pid": 11572, "tid": 17656, "ts": 65257860562.3, "ph": "X", "cat": "fee", "dur": 0.199, "name": "builtins.min"}, {"pid": 11572, "tid": 17656, "ts": 65257860558.699, "ph": "X", "cat": "fee", "dur": 3.9, "name": "getwidth (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:174)"}, {"pid": 11572, "tid": 17656, "ts": 65257860564.9, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_get_iscased (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:453)"}, {"pid": 11572, "tid": 17656, "ts": 65257860564.1, "ph": "X", "cat": "fee", "dur": 1.5, "name": "_get_literal_prefix (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:461)"}, {"pid": 11572, "tid": 17656, "ts": 65257860567.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_iscased (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:453)"}, {"pid": 11572, "tid": 17656, "ts": 65257860566.299, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_get_charset_prefix (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:492)"}, {"pid": 11572, "tid": 17656, "ts": 65257860567.7, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860567.9, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860568.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860568.299, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860568.5, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860568.7, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.min"}, {"pid": 11572, "tid": 17656, "ts": 65257860568.9, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860573.2, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860576.1, "ph": "X", "cat": "fee", "dur": 1.4, "name": "bytearray.find"}, {"pid": 11572, "tid": 17656, "ts": 65257860577.699, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860577.9, "ph": "X", "cat": "fee", "dur": 0.2, "name": "bytearray.find"}, {"pid": 11572, "tid": 17656, "ts": 65257860578.199, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860578.4, "ph": "X", "cat": "fee", "dur": 0.2, "name": "bytearray.find"}, {"pid": 11572, "tid": 17656, "ts": 65257860579.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860579.699, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860579.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860570.9, "ph": "X", "cat": "fee", "dur": 9.299, "name": "_optimize_charset (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:276)"}, {"pid": 11572, "tid": 17656, "ts": 65257860581.7, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860581.999, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860582.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860582.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860582.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860581.499, "ph": "X", "cat": "fee", "dur": 1.4, "name": "_compile_charset (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65257860582.999, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860558.2, "ph": "X", "cat": "fee", "dur": 25.1, "name": "_compile_info (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:536)"}, {"pid": 11572, "tid": 17656, "ts": 65257860586.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860587.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "bytearray.find"}, {"pid": 11572, "tid": 17656, "ts": 65257860587.299, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860587.4, "ph": "X", "cat": "fee", "dur": 0.2, "name": "bytearray.find"}, {"pid": 11572, "tid": 17656, "ts": 65257860587.7, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860587.799, "ph": "X", "cat": "fee", "dur": 0.1, "name": "bytearray.find"}, {"pid": 11572, "tid": 17656, "ts": 65257860588.2, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860588.5, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860588.599, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860585.6, "ph": "X", "cat": "fee", "dur": 3.099, "name": "_optimize_charset (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:276)"}, {"pid": 11572, "tid": 17656, "ts": 65257860589.099, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860589.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860589.4, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860589.8, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860589.9, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860590.099, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860590.22, "ph": "X", "cat": "fee", "dur": 0.08, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860590.4, "ph": "X", "cat": "fee", "dur": 0.399, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860589.599, "ph": "X", "cat": "fee", "dur": 1.22, "name": "_compile_charset (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:249)"}, {"pid": 11572, "tid": 17656, "ts": 65257860590.9, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860583.9, "ph": "X", "cat": "fee", "dur": 7.3, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:71)"}, {"pid": 11572, "tid": 17656, "ts": 65257860591.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "list.append"}, {"pid": 11572, "tid": 17656, "ts": 65257860557.399, "ph": "X", "cat": "fee", "dur": 34.12, "name": "_code (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:598)"}, {"pid": 11572, "tid": 17656, "ts": 65257860592.7, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860592.5, "ph": "X", "cat": "fee", "dur": 0.3, "name": "groups (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:81)"}, {"pid": 11572, "tid": 17656, "ts": 65257860593.5, "ph": "X", "cat": "fee", "dur": 0.2, "name": "dict.items"}, {"pid": 11572, "tid": 17656, "ts": 65257860594.919, "ph": "X", "cat": "fee", "dur": 0.08, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860594.899, "ph": "X", "cat": "fee", "dur": 0.2, "name": "groups (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:81)"}, {"pid": 11572, "tid": 17656, "ts": 65257860596.4, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_sre.compile"}, {"pid": 11572, "tid": 17656, "ts": 65257860504.6, "ph": "X", "cat": "fee", "dur": 93.0, "name": "compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:759)"}, {"pid": 11572, "tid": 17656, "ts": 65257860600.6, "ph": "X", "cat": "fee", "dur": 0.3, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65257860605.799, "ph": "X", "cat": "fee", "dur": 1.2, "name": "__new__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:670)"}, {"pid": 11572, "tid": 17656, "ts": 65257860604.0, "ph": "X", "cat": "fee", "dur": 3.099, "name": "__call__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:358)"}, {"pid": 11572, "tid": 17656, "ts": 65257860608.2, "ph": "X", "cat": "fee", "dur": 0.2, "name": "__new__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:670)"}, {"pid": 11572, "tid": 17656, "ts": 65257860607.9, "ph": "X", "cat": "fee", "dur": 0.599, "name": "__call__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:358)"}, {"pid": 11572, "tid": 17656, "ts": 65257860600.2, "ph": "X", "cat": "fee", "dur": 8.399, "name": "__and__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:977)"}, {"pid": 11572, "tid": 17656, "ts": 65257860608.9, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860493.299, "ph": "X", "cat": "fee", "dur": 116.4, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65257860610.1, "ph": "X", "cat": "fee", "dur": 6.3, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65257860492.7, "ph": "X", "cat": "fee", "dur": 123.8, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65257860618.9, "ph": "X", "cat": "fee", "dur": 0.099, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65257860620.3, "ph": "X", "cat": "fee", "dur": 0.299, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257860620.799, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.iter"}, {"pid": 11572, "tid": 17656, "ts": 65257860622.4, "ph": "X", "cat": "fee", "dur": 3.3, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:563)"}, {"pid": 11572, "tid": 17656, "ts": 65257860626.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_heapq.heapify"}, {"pid": 11572, "tid": 17656, "ts": 65257860627.8, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860628.5, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860629.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860629.6, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860632.4, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860632.9, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860633.3, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860634.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860634.5, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860634.9, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860635.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860635.999, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860636.7, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860637.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860638.2, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860639.1, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860640.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860640.5, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860640.9, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860642.5, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860643.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860644.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860646.7, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860648.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257860648.6, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923642.1, "ph": "X", "cat": "fee", "dur": 2.599, "name": "list.sort"}, {"pid": 11572, "tid": 17656, "ts": 65257923647.6, "ph": "X", "cat": "fee", "dur": 3.0, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:577)"}, {"pid": 11572, "tid": 17656, "ts": 65257860619.999, "ph": "X", "cat": "fee", "dur": 63031.1, "name": "nlargest (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:521)"}, {"pid": 11572, "tid": 17656, "ts": 65257860617.999, "ph": "X", "cat": "fee", "dur": 63035.1, "name": "most_common (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:600)"}, {"pid": 11572, "tid": 17656, "ts": 65257923657.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65257923656.599, "ph": "X", "cat": "fee", "dur": 6.0, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65257923663.1, "ph": "X", "cat": "fee", "dur": 11.2, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65257923655.599, "ph": "X", "cat": "fee", "dur": 18.8, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65257923677.099, "ph": "X", "cat": "fee", "dur": 0.3, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65257923679.0, "ph": "X", "cat": "fee", "dur": 0.5, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257923679.8, "ph": "X", "cat": "fee", "dur": 0.4, "name": "builtins.iter"}, {"pid": 11572, "tid": 17656, "ts": 65257923683.3, "ph": "X", "cat": "fee", "dur": 2.8, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:563)"}, {"pid": 11572, "tid": 17656, "ts": 65257923686.7, "ph": "X", "cat": "fee", "dur": 0.7, "name": "_heapq.heapify"}, {"pid": 11572, "tid": 17656, "ts": 65257923687.999, "ph": "X", "cat": "fee", "dur": 0.3, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923688.799, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923689.4, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923689.799, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923690.2, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923690.9, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923691.5, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923691.9, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923693.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923693.599, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923694.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923694.599, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923695.5, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923695.899, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923697.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923698.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923700.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923700.699, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923701.199, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923705.499, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923707.5, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257923711.099, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997229.4, "ph": "X", "cat": "fee", "dur": 2.3, "name": "list.sort"}, {"pid": 11572, "tid": 17656, "ts": 65257997233.6, "ph": "X", "cat": "fee", "dur": 1.399, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:577)"}, {"pid": 11572, "tid": 17656, "ts": 65257923678.6, "ph": "X", "cat": "fee", "dur": 73557.0, "name": "nlargest (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:521)"}, {"pid": 11572, "tid": 17656, "ts": 65257923676.2, "ph": "X", "cat": "fee", "dur": 73560.899, "name": "most_common (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:600)"}, {"pid": 11572, "tid": 17656, "ts": 65257997240.099, "ph": "X", "cat": "fee", "dur": 1.1, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65257997239.5, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65257997242.899, "ph": "X", "cat": "fee", "dur": 6.3, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65257997239.0, "ph": "X", "cat": "fee", "dur": 10.3, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65257997251.9, "ph": "X", "cat": "fee", "dur": 0.1, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65257997253.299, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65257997253.799, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.iter"}, {"pid": 11572, "tid": 17656, "ts": 65257997256.0, "ph": "X", "cat": "fee", "dur": 4.2, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:563)"}, {"pid": 11572, "tid": 17656, "ts": 65257997260.7, "ph": "X", "cat": "fee", "dur": 0.599, "name": "_heapq.heapify"}, {"pid": 11572, "tid": 17656, "ts": 65257997262.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997263.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997263.4, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997266.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997266.999, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997267.9, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997268.7, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997269.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997270.1, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997271.4, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997272.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997273.1, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997275.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997275.5, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997276.5, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997277.3, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997277.899, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997278.399, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997279.7, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997280.399, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997281.5, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997287.3, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65257997291.299, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070756.8, "ph": "X", "cat": "fee", "dur": 2.0, "name": "list.sort"}, {"pid": 11572, "tid": 17656, "ts": 65258070760.4, "ph": "X", "cat": "fee", "dur": 2.0, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:577)"}, {"pid": 11572, "tid": 17656, "ts": 65257997253.0, "ph": "X", "cat": "fee", "dur": 73509.799, "name": "nlargest (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:521)"}, {"pid": 11572, "tid": 17656, "ts": 65257997251.1, "ph": "X", "cat": "fee", "dur": 73512.999, "name": "most_common (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:600)"}, {"pid": 11572, "tid": 17656, "ts": 65258070767.6, "ph": "X", "cat": "fee", "dur": 0.7, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258070767.099, "ph": "X", "cat": "fee", "dur": 2.2, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258070769.7, "ph": "X", "cat": "fee", "dur": 6.499, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258070766.5, "ph": "X", "cat": "fee", "dur": 9.8, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258070778.3, "ph": "X", "cat": "fee", "dur": 0.199, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65258070779.6, "ph": "X", "cat": "fee", "dur": 0.199, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65258070780.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.iter"}, {"pid": 11572, "tid": 17656, "ts": 65258070782.4, "ph": "X", "cat": "fee", "dur": 2.799, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:563)"}, {"pid": 11572, "tid": 17656, "ts": 65258070785.599, "ph": "X", "cat": "fee", "dur": 0.6, "name": "_heapq.heapify"}, {"pid": 11572, "tid": 17656, "ts": 65258070786.7, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070787.7, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070788.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070789.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070789.6, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070791.6, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070793.6, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070795.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070795.499, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070796.3, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070797.299, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070799.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070800.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070800.599, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070805.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070813.8, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258070823.899, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258144067.2, "ph": "X", "cat": "fee", "dur": 2.099, "name": "list.sort"}, {"pid": 11572, "tid": 17656, "ts": 65258144071.2, "ph": "X", "cat": "fee", "dur": 1.8, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:577)"}, {"pid": 11572, "tid": 17656, "ts": 65258070779.299, "ph": "X", "cat": "fee", "dur": 73294.2, "name": "nlargest (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:521)"}, {"pid": 11572, "tid": 17656, "ts": 65258070777.7, "ph": "X", "cat": "fee", "dur": 73297.6, "name": "most_common (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:600)"}, {"pid": 11572, "tid": 17656, "ts": 65258144079.0, "ph": "X", "cat": "fee", "dur": 0.699, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258144078.3, "ph": "X", "cat": "fee", "dur": 2.6, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258144081.3, "ph": "X", "cat": "fee", "dur": 5.7, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258144077.399, "ph": "X", "cat": "fee", "dur": 9.7, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258144089.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65258144090.3, "ph": "X", "cat": "fee", "dur": 0.299, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65258144090.7, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.iter"}, {"pid": 11572, "tid": 17656, "ts": 65258144093.8, "ph": "X", "cat": "fee", "dur": 13497.2, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:563)"}, {"pid": 11572, "tid": 17656, "ts": 65258157592.1, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_heapq.heapify"}, {"pid": 11572, "tid": 17656, "ts": 65258157594.1, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157595.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157595.999, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157596.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157596.9, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157597.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157597.999, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157598.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157598.8, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157600.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157601.4, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157601.9, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157602.5, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157604.5, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157605.099, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157605.7, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157607.5, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157608.1, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157616.999, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258157617.6, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233688.1, "ph": "X", "cat": "fee", "dur": 2.3, "name": "list.sort"}, {"pid": 11572, "tid": 17656, "ts": 65258233692.599, "ph": "X", "cat": "fee", "dur": 1.9, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:577)"}, {"pid": 11572, "tid": 17656, "ts": 65258144090.2, "ph": "X", "cat": "fee", "dur": 89604.699, "name": "nlargest (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:521)"}, {"pid": 11572, "tid": 17656, "ts": 65258144088.5, "ph": "X", "cat": "fee", "dur": 89608.3, "name": "most_common (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:600)"}, {"pid": 11572, "tid": 17656, "ts": 65258233700.8, "ph": "X", "cat": "fee", "dur": 0.799, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258233700.3, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258233703.8, "ph": "X", "cat": "fee", "dur": 6.6, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258233699.4, "ph": "X", "cat": "fee", "dur": 11.1, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258233713.2, "ph": "X", "cat": "fee", "dur": 0.199, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65258233715.0, "ph": "X", "cat": "fee", "dur": 0.199, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65258233717.4, "ph": "X", "cat": "fee", "dur": 0.299, "name": "builtins.iter"}, {"pid": 11572, "tid": 17656, "ts": 65258233720.1, "ph": "X", "cat": "fee", "dur": 2.9, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:563)"}, {"pid": 11572, "tid": 17656, "ts": 65258233723.5, "ph": "X", "cat": "fee", "dur": 0.7, "name": "_heapq.heapify"}, {"pid": 11572, "tid": 17656, "ts": 65258233724.799, "ph": "X", "cat": "fee", "dur": 0.3, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233725.6, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233726.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233726.5, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233727.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233727.599, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233728.7, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233729.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233729.899, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233730.5, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233731.7, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233732.1, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233732.5, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233733.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233733.699, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233734.8, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233735.4, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233737.999, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233741.799, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258233752.199, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320894.5, "ph": "X", "cat": "fee", "dur": 1.8, "name": "list.sort"}, {"pid": 11572, "tid": 17656, "ts": 65258320897.899, "ph": "X", "cat": "fee", "dur": 1.8, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:577)"}, {"pid": 11572, "tid": 17656, "ts": 65258233714.7, "ph": "X", "cat": "fee", "dur": 87185.5, "name": "nlargest (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:521)"}, {"pid": 11572, "tid": 17656, "ts": 65258233712.3, "ph": "X", "cat": "fee", "dur": 87189.399, "name": "most_common (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:600)"}, {"pid": 11572, "tid": 17656, "ts": 65258320905.4, "ph": "X", "cat": "fee", "dur": 0.7, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258320904.9, "ph": "X", "cat": "fee", "dur": 2.3, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258320907.6, "ph": "X", "cat": "fee", "dur": 5.6, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258320904.199, "ph": "X", "cat": "fee", "dur": 9.1, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258320915.599, "ph": "X", "cat": "fee", "dur": 0.2, "name": "Counter.items"}, {"pid": 11572, "tid": 17656, "ts": 65258320916.899, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.len"}, {"pid": 11572, "tid": 17656, "ts": 65258320917.399, "ph": "X", "cat": "fee", "dur": 0.4, "name": "builtins.iter"}, {"pid": 11572, "tid": 17656, "ts": 65258320920.1, "ph": "X", "cat": "fee", "dur": 2.8, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:563)"}, {"pid": 11572, "tid": 17656, "ts": 65258320923.4, "ph": "X", "cat": "fee", "dur": 0.7, "name": "_heapq.heapify"}, {"pid": 11572, "tid": 17656, "ts": 65258320924.7, "ph": "X", "cat": "fee", "dur": 0.299, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320925.7, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320926.2, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320926.7, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320927.7, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320928.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320929.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320930.1, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320932.3, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320933.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320933.9, "ph": "X", "cat": "fee", "dur": 0.199, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258320941.199, "ph": "X", "cat": "fee", "dur": 0.2, "name": "_heapq.heapreplace"}, {"pid": 11572, "tid": 17656, "ts": 65258408138.7, "ph": "X", "cat": "fee", "dur": 2.1, "name": "list.sort"}, {"pid": 11572, "tid": 17656, "ts": 65258408142.2, "ph": "X", "cat": "fee", "dur": 1.599, "name": "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:577)"}, {"pid": 11572, "tid": 17656, "ts": 65258320916.6, "ph": "X", "cat": "fee", "dur": 87227.599, "name": "nlargest (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:521)"}, {"pid": 11572, "tid": 17656, "ts": 65258320914.9, "ph": "X", "cat": "fee", "dur": 87231.1, "name": "most_common (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:600)"}, {"pid": 11572, "tid": 17656, "ts": 65258408153.2, "ph": "X", "cat": "fee", "dur": 0.7, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258408152.299, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258408155.7, "ph": "X", "cat": "fee", "dur": 6.1, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258408151.6, "ph": "X", "cat": "fee", "dur": 10.299, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258408164.5, "ph": "X", "cat": "fee", "dur": 336.199, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65258408504.099, "ph": "X", "cat": "fee", "dur": 0.9, "name": "<listcomp> (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:175)"}, {"pid": 11572, "tid": 17656, "ts": 65258408510.199, "ph": "X", "cat": "fee", "dur": 203.1, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65258408713.999, "ph": "X", "cat": "fee", "dur": 0.5, "name": "dict.items"}, {"pid": 11572, "tid": 17656, "ts": 65258408715.499, "ph": "X", "cat": "fee", "dur": 0.3, "name": "str.upper"}, {"pid": 11572, "tid": 17656, "ts": 65258408722.8, "ph": "X", "cat": "fee", "dur": 245.899, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65258408969.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "str.upper"}, {"pid": 11572, "tid": 17656, "ts": 65258408975.299, "ph": "X", "cat": "fee", "dur": 32.3, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65258409008.2, "ph": "X", "cat": "fee", "dur": 0.1, "name": "str.upper"}, {"pid": 11572, "tid": 17656, "ts": 65258409013.7, "ph": "X", "cat": "fee", "dur": 86.2, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65258409100.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "str.upper"}, {"pid": 11572, "tid": 17656, "ts": 65258409105.8, "ph": "X", "cat": "fee", "dur": 85.0, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65258409191.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "str.upper"}, {"pid": 11572, "tid": 17656, "ts": 65258409197.0, "ph": "X", "cat": "fee", "dur": 81.5, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65258409280.2, "ph": "X", "cat": "fee", "dur": 0.2, "name": "str.upper"}, {"pid": 11572, "tid": 17656, "ts": 65258409289.0, "ph": "X", "cat": "fee", "dur": 110.2, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65258409400.0, "ph": "X", "cat": "fee", "dur": 0.099, "name": "str.upper"}, {"pid": 11572, "tid": 17656, "ts": 65258409405.6, "ph": "X", "cat": "fee", "dur": 112.8, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65258409519.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "str.upper"}, {"pid": 11572, "tid": 17656, "ts": 65258409524.0, "ph": "X", "cat": "fee", "dur": 112.7, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65257827660.899, "ph": "X", "cat": "fee", "dur": 581976.5, "name": "printTopNWords (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:156)"}, {"pid": 11572, "tid": 17656, "ts": 65258409643.9, "ph": "X", "cat": "fee", "dur": 0.2, "name": "dict.items"}, {"pid": 11572, "tid": 17656, "ts": 65258409645.1, "ph": "X", "cat": "fee", "dur": 0.099, "name": "dict.keys"}, {"pid": 11572, "tid": 17656, "ts": 65258409648.3, "ph": "X", "cat": "fee", "dur": 0.799, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258409647.999, "ph": "X", "cat": "fee", "dur": 2.4, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258409650.6, "ph": "X", "cat": "fee", "dur": 4.899, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258409647.4, "ph": "X", "cat": "fee", "dur": 8.199, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258409656.4, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.keys"}, {"pid": 11572, "tid": 17656, "ts": 65258409658.0, "ph": "X", "cat": "fee", "dur": 0.2, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258409657.899, "ph": "X", "cat": "fee", "dur": 0.6, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258409658.7, "ph": "X", "cat": "fee", "dur": 2.399, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258409657.7, "ph": "X", "cat": "fee", "dur": 3.499, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258409661.5, "ph": "X", "cat": "fee", "dur": 0.099, "name": "dict.keys"}, {"pid": 11572, "tid": 17656, "ts": 65258409662.6, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258409662.5, "ph": "X", "cat": "fee", "dur": 0.399, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258409663.0, "ph": "X", "cat": "fee", "dur": 2.3, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258409662.3, "ph": "X", "cat": "fee", "dur": 3.1, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258409668.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.keys"}, {"pid": 11572, "tid": 17656, "ts": 65258409669.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258409669.1, "ph": "X", "cat": "fee", "dur": 0.5, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258409669.7, "ph": "X", "cat": "fee", "dur": 2.3, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258409668.9, "ph": "X", "cat": "fee", "dur": 3.199, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258409672.4, "ph": "X", "cat": "fee", "dur": 0.099, "name": "dict.keys"}, {"pid": 11572, "tid": 17656, "ts": 65258409673.4, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258409673.3, "ph": "X", "cat": "fee", "dur": 0.4, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258409673.8, "ph": "X", "cat": "fee", "dur": 2.2, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258409673.099, "ph": "X", "cat": "fee", "dur": 3.0, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258409676.399, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.keys"}, {"pid": 11572, "tid": 17656, "ts": 65258409677.399, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258409677.3, "ph": "X", "cat": "fee", "dur": 0.4, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258409677.8, "ph": "X", "cat": "fee", "dur": 2.3, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258409677.2, "ph": "X", "cat": "fee", "dur": 2.919, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258409680.699, "ph": "X", "cat": "fee", "dur": 0.1, "name": "dict.keys"}, {"pid": 11572, "tid": 17656, "ts": 65258409682.12, "ph": "X", "cat": "fee", "dur": 0.18, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258409682.1, "ph": "X", "cat": "fee", "dur": 0.3, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258409682.6, "ph": "X", "cat": "fee", "dur": 2.2, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258409681.9, "ph": "X", "cat": "fee", "dur": 3.0, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258409685.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.keys"}, {"pid": 11572, "tid": 17656, "ts": 65258409686.2, "ph": "X", "cat": "fee", "dur": 0.099, "name": "builtins.isinstance"}, {"pid": 11572, "tid": 17656, "ts": 65258409686.1, "ph": "X", "cat": "fee", "dur": 0.399, "name": "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)"}, {"pid": 11572, "tid": 17656, "ts": 65258409686.6, "ph": "X", "cat": "fee", "dur": 2.399, "name": "re.Pattern.sub"}, {"pid": 11572, "tid": 17656, "ts": 65258409685.9, "ph": "X", "cat": "fee", "dur": 3.2, "name": "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)"}, {"pid": 11572, "tid": 17656, "ts": 65258409689.599, "ph": "X", "cat": "fee", "dur": 204.6, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65258409903.9, "ph": "X", "cat": "fee", "dur": 95.7, "name": "builtins.print"}, {"pid": 11572, "tid": 17656, "ts": 65258409643.4, "ph": "X", "cat": "fee", "dur": 356.7, "name": "printWordFrequencyOverYears (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:183)"}, {"pid": 11572, "tid": 17656, "ts": 65160479932.6, "ph": "X", "cat": "fee", "dur": 97930068.1, "name": "runWordCounter (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:214)"}, {"pid": 11572, "tid": 17656, "ts": 65160479932.4, "ph": "X", "cat": "fee", "dur": 98278199.7, "name": "main (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:255)"}, {"pid": 11572, "tid": 17656, "ts": 65160479925.4, "ph": "X", "cat": "fee", "dur": 98278207.699, "name": "<module> (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:1)"}, {"pid": 11572, "tid": 17656, "ts": 65160479924.7, "ph": "X", "cat": "fee", "dur": 98278209.499, "name": "builtins.exec"}], "viztracer_metadata": {"overflow": false, "version": "0.15.1"}, "file_info": {"files": {"C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py": ["# Module 'ntpath' -- common operations on WinNT/Win95 pathnames\n\"\"\"Common pathname manipulations, WindowsNT/95 version.\n\nInstead of importing this module directly, import os and refer to this\nmodule as os.path.\n\"\"\"\n\n# strings representing various path-related bits and pieces\n# These are primarily for export; internally, they are hardcoded.\n# Should be set before imports for resolving cyclic dependency.\ncurdir = '.'\npardir = '..'\nextsep = '.'\nsep = '\\\\'\npathsep = ';'\naltsep = '/'\ndefpath = '.;C:\\\\bin'\ndevnull = 'nul'\n\nimport os\nimport sys\nimport stat\nimport genericpath\nfrom genericpath import *\n\n__all__ = [\"normcase\",\"isabs\",\"join\",\"splitdrive\",\"split\",\"splitext\",\n           \"basename\",\"dirname\",\"commonprefix\",\"getsize\",\"getmtime\",\n           \"getatime\",\"getctime\", \"islink\",\"exists\",\"lexists\",\"isdir\",\"isfile\",\n           \"ismount\", \"expanduser\",\"expandvars\",\"normpath\",\"abspath\",\n           \"curdir\",\"pardir\",\"sep\",\"pathsep\",\"defpath\",\"altsep\",\n           \"extsep\",\"devnull\",\"realpath\",\"supports_unicode_filenames\",\"relpath\",\n           \"samefile\", \"sameopenfile\", \"samestat\", \"commonpath\"]\n\ndef _get_bothseps(path):\n    if isinstance(path, bytes):\n        return b'\\\\/'\n    else:\n        return '\\\\/'\n\n# Normalize the case of a pathname and map slashes to backslashes.\n# Other normalizations (such as optimizing '../' away) are not done\n# (this is done by normpath).\n\ndef normcase(s):\n    \"\"\"Normalize case of pathname.\n\n    Makes all characters lowercase and all slashes into backslashes.\"\"\"\n    s = os.fspath(s)\n    if isinstance(s, bytes):\n        return s.replace(b'/', b'\\\\').lower()\n    else:\n        return s.replace('/', '\\\\').lower()\n\n\n# Return whether a path is absolute.\n# Trivial in Posix, harder on Windows.\n# For Windows it is absolute if it starts with a slash or backslash (current\n# volume), or if a pathname after the volume-letter-and-colon or UNC-resource\n# starts with a slash or backslash.\n\ndef isabs(s):\n    \"\"\"Test whether a path is absolute\"\"\"\n    s = os.fspath(s)\n    # Paths beginning with \\\\?\\ are always absolute, but do not\n    # necessarily contain a drive.\n    if isinstance(s, bytes):\n        if s.replace(b'/', b'\\\\').startswith(b'\\\\\\\\?\\\\'):\n            return True\n    else:\n        if s.replace('/', '\\\\').startswith('\\\\\\\\?\\\\'):\n            return True\n    s = splitdrive(s)[1]\n    return len(s) > 0 and s[0] in _get_bothseps(s)\n\n\n# Join two (or more) paths.\ndef join(path, *paths):\n    path = os.fspath(path)\n    if isinstance(path, bytes):\n        sep = b'\\\\'\n        seps = b'\\\\/'\n        colon = b':'\n    else:\n        sep = '\\\\'\n        seps = '\\\\/'\n        colon = ':'\n    try:\n        if not paths:\n            path[:0] + sep  #23780: Ensure compatible data type even if p is null.\n        result_drive, result_path = splitdrive(path)\n        for p in map(os.fspath, paths):\n            p_drive, p_path = splitdrive(p)\n            if p_path and p_path[0] in seps:\n                # Second path is absolute\n                if p_drive or not result_drive:\n                    result_drive = p_drive\n                result_path = p_path\n                continue\n            elif p_drive and p_drive != result_drive:\n                if p_drive.lower() != result_drive.lower():\n                    # Different drives => ignore the first path entirely\n                    result_drive = p_drive\n                    result_path = p_path\n                    continue\n                # Same drive in different case\n                result_drive = p_drive\n            # Second path is relative to the first\n            if result_path and result_path[-1] not in seps:\n                result_path = result_path + sep\n            result_path = result_path + p_path\n        ## add separator between UNC and non-absolute path\n        if (result_path and result_path[0] not in seps and\n            result_drive and result_drive[-1:] != colon):\n            return result_drive + sep + result_path\n        return result_drive + result_path\n    except (TypeError, AttributeError, BytesWarning):\n        genericpath._check_arg_types('join', path, *paths)\n        raise\n\n\n# Split a path in a drive specification (a drive letter followed by a\n# colon) and the path specification.\n# It is always true that drivespec + pathspec == p\ndef splitdrive(p):\n    \"\"\"Split a pathname into drive/UNC sharepoint and relative path specifiers.\n    Returns a 2-tuple (drive_or_unc, path); either part may be empty.\n\n    If you assign\n        result = splitdrive(p)\n    It is always true that:\n        result[0] + result[1] == p\n\n    If the path contained a drive letter, drive_or_unc will contain everything\n    up to and including the colon.  e.g. splitdrive(\"c:/dir\") returns (\"c:\", \"/dir\")\n\n    If the path contained a UNC path, the drive_or_unc will contain the host name\n    and share up to but not including the fourth directory separator character.\n    e.g. splitdrive(\"//host/computer/dir\") returns (\"//host/computer\", \"/dir\")\n\n    Paths cannot contain both a drive letter and a UNC path.\n\n    \"\"\"\n    p = os.fspath(p)\n    if len(p) >= 2:\n        if isinstance(p, bytes):\n            sep = b'\\\\'\n            altsep = b'/'\n            colon = b':'\n        else:\n            sep = '\\\\'\n            altsep = '/'\n            colon = ':'\n        normp = p.replace(altsep, sep)\n        if (normp[0:2] == sep*2) and (normp[2:3] != sep):\n            # is a UNC path:\n            # vvvvvvvvvvvvvvvvvvvv drive letter or UNC path\n            # \\\\machine\\mountpoint\\directory\\etc\\...\n            #           directory ^^^^^^^^^^^^^^^\n            index = normp.find(sep, 2)\n            if index == -1:\n                return p[:0], p\n            index2 = normp.find(sep, index + 1)\n            # a UNC path can't have two slashes in a row\n            # (after the initial two)\n            if index2 == index + 1:\n                return p[:0], p\n            if index2 == -1:\n                index2 = len(p)\n            return p[:index2], p[index2:]\n        if normp[1:2] == colon:\n            return p[:2], p[2:]\n    return p[:0], p\n\n\n# Split a path in head (everything up to the last '/') and tail (the\n# rest).  After the trailing '/' is stripped, the invariant\n# join(head, tail) == p holds.\n# The resulting head won't end in '/' unless it is the root.\n\ndef split(p):\n    \"\"\"Split a pathname.\n\n    Return tuple (head, tail) where tail is everything after the final slash.\n    Either part may be empty.\"\"\"\n    p = os.fspath(p)\n    seps = _get_bothseps(p)\n    d, p = splitdrive(p)\n    # set i to index beyond p's last slash\n    i = len(p)\n    while i and p[i-1] not in seps:\n        i -= 1\n    head, tail = p[:i], p[i:]  # now tail has no slashes\n    # remove trailing slashes from head, unless it's all slashes\n    head = head.rstrip(seps) or head\n    return d + head, tail\n\n\n# Split a path in root and extension.\n# The extension is everything starting at the last dot in the last\n# pathname component; the root is everything before that.\n# It is always true that root + ext == p.\n\ndef splitext(p):\n    p = os.fspath(p)\n    if isinstance(p, bytes):\n        return genericpath._splitext(p, b'\\\\', b'/', b'.')\n    else:\n        return genericpath._splitext(p, '\\\\', '/', '.')\nsplitext.__doc__ = genericpath._splitext.__doc__\n\n\n# Return the tail (basename) part of a path.\n\ndef basename(p):\n    \"\"\"Returns the final component of a pathname\"\"\"\n    return split(p)[1]\n\n\n# Return the head (dirname) part of a path.\n\ndef dirname(p):\n    \"\"\"Returns the directory component of a pathname\"\"\"\n    return split(p)[0]\n\n# Is a path a symbolic link?\n# This will always return false on systems where os.lstat doesn't exist.\n\ndef islink(path):\n    \"\"\"Test whether a path is a symbolic link.\n    This will always return false for Windows prior to 6.0.\n    \"\"\"\n    try:\n        st = os.lstat(path)\n    except (OSError, ValueError, AttributeError):\n        return False\n    return stat.S_ISLNK(st.st_mode)\n\n# Being true for dangling symbolic links is also useful.\n\ndef lexists(path):\n    \"\"\"Test whether a path exists.  Returns True for broken symbolic links\"\"\"\n    try:\n        st = os.lstat(path)\n    except (OSError, ValueError):\n        return False\n    return True\n\n# Is a path a mount point?\n# Any drive letter root (eg c:\\)\n# Any share UNC (eg \\\\server\\share)\n# Any volume mounted on a filesystem folder\n#\n# No one method detects all three situations. Historically we've lexically\n# detected drive letter roots and share UNCs. The canonical approach to\n# detecting mounted volumes (querying the reparse tag) fails for the most\n# common case: drive letter roots. The alternative which uses GetVolumePathName\n# fails if the drive letter is the result of a SUBST.\ntry:\n    from nt import _getvolumepathname\nexcept ImportError:\n    _getvolumepathname = None\ndef ismount(path):\n    \"\"\"Test whether a path is a mount point (a drive root, the root of a\n    share, or a mounted volume)\"\"\"\n    path = os.fspath(path)\n    seps = _get_bothseps(path)\n    path = abspath(path)\n    root, rest = splitdrive(path)\n    if root and root[0] in seps:\n        return (not rest) or (rest in seps)\n    if rest in seps:\n        return True\n\n    if _getvolumepathname:\n        return path.rstrip(seps) == _getvolumepathname(path).rstrip(seps)\n    else:\n        return False\n\n\n# Expand paths beginning with '~' or '~user'.\n# '~' means $HOME; '~user' means that user's home directory.\n# If the path doesn't begin with '~', or if the user or $HOME is unknown,\n# the path is returned unchanged (leaving error reporting to whatever\n# function is called with the expanded path as argument).\n# See also module 'glob' for expansion of *, ? and [...] in pathnames.\n# (A function should also be defined to do full *sh-style environment\n# variable expansion.)\n\ndef expanduser(path):\n    \"\"\"Expand ~ and ~user constructs.\n\n    If user or $HOME is unknown, do nothing.\"\"\"\n    path = os.fspath(path)\n    if isinstance(path, bytes):\n        tilde = b'~'\n    else:\n        tilde = '~'\n    if not path.startswith(tilde):\n        return path\n    i, n = 1, len(path)\n    while i < n and path[i] not in _get_bothseps(path):\n        i += 1\n\n    if 'USERPROFILE' in os.environ:\n        userhome = os.environ['USERPROFILE']\n    elif not 'HOMEPATH' in os.environ:\n        return path\n    else:\n        try:\n            drive = os.environ['HOMEDRIVE']\n        except KeyError:\n            drive = ''\n        userhome = join(drive, os.environ['HOMEPATH'])\n\n    if isinstance(path, bytes):\n        userhome = os.fsencode(userhome)\n\n    if i != 1: #~user\n        userhome = join(dirname(userhome), path[1:i])\n\n    return userhome + path[i:]\n\n\n# Expand paths containing shell variable substitutions.\n# The following rules apply:\n#       - no expansion within single quotes\n#       - '$$' is translated into '$'\n#       - '%%' is translated into '%' if '%%' are not seen in %var1%%var2%\n#       - ${varname} is accepted.\n#       - $varname is accepted.\n#       - %varname% is accepted.\n#       - varnames can be made out of letters, digits and the characters '_-'\n#         (though is not verified in the ${varname} and %varname% cases)\n# XXX With COMMAND.COM you can use any characters in a variable name,\n# XXX except '^|<>='.\n\ndef expandvars(path):\n    \"\"\"Expand shell variables of the forms $var, ${var} and %var%.\n\n    Unknown variables are left unchanged.\"\"\"\n    path = os.fspath(path)\n    if isinstance(path, bytes):\n        if b'$' not in path and b'%' not in path:\n            return path\n        import string\n        varchars = bytes(string.ascii_letters + string.digits + '_-', 'ascii')\n        quote = b'\\''\n        percent = b'%'\n        brace = b'{'\n        rbrace = b'}'\n        dollar = b'$'\n        environ = getattr(os, 'environb', None)\n    else:\n        if '$' not in path and '%' not in path:\n            return path\n        import string\n        varchars = string.ascii_letters + string.digits + '_-'\n        quote = '\\''\n        percent = '%'\n        brace = '{'\n        rbrace = '}'\n        dollar = '$'\n        environ = os.environ\n    res = path[:0]\n    index = 0\n    pathlen = len(path)\n    while index < pathlen:\n        c = path[index:index+1]\n        if c == quote:   # no expansion within single quotes\n            path = path[index + 1:]\n            pathlen = len(path)\n            try:\n                index = path.index(c)\n                res += c + path[:index + 1]\n            except ValueError:\n                res += c + path\n                index = pathlen - 1\n        elif c == percent:  # variable or '%'\n            if path[index + 1:index + 2] == percent:\n                res += c\n                index += 1\n            else:\n                path = path[index+1:]\n                pathlen = len(path)\n                try:\n                    index = path.index(percent)\n                except ValueError:\n                    res += percent + path\n                    index = pathlen - 1\n                else:\n                    var = path[:index]\n                    try:\n                        if environ is None:\n                            value = os.fsencode(os.environ[os.fsdecode(var)])\n                        else:\n                            value = environ[var]\n                    except KeyError:\n                        value = percent + var + percent\n                    res += value\n        elif c == dollar:  # variable or '$$'\n            if path[index + 1:index + 2] == dollar:\n                res += c\n                index += 1\n            elif path[index + 1:index + 2] == brace:\n                path = path[index+2:]\n                pathlen = len(path)\n                try:\n                    index = path.index(rbrace)\n                except ValueError:\n                    res += dollar + brace + path\n                    index = pathlen - 1\n                else:\n                    var = path[:index]\n                    try:\n                        if environ is None:\n                            value = os.fsencode(os.environ[os.fsdecode(var)])\n                        else:\n                            value = environ[var]\n                    except KeyError:\n                        value = dollar + brace + var + rbrace\n                    res += value\n            else:\n                var = path[:0]\n                index += 1\n                c = path[index:index + 1]\n                while c and c in varchars:\n                    var += c\n                    index += 1\n                    c = path[index:index + 1]\n                try:\n                    if environ is None:\n                        value = os.fsencode(os.environ[os.fsdecode(var)])\n                    else:\n                        value = environ[var]\n                except KeyError:\n                    value = dollar + var\n                res += value\n                if c:\n                    index -= 1\n        else:\n            res += c\n        index += 1\n    return res\n\n\n# Normalize a path, e.g. A//B, A/./B and A/foo/../B all become A\\B.\n# Previously, this function also truncated pathnames to 8+3 format,\n# but as this module is called \"ntpath\", that's obviously wrong!\n\ndef normpath(path):\n    \"\"\"Normalize path, eliminating double slashes, etc.\"\"\"\n    path = os.fspath(path)\n    if isinstance(path, bytes):\n        sep = b'\\\\'\n        altsep = b'/'\n        curdir = b'.'\n        pardir = b'..'\n        special_prefixes = (b'\\\\\\\\.\\\\', b'\\\\\\\\?\\\\')\n    else:\n        sep = '\\\\'\n        altsep = '/'\n        curdir = '.'\n        pardir = '..'\n        special_prefixes = ('\\\\\\\\.\\\\', '\\\\\\\\?\\\\')\n    if path.startswith(special_prefixes):\n        # in the case of paths with these prefixes:\n        # \\\\.\\ -> device names\n        # \\\\?\\ -> literal paths\n        # do not do any normalization, but return the path\n        # unchanged apart from the call to os.fspath()\n        return path\n    path = path.replace(altsep, sep)\n    prefix, path = splitdrive(path)\n\n    # collapse initial backslashes\n    if path.startswith(sep):\n        prefix += sep\n        path = path.lstrip(sep)\n\n    comps = path.split(sep)\n    i = 0\n    while i < len(comps):\n        if not comps[i] or comps[i] == curdir:\n            del comps[i]\n        elif comps[i] == pardir:\n            if i > 0 and comps[i-1] != pardir:\n                del comps[i-1:i+1]\n                i -= 1\n            elif i == 0 and prefix.endswith(sep):\n                del comps[i]\n            else:\n                i += 1\n        else:\n            i += 1\n    # If the path is now empty, substitute '.'\n    if not prefix and not comps:\n        comps.append(curdir)\n    return prefix + sep.join(comps)\n\ndef _abspath_fallback(path):\n    \"\"\"Return the absolute version of a path as a fallback function in case\n    `nt._getfullpathname` is not available or raises OSError. See bpo-31047 for\n    more.\n\n    \"\"\"\n\n    path = os.fspath(path)\n    if not isabs(path):\n        if isinstance(path, bytes):\n            cwd = os.getcwdb()\n        else:\n            cwd = os.getcwd()\n        path = join(cwd, path)\n    return normpath(path)\n\n# Return an absolute path.\ntry:\n    from nt import _getfullpathname\n\nexcept ImportError: # not running on Windows - mock up something sensible\n    abspath = _abspath_fallback\n\nelse:  # use native Windows method on Windows\n    def abspath(path):\n        \"\"\"Return the absolute version of a path.\"\"\"\n        try:\n            return normpath(_getfullpathname(path))\n        except (OSError, ValueError):\n            return _abspath_fallback(path)\n\ntry:\n    from nt import _getfinalpathname, readlink as _nt_readlink\nexcept ImportError:\n    # realpath is a no-op on systems without _getfinalpathname support.\n    realpath = abspath\nelse:\n    def _readlink_deep(path):\n        # These error codes indicate that we should stop reading links and\n        # return the path we currently have.\n        # 1: ERROR_INVALID_FUNCTION\n        # 2: ERROR_FILE_NOT_FOUND\n        # 3: ERROR_DIRECTORY_NOT_FOUND\n        # 5: ERROR_ACCESS_DENIED\n        # 21: ERROR_NOT_READY (implies drive with no media)\n        # 32: ERROR_SHARING_VIOLATION (probably an NTFS paging file)\n        # 50: ERROR_NOT_SUPPORTED (implies no support for reparse points)\n        # 67: ERROR_BAD_NET_NAME (implies remote server unavailable)\n        # 87: ERROR_INVALID_PARAMETER\n        # 4390: ERROR_NOT_A_REPARSE_POINT\n        # 4392: ERROR_INVALID_REPARSE_DATA\n        # 4393: ERROR_REPARSE_TAG_INVALID\n        allowed_winerror = 1, 2, 3, 5, 21, 32, 50, 67, 87, 4390, 4392, 4393\n\n        seen = set()\n        while normcase(path) not in seen:\n            seen.add(normcase(path))\n            try:\n                old_path = path\n                path = _nt_readlink(path)\n                # Links may be relative, so resolve them against their\n                # own location\n                if not isabs(path):\n                    # If it's something other than a symlink, we don't know\n                    # what it's actually going to be resolved against, so\n                    # just return the old path.\n                    if not islink(old_path):\n                        path = old_path\n                        break\n                    path = normpath(join(dirname(old_path), path))\n            except OSError as ex:\n                if ex.winerror in allowed_winerror:\n                    break\n                raise\n            except ValueError:\n                # Stop on reparse points that are not symlinks\n                break\n        return path\n\n    def _getfinalpathname_nonstrict(path):\n        # These error codes indicate that we should stop resolving the path\n        # and return the value we currently have.\n        # 1: ERROR_INVALID_FUNCTION\n        # 2: ERROR_FILE_NOT_FOUND\n        # 3: ERROR_DIRECTORY_NOT_FOUND\n        # 5: ERROR_ACCESS_DENIED\n        # 21: ERROR_NOT_READY (implies drive with no media)\n        # 32: ERROR_SHARING_VIOLATION (probably an NTFS paging file)\n        # 50: ERROR_NOT_SUPPORTED\n        # 67: ERROR_BAD_NET_NAME (implies remote server unavailable)\n        # 87: ERROR_INVALID_PARAMETER\n        # 123: ERROR_INVALID_NAME\n        # 1920: ERROR_CANT_ACCESS_FILE\n        # 1921: ERROR_CANT_RESOLVE_FILENAME (implies unfollowable symlink)\n        allowed_winerror = 1, 2, 3, 5, 21, 32, 50, 67, 87, 123, 1920, 1921\n\n        # Non-strict algorithm is to find as much of the target directory\n        # as we can and join the rest.\n        tail = ''\n        while path:\n            try:\n                path = _getfinalpathname(path)\n                return join(path, tail) if tail else path\n            except OSError as ex:\n                if ex.winerror not in allowed_winerror:\n                    raise\n                try:\n                    # The OS could not resolve this path fully, so we attempt\n                    # to follow the link ourselves. If we succeed, join the tail\n                    # and return.\n                    new_path = _readlink_deep(path)\n                    if new_path != path:\n                        return join(new_path, tail) if tail else new_path\n                except OSError:\n                    # If we fail to readlink(), let's keep traversing\n                    pass\n                path, name = split(path)\n                # TODO (bpo-38186): Request the real file name from the directory\n                # entry using FindFirstFileW. For now, we will return the path\n                # as best we have it\n                if path and not name:\n                    return path + tail\n                tail = join(name, tail) if tail else name\n        return tail\n\n    def realpath(path):\n        path = normpath(path)\n        if isinstance(path, bytes):\n            prefix = b'\\\\\\\\?\\\\'\n            unc_prefix = b'\\\\\\\\?\\\\UNC\\\\'\n            new_unc_prefix = b'\\\\\\\\'\n            cwd = os.getcwdb()\n            # bpo-38081: Special case for realpath(b'nul')\n            if normcase(path) == normcase(os.fsencode(devnull)):\n                return b'\\\\\\\\.\\\\NUL'\n        else:\n            prefix = '\\\\\\\\?\\\\'\n            unc_prefix = '\\\\\\\\?\\\\UNC\\\\'\n            new_unc_prefix = '\\\\\\\\'\n            cwd = os.getcwd()\n            # bpo-38081: Special case for realpath('nul')\n            if normcase(path) == normcase(devnull):\n                return '\\\\\\\\.\\\\NUL'\n        had_prefix = path.startswith(prefix)\n        if not had_prefix and not isabs(path):\n            path = join(cwd, path)\n        try:\n            path = _getfinalpathname(path)\n            initial_winerror = 0\n        except OSError as ex:\n            initial_winerror = ex.winerror\n            path = _getfinalpathname_nonstrict(path)\n        # The path returned by _getfinalpathname will always start with \\\\?\\ -\n        # strip off that prefix unless it was already provided on the original\n        # path.\n        if not had_prefix and path.startswith(prefix):\n            # For UNC paths, the prefix will actually be \\\\?\\UNC\\\n            # Handle that case as well.\n            if path.startswith(unc_prefix):\n                spath = new_unc_prefix + path[len(unc_prefix):]\n            else:\n                spath = path[len(prefix):]\n            # Ensure that the non-prefixed path resolves to the same path\n            try:\n                if _getfinalpathname(spath) == path:\n                    path = spath\n            except OSError as ex:\n                # If the path does not exist and originally did not exist, then\n                # strip the prefix anyway.\n                if ex.winerror == initial_winerror:\n                    path = spath\n        return path\n\n\n# Win9x family and earlier have no Unicode filename support.\nsupports_unicode_filenames = (hasattr(sys, \"getwindowsversion\") and\n                              sys.getwindowsversion()[3] >= 2)\n\ndef relpath(path, start=None):\n    \"\"\"Return a relative version of a path\"\"\"\n    path = os.fspath(path)\n    if isinstance(path, bytes):\n        sep = b'\\\\'\n        curdir = b'.'\n        pardir = b'..'\n    else:\n        sep = '\\\\'\n        curdir = '.'\n        pardir = '..'\n\n    if start is None:\n        start = curdir\n\n    if not path:\n        raise ValueError(\"no path specified\")\n\n    start = os.fspath(start)\n    try:\n        start_abs = abspath(normpath(start))\n        path_abs = abspath(normpath(path))\n        start_drive, start_rest = splitdrive(start_abs)\n        path_drive, path_rest = splitdrive(path_abs)\n        if normcase(start_drive) != normcase(path_drive):\n            raise ValueError(\"path is on mount %r, start on mount %r\" % (\n                path_drive, start_drive))\n\n        start_list = [x for x in start_rest.split(sep) if x]\n        path_list = [x for x in path_rest.split(sep) if x]\n        # Work out how much of the filepath is shared by start and path.\n        i = 0\n        for e1, e2 in zip(start_list, path_list):\n            if normcase(e1) != normcase(e2):\n                break\n            i += 1\n\n        rel_list = [pardir] * (len(start_list)-i) + path_list[i:]\n        if not rel_list:\n            return curdir\n        return join(*rel_list)\n    except (TypeError, ValueError, AttributeError, BytesWarning, DeprecationWarning):\n        genericpath._check_arg_types('relpath', path, start)\n        raise\n\n\n# Return the longest common sub-path of the sequence of paths given as input.\n# The function is case-insensitive and 'separator-insensitive', i.e. if the\n# only difference between two paths is the use of '\\' versus '/' as separator,\n# they are deemed to be equal.\n#\n# However, the returned path will have the standard '\\' separator (even if the\n# given paths had the alternative '/' separator) and will have the case of the\n# first path given in the sequence. Additionally, any trailing separator is\n# stripped from the returned path.\n\ndef commonpath(paths):\n    \"\"\"Given a sequence of path names, returns the longest common sub-path.\"\"\"\n\n    if not paths:\n        raise ValueError('commonpath() arg is an empty sequence')\n\n    paths = tuple(map(os.fspath, paths))\n    if isinstance(paths[0], bytes):\n        sep = b'\\\\'\n        altsep = b'/'\n        curdir = b'.'\n    else:\n        sep = '\\\\'\n        altsep = '/'\n        curdir = '.'\n\n    try:\n        drivesplits = [splitdrive(p.replace(altsep, sep).lower()) for p in paths]\n        split_paths = [p.split(sep) for d, p in drivesplits]\n\n        try:\n            isabs, = set(p[:1] == sep for d, p in drivesplits)\n        except ValueError:\n            raise ValueError(\"Can't mix absolute and relative paths\") from None\n\n        # Check that all drive letters or UNC paths match. The check is made only\n        # now otherwise type errors for mixing strings and bytes would not be\n        # caught.\n        if len(set(d for d, p in drivesplits)) != 1:\n            raise ValueError(\"Paths don't have the same drive\")\n\n        drive, path = splitdrive(paths[0].replace(altsep, sep))\n        common = path.split(sep)\n        common = [c for c in common if c and c != curdir]\n\n        split_paths = [[c for c in s if c and c != curdir] for s in split_paths]\n        s1 = min(split_paths)\n        s2 = max(split_paths)\n        for i, c in enumerate(s1):\n            if c != s2[i]:\n                common = common[:i]\n                break\n        else:\n            common = common[:len(s1)]\n\n        prefix = drive + sep if isabs else drive\n        return prefix + sep.join(common)\n    except (TypeError, AttributeError):\n        genericpath._check_arg_types('commonpath', *paths)\n        raise\n\n\ntry:\n    # The genericpath.isdir implementation uses os.stat and checks the mode\n    # attribute to tell whether or not the path is a directory.\n    # This is overkill on Windows - just pass the path to GetFileAttributes\n    # and check the attribute from there.\n    from nt import _isdir as isdir\nexcept ImportError:\n    # Use genericpath.isdir as imported above.\n    pass\n", 794], "C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_bootlocale.py": ["\"\"\"A minimal subset of the locale module used at interpreter startup\n(imported by the _io module), in order to reduce startup time.\n\nDon't import directly from third-party code; use the `locale` module instead!\n\"\"\"\n\nimport sys\nimport _locale\n\nif sys.platform.startswith(\"win\"):\n    def getpreferredencoding(do_setlocale=True):\n        if sys.flags.utf8_mode:\n            return 'UTF-8'\n        return _locale._getdefaultlocale()[1]\nelse:\n    try:\n        _locale.CODESET\n    except AttributeError:\n        if hasattr(sys, 'getandroidapilevel'):\n            # On Android langinfo.h and CODESET are missing, and UTF-8 is\n            # always used in mbstowcs() and wcstombs().\n            def getpreferredencoding(do_setlocale=True):\n                return 'UTF-8'\n        else:\n            def getpreferredencoding(do_setlocale=True):\n                if sys.flags.utf8_mode:\n                    return 'UTF-8'\n                # This path for legacy systems needs the more complex\n                # getdefaultlocale() function, import the full locale module.\n                import locale\n                return locale.getpreferredencoding(do_setlocale)\n    else:\n        def getpreferredencoding(do_setlocale=True):\n            assert not do_setlocale\n            if sys.flags.utf8_mode:\n                return 'UTF-8'\n            result = _locale.nl_langinfo(_locale.CODESET)\n            if not result and sys.platform == 'darwin':\n                # nl_langinfo can return an empty string\n                # when the setting has an invalid value.\n                # Default to UTF-8 in that case because\n                # UTF-8 is the default charset on OSX and\n                # returning nothing will crash the\n                # interpreter.\n                result = 'UTF-8'\n            return result\n", 46], "C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\codecs.py": ["\"\"\" codecs -- Python Codec Registry, API and helpers.\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"\n\nimport builtins\nimport sys\n\n### Registry and builtin stateless codec functions\n\ntry:\n    from _codecs import *\nexcept ImportError as why:\n    raise SystemError('Failed to load the builtin codecs: %s' % why)\n\n__all__ = [\"register\", \"lookup\", \"open\", \"EncodedFile\", \"BOM\", \"BOM_BE\",\n           \"BOM_LE\", \"BOM32_BE\", \"BOM32_LE\", \"BOM64_BE\", \"BOM64_LE\",\n           \"BOM_UTF8\", \"BOM_UTF16\", \"BOM_UTF16_LE\", \"BOM_UTF16_BE\",\n           \"BOM_UTF32\", \"BOM_UTF32_LE\", \"BOM_UTF32_BE\",\n           \"CodecInfo\", \"Codec\", \"IncrementalEncoder\", \"IncrementalDecoder\",\n           \"StreamReader\", \"StreamWriter\",\n           \"StreamReaderWriter\", \"StreamRecoder\",\n           \"getencoder\", \"getdecoder\", \"getincrementalencoder\",\n           \"getincrementaldecoder\", \"getreader\", \"getwriter\",\n           \"encode\", \"decode\", \"iterencode\", \"iterdecode\",\n           \"strict_errors\", \"ignore_errors\", \"replace_errors\",\n           \"xmlcharrefreplace_errors\",\n           \"backslashreplace_errors\", \"namereplace_errors\",\n           \"register_error\", \"lookup_error\"]\n\n### Constants\n\n#\n# Byte Order Mark (BOM = ZERO WIDTH NO-BREAK SPACE = U+FEFF)\n# and its possible byte string values\n# for UTF8/UTF16/UTF32 output and little/big endian machines\n#\n\n# UTF-8\nBOM_UTF8 = b'\\xef\\xbb\\xbf'\n\n# UTF-16, little endian\nBOM_LE = BOM_UTF16_LE = b'\\xff\\xfe'\n\n# UTF-16, big endian\nBOM_BE = BOM_UTF16_BE = b'\\xfe\\xff'\n\n# UTF-32, little endian\nBOM_UTF32_LE = b'\\xff\\xfe\\x00\\x00'\n\n# UTF-32, big endian\nBOM_UTF32_BE = b'\\x00\\x00\\xfe\\xff'\n\nif sys.byteorder == 'little':\n\n    # UTF-16, native endianness\n    BOM = BOM_UTF16 = BOM_UTF16_LE\n\n    # UTF-32, native endianness\n    BOM_UTF32 = BOM_UTF32_LE\n\nelse:\n\n    # UTF-16, native endianness\n    BOM = BOM_UTF16 = BOM_UTF16_BE\n\n    # UTF-32, native endianness\n    BOM_UTF32 = BOM_UTF32_BE\n\n# Old broken names (don't use in new code)\nBOM32_LE = BOM_UTF16_LE\nBOM32_BE = BOM_UTF16_BE\nBOM64_LE = BOM_UTF32_LE\nBOM64_BE = BOM_UTF32_BE\n\n\n### Codec base classes (defining the API)\n\nclass CodecInfo(tuple):\n    \"\"\"Codec details when looking up the codec registry\"\"\"\n\n    # Private API to allow Python 3.4 to blacklist the known non-Unicode\n    # codecs in the standard library. A more general mechanism to\n    # reliably distinguish test encodings from other codecs will hopefully\n    # be defined for Python 3.5\n    #\n    # See http://bugs.python.org/issue19619\n    _is_text_encoding = True # Assume codecs are text encodings by default\n\n    def __new__(cls, encode, decode, streamreader=None, streamwriter=None,\n        incrementalencoder=None, incrementaldecoder=None, name=None,\n        *, _is_text_encoding=None):\n        self = tuple.__new__(cls, (encode, decode, streamreader, streamwriter))\n        self.name = name\n        self.encode = encode\n        self.decode = decode\n        self.incrementalencoder = incrementalencoder\n        self.incrementaldecoder = incrementaldecoder\n        self.streamwriter = streamwriter\n        self.streamreader = streamreader\n        if _is_text_encoding is not None:\n            self._is_text_encoding = _is_text_encoding\n        return self\n\n    def __repr__(self):\n        return \"<%s.%s object for encoding %s at %#x>\" % \\\n                (self.__class__.__module__, self.__class__.__qualname__,\n                 self.name, id(self))\n\nclass Codec:\n\n    \"\"\" Defines the interface for stateless encoders/decoders.\n\n        The .encode()/.decode() methods may use different error\n        handling schemes by providing the errors argument. These\n        string values are predefined:\n\n         'strict' - raise a ValueError error (or a subclass)\n         'ignore' - ignore the character and continue with the next\n         'replace' - replace with a suitable replacement character;\n                    Python will use the official U+FFFD REPLACEMENT\n                    CHARACTER for the builtin Unicode codecs on\n                    decoding and '?' on encoding.\n         'surrogateescape' - replace with private code points U+DCnn.\n         'xmlcharrefreplace' - Replace with the appropriate XML\n                               character reference (only for encoding).\n         'backslashreplace'  - Replace with backslashed escape sequences.\n         'namereplace'       - Replace with \\\\N{...} escape sequences\n                               (only for encoding).\n\n        The set of allowed values can be extended via register_error.\n\n    \"\"\"\n    def encode(self, input, errors='strict'):\n\n        \"\"\" Encodes the object input and returns a tuple (output\n            object, length consumed).\n\n            errors defines the error handling to apply. It defaults to\n            'strict' handling.\n\n            The method may not store state in the Codec instance. Use\n            StreamWriter for codecs which have to keep state in order to\n            make encoding efficient.\n\n            The encoder must be able to handle zero length input and\n            return an empty object of the output object type in this\n            situation.\n\n        \"\"\"\n        raise NotImplementedError\n\n    def decode(self, input, errors='strict'):\n\n        \"\"\" Decodes the object input and returns a tuple (output\n            object, length consumed).\n\n            input must be an object which provides the bf_getreadbuf\n            buffer slot. Python strings, buffer objects and memory\n            mapped files are examples of objects providing this slot.\n\n            errors defines the error handling to apply. It defaults to\n            'strict' handling.\n\n            The method may not store state in the Codec instance. Use\n            StreamReader for codecs which have to keep state in order to\n            make decoding efficient.\n\n            The decoder must be able to handle zero length input and\n            return an empty object of the output object type in this\n            situation.\n\n        \"\"\"\n        raise NotImplementedError\n\nclass IncrementalEncoder(object):\n    \"\"\"\n    An IncrementalEncoder encodes an input in multiple steps. The input can\n    be passed piece by piece to the encode() method. The IncrementalEncoder\n    remembers the state of the encoding process between calls to encode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        \"\"\"\n        Creates an IncrementalEncoder instance.\n\n        The IncrementalEncoder may use different error handling schemes by\n        providing the errors keyword argument. See the module docstring\n        for a list of possible values.\n        \"\"\"\n        self.errors = errors\n        self.buffer = \"\"\n\n    def encode(self, input, final=False):\n        \"\"\"\n        Encodes input and returns the resulting object.\n        \"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"\n        Resets the encoder to the initial state.\n        \"\"\"\n\n    def getstate(self):\n        \"\"\"\n        Return the current state of the encoder.\n        \"\"\"\n        return 0\n\n    def setstate(self, state):\n        \"\"\"\n        Set the current state of the encoder. state must have been\n        returned by getstate().\n        \"\"\"\n\nclass BufferedIncrementalEncoder(IncrementalEncoder):\n    \"\"\"\n    This subclass of IncrementalEncoder can be used as the baseclass for an\n    incremental encoder if the encoder must keep some of the output in a\n    buffer between calls to encode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        IncrementalEncoder.__init__(self, errors)\n        # unencoded input that is kept between calls to encode()\n        self.buffer = \"\"\n\n    def _buffer_encode(self, input, errors, final):\n        # Overwrite this method in subclasses: It must encode input\n        # and return an (output, length consumed) tuple\n        raise NotImplementedError\n\n    def encode(self, input, final=False):\n        # encode input (taking the buffer into account)\n        data = self.buffer + input\n        (result, consumed) = self._buffer_encode(data, self.errors, final)\n        # keep unencoded input until the next call\n        self.buffer = data[consumed:]\n        return result\n\n    def reset(self):\n        IncrementalEncoder.reset(self)\n        self.buffer = \"\"\n\n    def getstate(self):\n        return self.buffer or 0\n\n    def setstate(self, state):\n        self.buffer = state or \"\"\n\nclass IncrementalDecoder(object):\n    \"\"\"\n    An IncrementalDecoder decodes an input in multiple steps. The input can\n    be passed piece by piece to the decode() method. The IncrementalDecoder\n    remembers the state of the decoding process between calls to decode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        \"\"\"\n        Create an IncrementalDecoder instance.\n\n        The IncrementalDecoder may use different error handling schemes by\n        providing the errors keyword argument. See the module docstring\n        for a list of possible values.\n        \"\"\"\n        self.errors = errors\n\n    def decode(self, input, final=False):\n        \"\"\"\n        Decode input and returns the resulting object.\n        \"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"\n        Reset the decoder to the initial state.\n        \"\"\"\n\n    def getstate(self):\n        \"\"\"\n        Return the current state of the decoder.\n\n        This must be a (buffered_input, additional_state_info) tuple.\n        buffered_input must be a bytes object containing bytes that\n        were passed to decode() that have not yet been converted.\n        additional_state_info must be a non-negative integer\n        representing the state of the decoder WITHOUT yet having\n        processed the contents of buffered_input.  In the initial state\n        and after reset(), getstate() must return (b\"\", 0).\n        \"\"\"\n        return (b\"\", 0)\n\n    def setstate(self, state):\n        \"\"\"\n        Set the current state of the decoder.\n\n        state must have been returned by getstate().  The effect of\n        setstate((b\"\", 0)) must be equivalent to reset().\n        \"\"\"\n\nclass BufferedIncrementalDecoder(IncrementalDecoder):\n    \"\"\"\n    This subclass of IncrementalDecoder can be used as the baseclass for an\n    incremental decoder if the decoder must be able to handle incomplete\n    byte sequences.\n    \"\"\"\n    def __init__(self, errors='strict'):\n        IncrementalDecoder.__init__(self, errors)\n        # undecoded input that is kept between calls to decode()\n        self.buffer = b\"\"\n\n    def _buffer_decode(self, input, errors, final):\n        # Overwrite this method in subclasses: It must decode input\n        # and return an (output, length consumed) tuple\n        raise NotImplementedError\n\n    def decode(self, input, final=False):\n        # decode input (taking the buffer into account)\n        data = self.buffer + input\n        (result, consumed) = self._buffer_decode(data, self.errors, final)\n        # keep undecoded input until the next call\n        self.buffer = data[consumed:]\n        return result\n\n    def reset(self):\n        IncrementalDecoder.reset(self)\n        self.buffer = b\"\"\n\n    def getstate(self):\n        # additional state info is always 0\n        return (self.buffer, 0)\n\n    def setstate(self, state):\n        # ignore additional state info\n        self.buffer = state[0]\n\n#\n# The StreamWriter and StreamReader class provide generic working\n# interfaces which can be used to implement new encoding submodules\n# very easily. See encodings/utf_8.py for an example on how this is\n# done.\n#\n\nclass StreamWriter(Codec):\n\n    def __init__(self, stream, errors='strict'):\n\n        \"\"\" Creates a StreamWriter instance.\n\n            stream must be a file-like object open for writing.\n\n            The StreamWriter may use different error handling\n            schemes by providing the errors keyword argument. These\n            parameters are predefined:\n\n             'strict' - raise a ValueError (or a subclass)\n             'ignore' - ignore the character and continue with the next\n             'replace'- replace with a suitable replacement character\n             'xmlcharrefreplace' - Replace with the appropriate XML\n                                   character reference.\n             'backslashreplace'  - Replace with backslashed escape\n                                   sequences.\n             'namereplace'       - Replace with \\\\N{...} escape sequences.\n\n            The set of allowed parameter values can be extended via\n            register_error.\n        \"\"\"\n        self.stream = stream\n        self.errors = errors\n\n    def write(self, object):\n\n        \"\"\" Writes the object's contents encoded to self.stream.\n        \"\"\"\n        data, consumed = self.encode(object, self.errors)\n        self.stream.write(data)\n\n    def writelines(self, list):\n\n        \"\"\" Writes the concatenated list of strings to the stream\n            using .write().\n        \"\"\"\n        self.write(''.join(list))\n\n    def reset(self):\n\n        \"\"\" Resets the codec buffers used for keeping internal state.\n\n            Calling this method should ensure that the data on the\n            output is put into a clean state, that allows appending\n            of new fresh data without having to rescan the whole\n            stream to recover state.\n\n        \"\"\"\n        pass\n\n    def seek(self, offset, whence=0):\n        self.stream.seek(offset, whence)\n        if whence == 0 and offset == 0:\n            self.reset()\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamReader(Codec):\n\n    charbuffertype = str\n\n    def __init__(self, stream, errors='strict'):\n\n        \"\"\" Creates a StreamReader instance.\n\n            stream must be a file-like object open for reading.\n\n            The StreamReader may use different error handling\n            schemes by providing the errors keyword argument. These\n            parameters are predefined:\n\n             'strict' - raise a ValueError (or a subclass)\n             'ignore' - ignore the character and continue with the next\n             'replace'- replace with a suitable replacement character\n             'backslashreplace' - Replace with backslashed escape sequences;\n\n            The set of allowed parameter values can be extended via\n            register_error.\n        \"\"\"\n        self.stream = stream\n        self.errors = errors\n        self.bytebuffer = b\"\"\n        self._empty_charbuffer = self.charbuffertype()\n        self.charbuffer = self._empty_charbuffer\n        self.linebuffer = None\n\n    def decode(self, input, errors='strict'):\n        raise NotImplementedError\n\n    def read(self, size=-1, chars=-1, firstline=False):\n\n        \"\"\" Decodes data from the stream self.stream and returns the\n            resulting object.\n\n            chars indicates the number of decoded code points or bytes to\n            return. read() will never return more data than requested,\n            but it might return less, if there is not enough available.\n\n            size indicates the approximate maximum number of decoded\n            bytes or code points to read for decoding. The decoder\n            can modify this setting as appropriate. The default value\n            -1 indicates to read and decode as much as possible.  size\n            is intended to prevent having to decode huge files in one\n            step.\n\n            If firstline is true, and a UnicodeDecodeError happens\n            after the first line terminator in the input only the first line\n            will be returned, the rest of the input will be kept until the\n            next call to read().\n\n            The method should use a greedy read strategy, meaning that\n            it should read as much data as is allowed within the\n            definition of the encoding and the given size, e.g.  if\n            optional encoding endings or state markers are available\n            on the stream, these should be read too.\n        \"\"\"\n        # If we have lines cached, first merge them back into characters\n        if self.linebuffer:\n            self.charbuffer = self._empty_charbuffer.join(self.linebuffer)\n            self.linebuffer = None\n\n        if chars < 0:\n            # For compatibility with other read() methods that take a\n            # single argument\n            chars = size\n\n        # read until we get the required number of characters (if available)\n        while True:\n            # can the request be satisfied from the character buffer?\n            if chars >= 0:\n                if len(self.charbuffer) >= chars:\n                    break\n            # we need more data\n            if size < 0:\n                newdata = self.stream.read()\n            else:\n                newdata = self.stream.read(size)\n            # decode bytes (those remaining from the last call included)\n            data = self.bytebuffer + newdata\n            if not data:\n                break\n            try:\n                newchars, decodedbytes = self.decode(data, self.errors)\n            except UnicodeDecodeError as exc:\n                if firstline:\n                    newchars, decodedbytes = \\\n                        self.decode(data[:exc.start], self.errors)\n                    lines = newchars.splitlines(keepends=True)\n                    if len(lines)<=1:\n                        raise\n                else:\n                    raise\n            # keep undecoded bytes until the next call\n            self.bytebuffer = data[decodedbytes:]\n            # put new characters in the character buffer\n            self.charbuffer += newchars\n            # there was no data available\n            if not newdata:\n                break\n        if chars < 0:\n            # Return everything we've got\n            result = self.charbuffer\n            self.charbuffer = self._empty_charbuffer\n        else:\n            # Return the first chars characters\n            result = self.charbuffer[:chars]\n            self.charbuffer = self.charbuffer[chars:]\n        return result\n\n    def readline(self, size=None, keepends=True):\n\n        \"\"\" Read one line from the input stream and return the\n            decoded data.\n\n            size, if given, is passed as size argument to the\n            read() method.\n\n        \"\"\"\n        # If we have lines cached from an earlier read, return\n        # them unconditionally\n        if self.linebuffer:\n            line = self.linebuffer[0]\n            del self.linebuffer[0]\n            if len(self.linebuffer) == 1:\n                # revert to charbuffer mode; we might need more data\n                # next time\n                self.charbuffer = self.linebuffer[0]\n                self.linebuffer = None\n            if not keepends:\n                line = line.splitlines(keepends=False)[0]\n            return line\n\n        readsize = size or 72\n        line = self._empty_charbuffer\n        # If size is given, we call read() only once\n        while True:\n            data = self.read(readsize, firstline=True)\n            if data:\n                # If we're at a \"\\r\" read one extra character (which might\n                # be a \"\\n\") to get a proper line ending. If the stream is\n                # temporarily exhausted we return the wrong line ending.\n                if (isinstance(data, str) and data.endswith(\"\\r\")) or \\\n                   (isinstance(data, bytes) and data.endswith(b\"\\r\")):\n                    data += self.read(size=1, chars=1)\n\n            line += data\n            lines = line.splitlines(keepends=True)\n            if lines:\n                if len(lines) > 1:\n                    # More than one line result; the first line is a full line\n                    # to return\n                    line = lines[0]\n                    del lines[0]\n                    if len(lines) > 1:\n                        # cache the remaining lines\n                        lines[-1] += self.charbuffer\n                        self.linebuffer = lines\n                        self.charbuffer = None\n                    else:\n                        # only one remaining line, put it back into charbuffer\n                        self.charbuffer = lines[0] + self.charbuffer\n                    if not keepends:\n                        line = line.splitlines(keepends=False)[0]\n                    break\n                line0withend = lines[0]\n                line0withoutend = lines[0].splitlines(keepends=False)[0]\n                if line0withend != line0withoutend: # We really have a line end\n                    # Put the rest back together and keep it until the next call\n                    self.charbuffer = self._empty_charbuffer.join(lines[1:]) + \\\n                                      self.charbuffer\n                    if keepends:\n                        line = line0withend\n                    else:\n                        line = line0withoutend\n                    break\n            # we didn't get anything or this was our only try\n            if not data or size is not None:\n                if line and not keepends:\n                    line = line.splitlines(keepends=False)[0]\n                break\n            if readsize < 8000:\n                readsize *= 2\n        return line\n\n    def readlines(self, sizehint=None, keepends=True):\n\n        \"\"\" Read all lines available on the input stream\n            and return them as a list.\n\n            Line breaks are implemented using the codec's decoder\n            method and are included in the list entries.\n\n            sizehint, if given, is ignored since there is no efficient\n            way to finding the true end-of-line.\n\n        \"\"\"\n        data = self.read()\n        return data.splitlines(keepends)\n\n    def reset(self):\n\n        \"\"\" Resets the codec buffers used for keeping internal state.\n\n            Note that no stream repositioning should take place.\n            This method is primarily intended to be able to recover\n            from decoding errors.\n\n        \"\"\"\n        self.bytebuffer = b\"\"\n        self.charbuffer = self._empty_charbuffer\n        self.linebuffer = None\n\n    def seek(self, offset, whence=0):\n        \"\"\" Set the input stream's current position.\n\n            Resets the codec buffers used for keeping state.\n        \"\"\"\n        self.stream.seek(offset, whence)\n        self.reset()\n\n    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        line = self.readline()\n        if line:\n            return line\n        raise StopIteration\n\n    def __iter__(self):\n        return self\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamReaderWriter:\n\n    \"\"\" StreamReaderWriter instances allow wrapping streams which\n        work in both read and write modes.\n\n        The design is such that one can use the factory functions\n        returned by the codec.lookup() function to construct the\n        instance.\n\n    \"\"\"\n    # Optional attributes set by the file wrappers below\n    encoding = 'unknown'\n\n    def __init__(self, stream, Reader, Writer, errors='strict'):\n\n        \"\"\" Creates a StreamReaderWriter instance.\n\n            stream must be a Stream-like object.\n\n            Reader, Writer must be factory functions or classes\n            providing the StreamReader, StreamWriter interface resp.\n\n            Error handling is done in the same way as defined for the\n            StreamWriter/Readers.\n\n        \"\"\"\n        self.stream = stream\n        self.reader = Reader(stream, errors)\n        self.writer = Writer(stream, errors)\n        self.errors = errors\n\n    def read(self, size=-1):\n\n        return self.reader.read(size)\n\n    def readline(self, size=None):\n\n        return self.reader.readline(size)\n\n    def readlines(self, sizehint=None):\n\n        return self.reader.readlines(sizehint)\n\n    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        return next(self.reader)\n\n    def __iter__(self):\n        return self\n\n    def write(self, data):\n\n        return self.writer.write(data)\n\n    def writelines(self, list):\n\n        return self.writer.writelines(list)\n\n    def reset(self):\n\n        self.reader.reset()\n        self.writer.reset()\n\n    def seek(self, offset, whence=0):\n        self.stream.seek(offset, whence)\n        self.reader.reset()\n        if whence == 0 and offset == 0:\n            self.writer.reset()\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    # these are needed to make \"with StreamReaderWriter(...)\" work properly\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamRecoder:\n\n    \"\"\" StreamRecoder instances translate data from one encoding to another.\n\n        They use the complete set of APIs returned by the\n        codecs.lookup() function to implement their task.\n\n        Data written to the StreamRecoder is first decoded into an\n        intermediate format (depending on the \"decode\" codec) and then\n        written to the underlying stream using an instance of the provided\n        Writer class.\n\n        In the other direction, data is read from the underlying stream using\n        a Reader instance and then encoded and returned to the caller.\n\n    \"\"\"\n    # Optional attributes set by the file wrappers below\n    data_encoding = 'unknown'\n    file_encoding = 'unknown'\n\n    def __init__(self, stream, encode, decode, Reader, Writer,\n                 errors='strict'):\n\n        \"\"\" Creates a StreamRecoder instance which implements a two-way\n            conversion: encode and decode work on the frontend (the\n            data visible to .read() and .write()) while Reader and Writer\n            work on the backend (the data in stream).\n\n            You can use these objects to do transparent\n            transcodings from e.g. latin-1 to utf-8 and back.\n\n            stream must be a file-like object.\n\n            encode and decode must adhere to the Codec interface; Reader and\n            Writer must be factory functions or classes providing the\n            StreamReader and StreamWriter interfaces resp.\n\n            Error handling is done in the same way as defined for the\n            StreamWriter/Readers.\n\n        \"\"\"\n        self.stream = stream\n        self.encode = encode\n        self.decode = decode\n        self.reader = Reader(stream, errors)\n        self.writer = Writer(stream, errors)\n        self.errors = errors\n\n    def read(self, size=-1):\n\n        data = self.reader.read(size)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def readline(self, size=None):\n\n        if size is None:\n            data = self.reader.readline()\n        else:\n            data = self.reader.readline(size)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def readlines(self, sizehint=None):\n\n        data = self.reader.read()\n        data, bytesencoded = self.encode(data, self.errors)\n        return data.splitlines(keepends=True)\n\n    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        data = next(self.reader)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def __iter__(self):\n        return self\n\n    def write(self, data):\n\n        data, bytesdecoded = self.decode(data, self.errors)\n        return self.writer.write(data)\n\n    def writelines(self, list):\n\n        data = b''.join(list)\n        data, bytesdecoded = self.decode(data, self.errors)\n        return self.writer.write(data)\n\n    def reset(self):\n\n        self.reader.reset()\n        self.writer.reset()\n\n    def seek(self, offset, whence=0):\n        # Seeks must be propagated to both the readers and writers\n        # as they might need to reset their internal buffers.\n        self.reader.seek(offset, whence)\n        self.writer.seek(offset, whence)\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n### Shortcuts\n\ndef open(filename, mode='r', encoding=None, errors='strict', buffering=-1):\n\n    \"\"\" Open an encoded file using the given mode and return\n        a wrapped version providing transparent encoding/decoding.\n\n        Note: The wrapped version will only accept the object format\n        defined by the codecs, i.e. Unicode objects for most builtin\n        codecs. Output is also codec dependent and will usually be\n        Unicode as well.\n\n        Underlying encoded files are always opened in binary mode.\n        The default file mode is 'r', meaning to open the file in read mode.\n\n        encoding specifies the encoding which is to be used for the\n        file.\n\n        errors may be given to define the error handling. It defaults\n        to 'strict' which causes ValueErrors to be raised in case an\n        encoding error occurs.\n\n        buffering has the same meaning as for the builtin open() API.\n        It defaults to -1 which means that the default buffer size will\n        be used.\n\n        The returned wrapped file object provides an extra attribute\n        .encoding which allows querying the used encoding. This\n        attribute is only available if an encoding was specified as\n        parameter.\n\n    \"\"\"\n    if encoding is not None and \\\n       'b' not in mode:\n        # Force opening of the file in binary mode\n        mode = mode + 'b'\n    file = builtins.open(filename, mode, buffering)\n    if encoding is None:\n        return file\n\n    try:\n        info = lookup(encoding)\n        srw = StreamReaderWriter(file, info.streamreader, info.streamwriter, errors)\n        # Add attributes to simplify introspection\n        srw.encoding = encoding\n        return srw\n    except:\n        file.close()\n        raise\n\ndef EncodedFile(file, data_encoding, file_encoding=None, errors='strict'):\n\n    \"\"\" Return a wrapped version of file which provides transparent\n        encoding translation.\n\n        Data written to the wrapped file is decoded according\n        to the given data_encoding and then encoded to the underlying\n        file using file_encoding. The intermediate data type\n        will usually be Unicode but depends on the specified codecs.\n\n        Bytes read from the file are decoded using file_encoding and then\n        passed back to the caller encoded using data_encoding.\n\n        If file_encoding is not given, it defaults to data_encoding.\n\n        errors may be given to define the error handling. It defaults\n        to 'strict' which causes ValueErrors to be raised in case an\n        encoding error occurs.\n\n        The returned wrapped file object provides two extra attributes\n        .data_encoding and .file_encoding which reflect the given\n        parameters of the same name. The attributes can be used for\n        introspection by Python programs.\n\n    \"\"\"\n    if file_encoding is None:\n        file_encoding = data_encoding\n    data_info = lookup(data_encoding)\n    file_info = lookup(file_encoding)\n    sr = StreamRecoder(file, data_info.encode, data_info.decode,\n                       file_info.streamreader, file_info.streamwriter, errors)\n    # Add attributes to simplify introspection\n    sr.data_encoding = data_encoding\n    sr.file_encoding = file_encoding\n    return sr\n\n### Helpers for codec lookup\n\ndef getencoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its encoder function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).encode\n\ndef getdecoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its decoder function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).decode\n\ndef getincrementalencoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its IncrementalEncoder class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found\n        or the codecs doesn't provide an incremental encoder.\n\n    \"\"\"\n    encoder = lookup(encoding).incrementalencoder\n    if encoder is None:\n        raise LookupError(encoding)\n    return encoder\n\ndef getincrementaldecoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its IncrementalDecoder class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found\n        or the codecs doesn't provide an incremental decoder.\n\n    \"\"\"\n    decoder = lookup(encoding).incrementaldecoder\n    if decoder is None:\n        raise LookupError(encoding)\n    return decoder\n\ndef getreader(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its StreamReader class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).streamreader\n\ndef getwriter(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its StreamWriter class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).streamwriter\n\ndef iterencode(iterator, encoding, errors='strict', **kwargs):\n    \"\"\"\n    Encoding iterator.\n\n    Encodes the input strings from the iterator using an IncrementalEncoder.\n\n    errors and kwargs are passed through to the IncrementalEncoder\n    constructor.\n    \"\"\"\n    encoder = getincrementalencoder(encoding)(errors, **kwargs)\n    for input in iterator:\n        output = encoder.encode(input)\n        if output:\n            yield output\n    output = encoder.encode(\"\", True)\n    if output:\n        yield output\n\ndef iterdecode(iterator, encoding, errors='strict', **kwargs):\n    \"\"\"\n    Decoding iterator.\n\n    Decodes the input strings from the iterator using an IncrementalDecoder.\n\n    errors and kwargs are passed through to the IncrementalDecoder\n    constructor.\n    \"\"\"\n    decoder = getincrementaldecoder(encoding)(errors, **kwargs)\n    for input in iterator:\n        output = decoder.decode(input)\n        if output:\n            yield output\n    output = decoder.decode(b\"\", True)\n    if output:\n        yield output\n\n### Helpers for charmap-based codecs\n\ndef make_identity_dict(rng):\n\n    \"\"\" make_identity_dict(rng) -> dict\n\n        Return a dictionary where elements of the rng sequence are\n        mapped to themselves.\n\n    \"\"\"\n    return {i:i for i in rng}\n\ndef make_encoding_map(decoding_map):\n\n    \"\"\" Creates an encoding map from a decoding map.\n\n        If a target mapping in the decoding map occurs multiple\n        times, then that target is mapped to None (undefined mapping),\n        causing an exception when encountered by the charmap codec\n        during translation.\n\n        One example where this happens is cp875.py which decodes\n        multiple character to \\\\u001a.\n\n    \"\"\"\n    m = {}\n    for k,v in decoding_map.items():\n        if not v in m:\n            m[v] = k\n        else:\n            m[v] = None\n    return m\n\n### error handlers\n\ntry:\n    strict_errors = lookup_error(\"strict\")\n    ignore_errors = lookup_error(\"ignore\")\n    replace_errors = lookup_error(\"replace\")\n    xmlcharrefreplace_errors = lookup_error(\"xmlcharrefreplace\")\n    backslashreplace_errors = lookup_error(\"backslashreplace\")\n    namereplace_errors = lookup_error(\"namereplace\")\nexcept LookupError:\n    # In --disable-unicode builds, these error handler are missing\n    strict_errors = None\n    ignore_errors = None\n    replace_errors = None\n    xmlcharrefreplace_errors = None\n    backslashreplace_errors = None\n    namereplace_errors = None\n\n# Tell modulefinder that using codecs probably needs the encodings\n# package\n_false = 0\nif _false:\n    import encodings\n\n### Tests\n\nif __name__ == '__main__':\n\n    # Make stdout translate Latin-1 output into UTF-8 output\n    sys.stdout = EncodedFile(sys.stdout, 'latin-1', 'utf-8')\n\n    # Have stdin translate Latin-1 input into UTF-8 input\n    sys.stdin = EncodedFile(sys.stdin, 'utf-8', 'latin-1')\n", 1126], "C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\encodings\\cp1252.py": ["\"\"\" Python Character Mapping Codec cp1252 generated from 'MAPPINGS/VENDORS/MICSFT/WINDOWS/CP1252.TXT' with gencodec.py.\n\n\"\"\"#\"\n\nimport codecs\n\n### Codec APIs\n\nclass Codec(codecs.Codec):\n\n    def encode(self,input,errors='strict'):\n        return codecs.charmap_encode(input,errors,encoding_table)\n\n    def decode(self,input,errors='strict'):\n        return codecs.charmap_decode(input,errors,decoding_table)\n\nclass IncrementalEncoder(codecs.IncrementalEncoder):\n    def encode(self, input, final=False):\n        return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n\nclass IncrementalDecoder(codecs.IncrementalDecoder):\n    def decode(self, input, final=False):\n        return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n\nclass StreamWriter(Codec,codecs.StreamWriter):\n    pass\n\nclass StreamReader(Codec,codecs.StreamReader):\n    pass\n\n### encodings module API\n\ndef getregentry():\n    return codecs.CodecInfo(\n        name='cp1252',\n        encode=Codec().encode,\n        decode=Codec().decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamreader=StreamReader,\n        streamwriter=StreamWriter,\n    )\n\n\n### Decoding Table\n\ndecoding_table = (\n    '\\x00'     #  0x00 -> NULL\n    '\\x01'     #  0x01 -> START OF HEADING\n    '\\x02'     #  0x02 -> START OF TEXT\n    '\\x03'     #  0x03 -> END OF TEXT\n    '\\x04'     #  0x04 -> END OF TRANSMISSION\n    '\\x05'     #  0x05 -> ENQUIRY\n    '\\x06'     #  0x06 -> ACKNOWLEDGE\n    '\\x07'     #  0x07 -> BELL\n    '\\x08'     #  0x08 -> BACKSPACE\n    '\\t'       #  0x09 -> HORIZONTAL TABULATION\n    '\\n'       #  0x0A -> LINE FEED\n    '\\x0b'     #  0x0B -> VERTICAL TABULATION\n    '\\x0c'     #  0x0C -> FORM FEED\n    '\\r'       #  0x0D -> CARRIAGE RETURN\n    '\\x0e'     #  0x0E -> SHIFT OUT\n    '\\x0f'     #  0x0F -> SHIFT IN\n    '\\x10'     #  0x10 -> DATA LINK ESCAPE\n    '\\x11'     #  0x11 -> DEVICE CONTROL ONE\n    '\\x12'     #  0x12 -> DEVICE CONTROL TWO\n    '\\x13'     #  0x13 -> DEVICE CONTROL THREE\n    '\\x14'     #  0x14 -> DEVICE CONTROL FOUR\n    '\\x15'     #  0x15 -> NEGATIVE ACKNOWLEDGE\n    '\\x16'     #  0x16 -> SYNCHRONOUS IDLE\n    '\\x17'     #  0x17 -> END OF TRANSMISSION BLOCK\n    '\\x18'     #  0x18 -> CANCEL\n    '\\x19'     #  0x19 -> END OF MEDIUM\n    '\\x1a'     #  0x1A -> SUBSTITUTE\n    '\\x1b'     #  0x1B -> ESCAPE\n    '\\x1c'     #  0x1C -> FILE SEPARATOR\n    '\\x1d'     #  0x1D -> GROUP SEPARATOR\n    '\\x1e'     #  0x1E -> RECORD SEPARATOR\n    '\\x1f'     #  0x1F -> UNIT SEPARATOR\n    ' '        #  0x20 -> SPACE\n    '!'        #  0x21 -> EXCLAMATION MARK\n    '\"'        #  0x22 -> QUOTATION MARK\n    '#'        #  0x23 -> NUMBER SIGN\n    '$'        #  0x24 -> DOLLAR SIGN\n    '%'        #  0x25 -> PERCENT SIGN\n    '&'        #  0x26 -> AMPERSAND\n    \"'\"        #  0x27 -> APOSTROPHE\n    '('        #  0x28 -> LEFT PARENTHESIS\n    ')'        #  0x29 -> RIGHT PARENTHESIS\n    '*'        #  0x2A -> ASTERISK\n    '+'        #  0x2B -> PLUS SIGN\n    ','        #  0x2C -> COMMA\n    '-'        #  0x2D -> HYPHEN-MINUS\n    '.'        #  0x2E -> FULL STOP\n    '/'        #  0x2F -> SOLIDUS\n    '0'        #  0x30 -> DIGIT ZERO\n    '1'        #  0x31 -> DIGIT ONE\n    '2'        #  0x32 -> DIGIT TWO\n    '3'        #  0x33 -> DIGIT THREE\n    '4'        #  0x34 -> DIGIT FOUR\n    '5'        #  0x35 -> DIGIT FIVE\n    '6'        #  0x36 -> DIGIT SIX\n    '7'        #  0x37 -> DIGIT SEVEN\n    '8'        #  0x38 -> DIGIT EIGHT\n    '9'        #  0x39 -> DIGIT NINE\n    ':'        #  0x3A -> COLON\n    ';'        #  0x3B -> SEMICOLON\n    '<'        #  0x3C -> LESS-THAN SIGN\n    '='        #  0x3D -> EQUALS SIGN\n    '>'        #  0x3E -> GREATER-THAN SIGN\n    '?'        #  0x3F -> QUESTION MARK\n    '@'        #  0x40 -> COMMERCIAL AT\n    'A'        #  0x41 -> LATIN CAPITAL LETTER A\n    'B'        #  0x42 -> LATIN CAPITAL LETTER B\n    'C'        #  0x43 -> LATIN CAPITAL LETTER C\n    'D'        #  0x44 -> LATIN CAPITAL LETTER D\n    'E'        #  0x45 -> LATIN CAPITAL LETTER E\n    'F'        #  0x46 -> LATIN CAPITAL LETTER F\n    'G'        #  0x47 -> LATIN CAPITAL LETTER G\n    'H'        #  0x48 -> LATIN CAPITAL LETTER H\n    'I'        #  0x49 -> LATIN CAPITAL LETTER I\n    'J'        #  0x4A -> LATIN CAPITAL LETTER J\n    'K'        #  0x4B -> LATIN CAPITAL LETTER K\n    'L'        #  0x4C -> LATIN CAPITAL LETTER L\n    'M'        #  0x4D -> LATIN CAPITAL LETTER M\n    'N'        #  0x4E -> LATIN CAPITAL LETTER N\n    'O'        #  0x4F -> LATIN CAPITAL LETTER O\n    'P'        #  0x50 -> LATIN CAPITAL LETTER P\n    'Q'        #  0x51 -> LATIN CAPITAL LETTER Q\n    'R'        #  0x52 -> LATIN CAPITAL LETTER R\n    'S'        #  0x53 -> LATIN CAPITAL LETTER S\n    'T'        #  0x54 -> LATIN CAPITAL LETTER T\n    'U'        #  0x55 -> LATIN CAPITAL LETTER U\n    'V'        #  0x56 -> LATIN CAPITAL LETTER V\n    'W'        #  0x57 -> LATIN CAPITAL LETTER W\n    'X'        #  0x58 -> LATIN CAPITAL LETTER X\n    'Y'        #  0x59 -> LATIN CAPITAL LETTER Y\n    'Z'        #  0x5A -> LATIN CAPITAL LETTER Z\n    '['        #  0x5B -> LEFT SQUARE BRACKET\n    '\\\\'       #  0x5C -> REVERSE SOLIDUS\n    ']'        #  0x5D -> RIGHT SQUARE BRACKET\n    '^'        #  0x5E -> CIRCUMFLEX ACCENT\n    '_'        #  0x5F -> LOW LINE\n    '`'        #  0x60 -> GRAVE ACCENT\n    'a'        #  0x61 -> LATIN SMALL LETTER A\n    'b'        #  0x62 -> LATIN SMALL LETTER B\n    'c'        #  0x63 -> LATIN SMALL LETTER C\n    'd'        #  0x64 -> LATIN SMALL LETTER D\n    'e'        #  0x65 -> LATIN SMALL LETTER E\n    'f'        #  0x66 -> LATIN SMALL LETTER F\n    'g'        #  0x67 -> LATIN SMALL LETTER G\n    'h'        #  0x68 -> LATIN SMALL LETTER H\n    'i'        #  0x69 -> LATIN SMALL LETTER I\n    'j'        #  0x6A -> LATIN SMALL LETTER J\n    'k'        #  0x6B -> LATIN SMALL LETTER K\n    'l'        #  0x6C -> LATIN SMALL LETTER L\n    'm'        #  0x6D -> LATIN SMALL LETTER M\n    'n'        #  0x6E -> LATIN SMALL LETTER N\n    'o'        #  0x6F -> LATIN SMALL LETTER O\n    'p'        #  0x70 -> LATIN SMALL LETTER P\n    'q'        #  0x71 -> LATIN SMALL LETTER Q\n    'r'        #  0x72 -> LATIN SMALL LETTER R\n    's'        #  0x73 -> LATIN SMALL LETTER S\n    't'        #  0x74 -> LATIN SMALL LETTER T\n    'u'        #  0x75 -> LATIN SMALL LETTER U\n    'v'        #  0x76 -> LATIN SMALL LETTER V\n    'w'        #  0x77 -> LATIN SMALL LETTER W\n    'x'        #  0x78 -> LATIN SMALL LETTER X\n    'y'        #  0x79 -> LATIN SMALL LETTER Y\n    'z'        #  0x7A -> LATIN SMALL LETTER Z\n    '{'        #  0x7B -> LEFT CURLY BRACKET\n    '|'        #  0x7C -> VERTICAL LINE\n    '}'        #  0x7D -> RIGHT CURLY BRACKET\n    '~'        #  0x7E -> TILDE\n    '\\x7f'     #  0x7F -> DELETE\n    '\\u20ac'   #  0x80 -> EURO SIGN\n    '\\ufffe'   #  0x81 -> UNDEFINED\n    '\\u201a'   #  0x82 -> SINGLE LOW-9 QUOTATION MARK\n    '\\u0192'   #  0x83 -> LATIN SMALL LETTER F WITH HOOK\n    '\\u201e'   #  0x84 -> DOUBLE LOW-9 QUOTATION MARK\n    '\\u2026'   #  0x85 -> HORIZONTAL ELLIPSIS\n    '\\u2020'   #  0x86 -> DAGGER\n    '\\u2021'   #  0x87 -> DOUBLE DAGGER\n    '\\u02c6'   #  0x88 -> MODIFIER LETTER CIRCUMFLEX ACCENT\n    '\\u2030'   #  0x89 -> PER MILLE SIGN\n    '\\u0160'   #  0x8A -> LATIN CAPITAL LETTER S WITH CARON\n    '\\u2039'   #  0x8B -> SINGLE LEFT-POINTING ANGLE QUOTATION MARK\n    '\\u0152'   #  0x8C -> LATIN CAPITAL LIGATURE OE\n    '\\ufffe'   #  0x8D -> UNDEFINED\n    '\\u017d'   #  0x8E -> LATIN CAPITAL LETTER Z WITH CARON\n    '\\ufffe'   #  0x8F -> UNDEFINED\n    '\\ufffe'   #  0x90 -> UNDEFINED\n    '\\u2018'   #  0x91 -> LEFT SINGLE QUOTATION MARK\n    '\\u2019'   #  0x92 -> RIGHT SINGLE QUOTATION MARK\n    '\\u201c'   #  0x93 -> LEFT DOUBLE QUOTATION MARK\n    '\\u201d'   #  0x94 -> RIGHT DOUBLE QUOTATION MARK\n    '\\u2022'   #  0x95 -> BULLET\n    '\\u2013'   #  0x96 -> EN DASH\n    '\\u2014'   #  0x97 -> EM DASH\n    '\\u02dc'   #  0x98 -> SMALL TILDE\n    '\\u2122'   #  0x99 -> TRADE MARK SIGN\n    '\\u0161'   #  0x9A -> LATIN SMALL LETTER S WITH CARON\n    '\\u203a'   #  0x9B -> SINGLE RIGHT-POINTING ANGLE QUOTATION MARK\n    '\\u0153'   #  0x9C -> LATIN SMALL LIGATURE OE\n    '\\ufffe'   #  0x9D -> UNDEFINED\n    '\\u017e'   #  0x9E -> LATIN SMALL LETTER Z WITH CARON\n    '\\u0178'   #  0x9F -> LATIN CAPITAL LETTER Y WITH DIAERESIS\n    '\\xa0'     #  0xA0 -> NO-BREAK SPACE\n    '\\xa1'     #  0xA1 -> INVERTED EXCLAMATION MARK\n    '\\xa2'     #  0xA2 -> CENT SIGN\n    '\\xa3'     #  0xA3 -> POUND SIGN\n    '\\xa4'     #  0xA4 -> CURRENCY SIGN\n    '\\xa5'     #  0xA5 -> YEN SIGN\n    '\\xa6'     #  0xA6 -> BROKEN BAR\n    '\\xa7'     #  0xA7 -> SECTION SIGN\n    '\\xa8'     #  0xA8 -> DIAERESIS\n    '\\xa9'     #  0xA9 -> COPYRIGHT SIGN\n    '\\xaa'     #  0xAA -> FEMININE ORDINAL INDICATOR\n    '\\xab'     #  0xAB -> LEFT-POINTING DOUBLE ANGLE QUOTATION MARK\n    '\\xac'     #  0xAC -> NOT SIGN\n    '\\xad'     #  0xAD -> SOFT HYPHEN\n    '\\xae'     #  0xAE -> REGISTERED SIGN\n    '\\xaf'     #  0xAF -> MACRON\n    '\\xb0'     #  0xB0 -> DEGREE SIGN\n    '\\xb1'     #  0xB1 -> PLUS-MINUS SIGN\n    '\\xb2'     #  0xB2 -> SUPERSCRIPT TWO\n    '\\xb3'     #  0xB3 -> SUPERSCRIPT THREE\n    '\\xb4'     #  0xB4 -> ACUTE ACCENT\n    '\\xb5'     #  0xB5 -> MICRO SIGN\n    '\\xb6'     #  0xB6 -> PILCROW SIGN\n    '\\xb7'     #  0xB7 -> MIDDLE DOT\n    '\\xb8'     #  0xB8 -> CEDILLA\n    '\\xb9'     #  0xB9 -> SUPERSCRIPT ONE\n    '\\xba'     #  0xBA -> MASCULINE ORDINAL INDICATOR\n    '\\xbb'     #  0xBB -> RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK\n    '\\xbc'     #  0xBC -> VULGAR FRACTION ONE QUARTER\n    '\\xbd'     #  0xBD -> VULGAR FRACTION ONE HALF\n    '\\xbe'     #  0xBE -> VULGAR FRACTION THREE QUARTERS\n    '\\xbf'     #  0xBF -> INVERTED QUESTION MARK\n    '\\xc0'     #  0xC0 -> LATIN CAPITAL LETTER A WITH GRAVE\n    '\\xc1'     #  0xC1 -> LATIN CAPITAL LETTER A WITH ACUTE\n    '\\xc2'     #  0xC2 -> LATIN CAPITAL LETTER A WITH CIRCUMFLEX\n    '\\xc3'     #  0xC3 -> LATIN CAPITAL LETTER A WITH TILDE\n    '\\xc4'     #  0xC4 -> LATIN CAPITAL LETTER A WITH DIAERESIS\n    '\\xc5'     #  0xC5 -> LATIN CAPITAL LETTER A WITH RING ABOVE\n    '\\xc6'     #  0xC6 -> LATIN CAPITAL LETTER AE\n    '\\xc7'     #  0xC7 -> LATIN CAPITAL LETTER C WITH CEDILLA\n    '\\xc8'     #  0xC8 -> LATIN CAPITAL LETTER E WITH GRAVE\n    '\\xc9'     #  0xC9 -> LATIN CAPITAL LETTER E WITH ACUTE\n    '\\xca'     #  0xCA -> LATIN CAPITAL LETTER E WITH CIRCUMFLEX\n    '\\xcb'     #  0xCB -> LATIN CAPITAL LETTER E WITH DIAERESIS\n    '\\xcc'     #  0xCC -> LATIN CAPITAL LETTER I WITH GRAVE\n    '\\xcd'     #  0xCD -> LATIN CAPITAL LETTER I WITH ACUTE\n    '\\xce'     #  0xCE -> LATIN CAPITAL LETTER I WITH CIRCUMFLEX\n    '\\xcf'     #  0xCF -> LATIN CAPITAL LETTER I WITH DIAERESIS\n    '\\xd0'     #  0xD0 -> LATIN CAPITAL LETTER ETH\n    '\\xd1'     #  0xD1 -> LATIN CAPITAL LETTER N WITH TILDE\n    '\\xd2'     #  0xD2 -> LATIN CAPITAL LETTER O WITH GRAVE\n    '\\xd3'     #  0xD3 -> LATIN CAPITAL LETTER O WITH ACUTE\n    '\\xd4'     #  0xD4 -> LATIN CAPITAL LETTER O WITH CIRCUMFLEX\n    '\\xd5'     #  0xD5 -> LATIN CAPITAL LETTER O WITH TILDE\n    '\\xd6'     #  0xD6 -> LATIN CAPITAL LETTER O WITH DIAERESIS\n    '\\xd7'     #  0xD7 -> MULTIPLICATION SIGN\n    '\\xd8'     #  0xD8 -> LATIN CAPITAL LETTER O WITH STROKE\n    '\\xd9'     #  0xD9 -> LATIN CAPITAL LETTER U WITH GRAVE\n    '\\xda'     #  0xDA -> LATIN CAPITAL LETTER U WITH ACUTE\n    '\\xdb'     #  0xDB -> LATIN CAPITAL LETTER U WITH CIRCUMFLEX\n    '\\xdc'     #  0xDC -> LATIN CAPITAL LETTER U WITH DIAERESIS\n    '\\xdd'     #  0xDD -> LATIN CAPITAL LETTER Y WITH ACUTE\n    '\\xde'     #  0xDE -> LATIN CAPITAL LETTER THORN\n    '\\xdf'     #  0xDF -> LATIN SMALL LETTER SHARP S\n    '\\xe0'     #  0xE0 -> LATIN SMALL LETTER A WITH GRAVE\n    '\\xe1'     #  0xE1 -> LATIN SMALL LETTER A WITH ACUTE\n    '\\xe2'     #  0xE2 -> LATIN SMALL LETTER A WITH CIRCUMFLEX\n    '\\xe3'     #  0xE3 -> LATIN SMALL LETTER A WITH TILDE\n    '\\xe4'     #  0xE4 -> LATIN SMALL LETTER A WITH DIAERESIS\n    '\\xe5'     #  0xE5 -> LATIN SMALL LETTER A WITH RING ABOVE\n    '\\xe6'     #  0xE6 -> LATIN SMALL LETTER AE\n    '\\xe7'     #  0xE7 -> LATIN SMALL LETTER C WITH CEDILLA\n    '\\xe8'     #  0xE8 -> LATIN SMALL LETTER E WITH GRAVE\n    '\\xe9'     #  0xE9 -> LATIN SMALL LETTER E WITH ACUTE\n    '\\xea'     #  0xEA -> LATIN SMALL LETTER E WITH CIRCUMFLEX\n    '\\xeb'     #  0xEB -> LATIN SMALL LETTER E WITH DIAERESIS\n    '\\xec'     #  0xEC -> LATIN SMALL LETTER I WITH GRAVE\n    '\\xed'     #  0xED -> LATIN SMALL LETTER I WITH ACUTE\n    '\\xee'     #  0xEE -> LATIN SMALL LETTER I WITH CIRCUMFLEX\n    '\\xef'     #  0xEF -> LATIN SMALL LETTER I WITH DIAERESIS\n    '\\xf0'     #  0xF0 -> LATIN SMALL LETTER ETH\n    '\\xf1'     #  0xF1 -> LATIN SMALL LETTER N WITH TILDE\n    '\\xf2'     #  0xF2 -> LATIN SMALL LETTER O WITH GRAVE\n    '\\xf3'     #  0xF3 -> LATIN SMALL LETTER O WITH ACUTE\n    '\\xf4'     #  0xF4 -> LATIN SMALL LETTER O WITH CIRCUMFLEX\n    '\\xf5'     #  0xF5 -> LATIN SMALL LETTER O WITH TILDE\n    '\\xf6'     #  0xF6 -> LATIN SMALL LETTER O WITH DIAERESIS\n    '\\xf7'     #  0xF7 -> DIVISION SIGN\n    '\\xf8'     #  0xF8 -> LATIN SMALL LETTER O WITH STROKE\n    '\\xf9'     #  0xF9 -> LATIN SMALL LETTER U WITH GRAVE\n    '\\xfa'     #  0xFA -> LATIN SMALL LETTER U WITH ACUTE\n    '\\xfb'     #  0xFB -> LATIN SMALL LETTER U WITH CIRCUMFLEX\n    '\\xfc'     #  0xFC -> LATIN SMALL LETTER U WITH DIAERESIS\n    '\\xfd'     #  0xFD -> LATIN SMALL LETTER Y WITH ACUTE\n    '\\xfe'     #  0xFE -> LATIN SMALL LETTER THORN\n    '\\xff'     #  0xFF -> LATIN SMALL LETTER Y WITH DIAERESIS\n)\n\n### Encoding table\nencoding_table=codecs.charmap_build(decoding_table)\n", 307], "C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py": ["'''\nCS337 Spring 2022 - Operating Systems Prof. Al Madi\nProject 5 - Multitasking\nserial_code_4.py\nMatthew Bass\n03/13/2022\n\nThis is a file to count the words and do other functions with the the\nreddit's comments data\n\nAnother version much more simplified\n\nRefactored to process all the files one at a time\n\nIt does the following:\n    - Read in the Reddit comments files\n\n    - Count each word\n\n    - Print the 10 most common words in each file\n\n    - Print the frequency of a given word in each year to observe word trends\n      (frequency = word_count / number_of_words)\n\n    - Time your \u201ccommon word\u201d and \u201cword trend\u201d code reliably for comparison\n'''\n\nimport os\nimport re\nimport time\nfrom collections import Counter\n\n'''\nHelper FunctionS\n'''\n\n\n\n'''\nFunctions to parse the raw data and clean it\n'''\n\n\ndef readInData(data_file: str, data_path: str) -> str:\n    '''\n    A Function to read in the raw data from the file as a string\n\n    Args:\n        data_file (str): the name of the file\n        data_path (str): the path to the file\n\n    Returns:\n        data (str): the raw string of the data\n\n    '''\n    with open(data_path+data_file, 'r') as file:\n        data = file.read()\n    return data\n\n\ndef cleanAndTokenize(data : str) -> list:\n    '''\n    A Function to clean and tokenize the raw string\n    Args:\n        data (str): the raw string of the data\n\n    Returns:\n        tokens (list): a list of the cleaned word tokens\n\n    '''\n    # Remove extra spaces, tabs, and line breaks\n    data = \" \".join(data.split())\n\n    # keep only words\n    data = re.sub(r\"[^A-Za-z\\s]+\", \"\", data).split(\" \")\n    return data\n\ndef getWordCount(data_file: str, data_path: str) -> Counter:\n    '''\n    A Function to get the word count from specified file\n\n    Args:\n        data_file (str): the name of the file\n        data_path (str): the path to the file\n\n    Returns:\n        word_count(Counter): A counter of the files word count\n\n\n    '''\n    data = readInData(data_file,data_path)\n    data = cleanAndTokenize(data)\n    return Counter(data)\n\n\ndef getWordFrequencies(word_count : Counter) -> dict:\n    '''\n    A Function to get the word frequency from the counter\n\n    Args:\n        word_count (Counter):\n\n    Returns:\n        word_frequencies (dict): a dict of the word frequencies\n    '''\n    # Initialize word frequencies dict\n    word_frequencies = {}\n\n    # Get the total word count\n    total_count = sum(word_count.values())\n\n\n    for word, count in word_count.items():\n        word_frequencies[word] = (count / total_count)\n\n\n    return word_frequencies\n\n\n\n\ndef getWordData(data_file: str, data_path: str, debug = True) -> dict:\n    '''\n    Main running function to get all the word count data\n    :param data_file: the name of the file\n    :param data_path: the path to the file\n    :param debug: Bool if true debug staatement printed\n\n    :return word_data: a tuple of the word counts and word frequencies\n\n    '''\n\n\n    if debug:\n        t_start_time = time.perf_counter()\n        print(f\"START getWordData {data_file}\")\n\n    # Get the word counter\n    word_count = getWordCount(data_file,data_path)\n\n    if debug:\n        t_end_time = time.perf_counter()\n        t_total_time = t_end_time - t_start_time\n        print(f\"\\nEND getWordData {data_file}! \" +\n              f\"\\n\\tIt took {t_total_time} sec(s) to run in total!\\n\")\n\n    # Get the word frequencies\n    word_frequencies = getWordFrequencies(word_count)\n\n    # Make the word data object\n    word_data = (word_count, word_frequencies)\n\n    return word_data\n\n\ndef printTopNWords(files_data: dict, top_n_words: int = 10):\n    '''\n    A Function to print out the top N words over the years\n    Args:\n        files_data (dict): the dict of word data\n        top_n_words (int): the top n words to print out\n\n    Returns:\n\n    '''\n\n    # Get the top words from all the years\n    top_words = {}\n    for file_name, data in files_data.items():\n        n_words = data[0].most_common(top_n_words)\n\n        top_words[re.sub(\"[^0-9]\", \"\", file_name)] = n_words\n\n    print(f\"\\nThe top {top_n_words} words for each year (word, count)\")\n    print(f\"In Order Top: {[x+1 for x in range(top_n_words)]}\")\n    for year, tw in top_words.items():\n        print(f\"{year.upper()}. {tw}\")\n\n\n    return\n\n\ndef printWordFrequencyOverYears(files_data: dict, word: str):\n    '''\n    A Function to print out the top N words over the years\n    Args:\n        files_data (dict): the dict of word data\n        word (str): the word whos frequency to print out\n\n    Returns:\n\n    '''\n\n    # Get the word frequency from over the years\n    word_freq = {}\n    for file_name, data in files_data.items():\n        word_freqs = data[1]\n\n        # If the word is in the frequencies for that year add it\n        if word in word_freqs.keys():\n\n            word_freq[re.sub(\"[^0-9]\", \"\", file_name)] = word_freqs[word]\n\n        #if it isnt the frequency is 0\n        else:\n            word_freq[re.sub(\"[^0-9]\", \"\", file_name)] = 0\n\n    # Print the Header\n    print(f\"\\n The frequency of {word} over the years is:\")\n    print(f\"\\t {word_freq}\")\n    return\n\n\ndef runWordCounter() -> dict:\n    '''\n    Main function to run the word counter\n\n    Timing of funtions will be done in nanoseconds\n\n    :param data_type: a str of the data type to use. Valid types list, np, gpu\n    :return: a dictionary of all the files raw strings\n    '''\n\n\n    # Get the current file directory path of the file.\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n\n    # Make the filepath the reddit comments (data) path\n\n    data_path = os.path.join(dir_path, os.path.normcase(\"data/\"))\n\n    # Get all the data files\n    data_files = os.listdir(data_path)\n\n    #calculate the word data for each data file\n    files_data = {}\n    getWordData_start_time = time.perf_counter()\n    for data_file in data_files:\n        files_data[data_file] = getWordData(data_file,data_path)\n    getWordData_end_time = time.perf_counter()\n    getWordData_total_time = getWordData_end_time - getWordData_start_time\n    print(f\"\\nWord Counter  is done! \" +\n          f\"\\n\\tIt took {getWordData_total_time} sec(s) to run in total!\\n\")\n\n    # Print the top 10 words\n    printTopNWords(files_data)\n\n    # Print word frequency of the\n    printWordFrequencyOverYears(files_data,\"the\")\n\n    return\n\n\n# Main function to run the script\ndef main():\n\n\n    runWordCounter()\n    return\n\n\nif __name__ == \"__main__\":\n    main()\n", 263], "C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py": ["#\n# Secret Labs' Regular Expression Engine\n#\n# convert template to internal format\n#\n# Copyright (c) 1997-2001 by Secret Labs AB.  All rights reserved.\n#\n# See the sre.py file for information on usage and redistribution.\n#\n\n\"\"\"Internal support module for sre\"\"\"\n\nimport _sre\nimport sre_parse\nfrom sre_constants import *\n\nassert _sre.MAGIC == MAGIC, \"SRE module mismatch\"\n\n_LITERAL_CODES = {LITERAL, NOT_LITERAL}\n_REPEATING_CODES = {REPEAT, MIN_REPEAT, MAX_REPEAT}\n_SUCCESS_CODES = {SUCCESS, FAILURE}\n_ASSERT_CODES = {ASSERT, ASSERT_NOT}\n_UNIT_CODES = _LITERAL_CODES | {ANY, IN}\n\n# Sets of lowercase characters which have the same uppercase.\n_equivalences = (\n    # LATIN SMALL LETTER I, LATIN SMALL LETTER DOTLESS I\n    (0x69, 0x131), # i\u0131\n    # LATIN SMALL LETTER S, LATIN SMALL LETTER LONG S\n    (0x73, 0x17f), # s\u017f\n    # MICRO SIGN, GREEK SMALL LETTER MU\n    (0xb5, 0x3bc), # \u00b5\u03bc\n    # COMBINING GREEK YPOGEGRAMMENI, GREEK SMALL LETTER IOTA, GREEK PROSGEGRAMMENI\n    (0x345, 0x3b9, 0x1fbe), # \\u0345\u03b9\u1fbe\n    # GREEK SMALL LETTER IOTA WITH DIALYTIKA AND TONOS, GREEK SMALL LETTER IOTA WITH DIALYTIKA AND OXIA\n    (0x390, 0x1fd3), # \u0390\u1fd3\n    # GREEK SMALL LETTER UPSILON WITH DIALYTIKA AND TONOS, GREEK SMALL LETTER UPSILON WITH DIALYTIKA AND OXIA\n    (0x3b0, 0x1fe3), # \u03b0\u1fe3\n    # GREEK SMALL LETTER BETA, GREEK BETA SYMBOL\n    (0x3b2, 0x3d0), # \u03b2\u03d0\n    # GREEK SMALL LETTER EPSILON, GREEK LUNATE EPSILON SYMBOL\n    (0x3b5, 0x3f5), # \u03b5\u03f5\n    # GREEK SMALL LETTER THETA, GREEK THETA SYMBOL\n    (0x3b8, 0x3d1), # \u03b8\u03d1\n    # GREEK SMALL LETTER KAPPA, GREEK KAPPA SYMBOL\n    (0x3ba, 0x3f0), # \u03ba\u03f0\n    # GREEK SMALL LETTER PI, GREEK PI SYMBOL\n    (0x3c0, 0x3d6), # \u03c0\u03d6\n    # GREEK SMALL LETTER RHO, GREEK RHO SYMBOL\n    (0x3c1, 0x3f1), # \u03c1\u03f1\n    # GREEK SMALL LETTER FINAL SIGMA, GREEK SMALL LETTER SIGMA\n    (0x3c2, 0x3c3), # \u03c2\u03c3\n    # GREEK SMALL LETTER PHI, GREEK PHI SYMBOL\n    (0x3c6, 0x3d5), # \u03c6\u03d5\n    # LATIN SMALL LETTER S WITH DOT ABOVE, LATIN SMALL LETTER LONG S WITH DOT ABOVE\n    (0x1e61, 0x1e9b), # \u1e61\u1e9b\n    # LATIN SMALL LIGATURE LONG S T, LATIN SMALL LIGATURE ST\n    (0xfb05, 0xfb06), # \ufb05\ufb06\n)\n\n# Maps the lowercase code to lowercase codes which have the same uppercase.\n_ignorecase_fixes = {i: tuple(j for j in t if i != j)\n                     for t in _equivalences for i in t}\n\ndef _combine_flags(flags, add_flags, del_flags,\n                   TYPE_FLAGS=sre_parse.TYPE_FLAGS):\n    if add_flags & TYPE_FLAGS:\n        flags &= ~TYPE_FLAGS\n    return (flags | add_flags) & ~del_flags\n\ndef _compile(code, pattern, flags):\n    # internal: compile a (sub)pattern\n    emit = code.append\n    _len = len\n    LITERAL_CODES = _LITERAL_CODES\n    REPEATING_CODES = _REPEATING_CODES\n    SUCCESS_CODES = _SUCCESS_CODES\n    ASSERT_CODES = _ASSERT_CODES\n    iscased = None\n    tolower = None\n    fixes = None\n    if flags & SRE_FLAG_IGNORECASE and not flags & SRE_FLAG_LOCALE:\n        if flags & SRE_FLAG_UNICODE:\n            iscased = _sre.unicode_iscased\n            tolower = _sre.unicode_tolower\n            fixes = _ignorecase_fixes\n        else:\n            iscased = _sre.ascii_iscased\n            tolower = _sre.ascii_tolower\n    for op, av in pattern:\n        if op in LITERAL_CODES:\n            if not flags & SRE_FLAG_IGNORECASE:\n                emit(op)\n                emit(av)\n            elif flags & SRE_FLAG_LOCALE:\n                emit(OP_LOCALE_IGNORE[op])\n                emit(av)\n            elif not iscased(av):\n                emit(op)\n                emit(av)\n            else:\n                lo = tolower(av)\n                if not fixes:  # ascii\n                    emit(OP_IGNORE[op])\n                    emit(lo)\n                elif lo not in fixes:\n                    emit(OP_UNICODE_IGNORE[op])\n                    emit(lo)\n                else:\n                    emit(IN_UNI_IGNORE)\n                    skip = _len(code); emit(0)\n                    if op is NOT_LITERAL:\n                        emit(NEGATE)\n                    for k in (lo,) + fixes[lo]:\n                        emit(LITERAL)\n                        emit(k)\n                    emit(FAILURE)\n                    code[skip] = _len(code) - skip\n        elif op is IN:\n            charset, hascased = _optimize_charset(av, iscased, tolower, fixes)\n            if flags & SRE_FLAG_IGNORECASE and flags & SRE_FLAG_LOCALE:\n                emit(IN_LOC_IGNORE)\n            elif not hascased:\n                emit(IN)\n            elif not fixes:  # ascii\n                emit(IN_IGNORE)\n            else:\n                emit(IN_UNI_IGNORE)\n            skip = _len(code); emit(0)\n            _compile_charset(charset, flags, code)\n            code[skip] = _len(code) - skip\n        elif op is ANY:\n            if flags & SRE_FLAG_DOTALL:\n                emit(ANY_ALL)\n            else:\n                emit(ANY)\n        elif op in REPEATING_CODES:\n            if flags & SRE_FLAG_TEMPLATE:\n                raise error(\"internal: unsupported template operator %r\" % (op,))\n            if _simple(av[2]):\n                if op is MAX_REPEAT:\n                    emit(REPEAT_ONE)\n                else:\n                    emit(MIN_REPEAT_ONE)\n                skip = _len(code); emit(0)\n                emit(av[0])\n                emit(av[1])\n                _compile(code, av[2], flags)\n                emit(SUCCESS)\n                code[skip] = _len(code) - skip\n            else:\n                emit(REPEAT)\n                skip = _len(code); emit(0)\n                emit(av[0])\n                emit(av[1])\n                _compile(code, av[2], flags)\n                code[skip] = _len(code) - skip\n                if op is MAX_REPEAT:\n                    emit(MAX_UNTIL)\n                else:\n                    emit(MIN_UNTIL)\n        elif op is SUBPATTERN:\n            group, add_flags, del_flags, p = av\n            if group:\n                emit(MARK)\n                emit((group-1)*2)\n            # _compile_info(code, p, _combine_flags(flags, add_flags, del_flags))\n            _compile(code, p, _combine_flags(flags, add_flags, del_flags))\n            if group:\n                emit(MARK)\n                emit((group-1)*2+1)\n        elif op in SUCCESS_CODES:\n            emit(op)\n        elif op in ASSERT_CODES:\n            emit(op)\n            skip = _len(code); emit(0)\n            if av[0] >= 0:\n                emit(0) # look ahead\n            else:\n                lo, hi = av[1].getwidth()\n                if lo != hi:\n                    raise error(\"look-behind requires fixed-width pattern\")\n                emit(lo) # look behind\n            _compile(code, av[1], flags)\n            emit(SUCCESS)\n            code[skip] = _len(code) - skip\n        elif op is CALL:\n            emit(op)\n            skip = _len(code); emit(0)\n            _compile(code, av, flags)\n            emit(SUCCESS)\n            code[skip] = _len(code) - skip\n        elif op is AT:\n            emit(op)\n            if flags & SRE_FLAG_MULTILINE:\n                av = AT_MULTILINE.get(av, av)\n            if flags & SRE_FLAG_LOCALE:\n                av = AT_LOCALE.get(av, av)\n            elif flags & SRE_FLAG_UNICODE:\n                av = AT_UNICODE.get(av, av)\n            emit(av)\n        elif op is BRANCH:\n            emit(op)\n            tail = []\n            tailappend = tail.append\n            for av in av[1]:\n                skip = _len(code); emit(0)\n                # _compile_info(code, av, flags)\n                _compile(code, av, flags)\n                emit(JUMP)\n                tailappend(_len(code)); emit(0)\n                code[skip] = _len(code) - skip\n            emit(FAILURE) # end of branch\n            for tail in tail:\n                code[tail] = _len(code) - tail\n        elif op is CATEGORY:\n            emit(op)\n            if flags & SRE_FLAG_LOCALE:\n                av = CH_LOCALE[av]\n            elif flags & SRE_FLAG_UNICODE:\n                av = CH_UNICODE[av]\n            emit(av)\n        elif op is GROUPREF:\n            if not flags & SRE_FLAG_IGNORECASE:\n                emit(op)\n            elif flags & SRE_FLAG_LOCALE:\n                emit(GROUPREF_LOC_IGNORE)\n            elif not fixes:  # ascii\n                emit(GROUPREF_IGNORE)\n            else:\n                emit(GROUPREF_UNI_IGNORE)\n            emit(av-1)\n        elif op is GROUPREF_EXISTS:\n            emit(op)\n            emit(av[0]-1)\n            skipyes = _len(code); emit(0)\n            _compile(code, av[1], flags)\n            if av[2]:\n                emit(JUMP)\n                skipno = _len(code); emit(0)\n                code[skipyes] = _len(code) - skipyes + 1\n                _compile(code, av[2], flags)\n                code[skipno] = _len(code) - skipno\n            else:\n                code[skipyes] = _len(code) - skipyes + 1\n        else:\n            raise error(\"internal: unsupported operand type %r\" % (op,))\n\ndef _compile_charset(charset, flags, code):\n    # compile charset subprogram\n    emit = code.append\n    for op, av in charset:\n        emit(op)\n        if op is NEGATE:\n            pass\n        elif op is LITERAL:\n            emit(av)\n        elif op is RANGE or op is RANGE_UNI_IGNORE:\n            emit(av[0])\n            emit(av[1])\n        elif op is CHARSET:\n            code.extend(av)\n        elif op is BIGCHARSET:\n            code.extend(av)\n        elif op is CATEGORY:\n            if flags & SRE_FLAG_LOCALE:\n                emit(CH_LOCALE[av])\n            elif flags & SRE_FLAG_UNICODE:\n                emit(CH_UNICODE[av])\n            else:\n                emit(av)\n        else:\n            raise error(\"internal: unsupported set operator %r\" % (op,))\n    emit(FAILURE)\n\ndef _optimize_charset(charset, iscased=None, fixup=None, fixes=None):\n    # internal: optimize character set\n    out = []\n    tail = []\n    charmap = bytearray(256)\n    hascased = False\n    for op, av in charset:\n        while True:\n            try:\n                if op is LITERAL:\n                    if fixup:\n                        lo = fixup(av)\n                        charmap[lo] = 1\n                        if fixes and lo in fixes:\n                            for k in fixes[lo]:\n                                charmap[k] = 1\n                        if not hascased and iscased(av):\n                            hascased = True\n                    else:\n                        charmap[av] = 1\n                elif op is RANGE:\n                    r = range(av[0], av[1]+1)\n                    if fixup:\n                        if fixes:\n                            for i in map(fixup, r):\n                                charmap[i] = 1\n                                if i in fixes:\n                                    for k in fixes[i]:\n                                        charmap[k] = 1\n                        else:\n                            for i in map(fixup, r):\n                                charmap[i] = 1\n                        if not hascased:\n                            hascased = any(map(iscased, r))\n                    else:\n                        for i in r:\n                            charmap[i] = 1\n                elif op is NEGATE:\n                    out.append((op, av))\n                else:\n                    tail.append((op, av))\n            except IndexError:\n                if len(charmap) == 256:\n                    # character set contains non-UCS1 character codes\n                    charmap += b'\\0' * 0xff00\n                    continue\n                # Character set contains non-BMP character codes.\n                if fixup:\n                    hascased = True\n                    # There are only two ranges of cased non-BMP characters:\n                    # 10400-1044F (Deseret) and 118A0-118DF (Warang Citi),\n                    # and for both ranges RANGE_UNI_IGNORE works.\n                    if op is RANGE:\n                        op = RANGE_UNI_IGNORE\n                tail.append((op, av))\n            break\n\n    # compress character map\n    runs = []\n    q = 0\n    while True:\n        p = charmap.find(1, q)\n        if p < 0:\n            break\n        if len(runs) >= 2:\n            runs = None\n            break\n        q = charmap.find(0, p)\n        if q < 0:\n            runs.append((p, len(charmap)))\n            break\n        runs.append((p, q))\n    if runs is not None:\n        # use literal/range\n        for p, q in runs:\n            if q - p == 1:\n                out.append((LITERAL, p))\n            else:\n                out.append((RANGE, (p, q - 1)))\n        out += tail\n        # if the case was changed or new representation is more compact\n        if hascased or len(out) < len(charset):\n            return out, hascased\n        # else original character set is good enough\n        return charset, hascased\n\n    # use bitmap\n    if len(charmap) == 256:\n        data = _mk_bitmap(charmap)\n        out.append((CHARSET, data))\n        out += tail\n        return out, hascased\n\n    # To represent a big charset, first a bitmap of all characters in the\n    # set is constructed. Then, this bitmap is sliced into chunks of 256\n    # characters, duplicate chunks are eliminated, and each chunk is\n    # given a number. In the compiled expression, the charset is\n    # represented by a 32-bit word sequence, consisting of one word for\n    # the number of different chunks, a sequence of 256 bytes (64 words)\n    # of chunk numbers indexed by their original chunk position, and a\n    # sequence of 256-bit chunks (8 words each).\n\n    # Compression is normally good: in a typical charset, large ranges of\n    # Unicode will be either completely excluded (e.g. if only cyrillic\n    # letters are to be matched), or completely included (e.g. if large\n    # subranges of Kanji match). These ranges will be represented by\n    # chunks of all one-bits or all zero-bits.\n\n    # Matching can be also done efficiently: the more significant byte of\n    # the Unicode character is an index into the chunk number, and the\n    # less significant byte is a bit index in the chunk (just like the\n    # CHARSET matching).\n\n    charmap = bytes(charmap) # should be hashable\n    comps = {}\n    mapping = bytearray(256)\n    block = 0\n    data = bytearray()\n    for i in range(0, 65536, 256):\n        chunk = charmap[i: i + 256]\n        if chunk in comps:\n            mapping[i // 256] = comps[chunk]\n        else:\n            mapping[i // 256] = comps[chunk] = block\n            block += 1\n            data += chunk\n    data = _mk_bitmap(data)\n    data[0:0] = [block] + _bytes_to_codes(mapping)\n    out.append((BIGCHARSET, data))\n    out += tail\n    return out, hascased\n\n_CODEBITS = _sre.CODESIZE * 8\nMAXCODE = (1 << _CODEBITS) - 1\n_BITS_TRANS = b'0' + b'1' * 255\ndef _mk_bitmap(bits, _CODEBITS=_CODEBITS, _int=int):\n    s = bits.translate(_BITS_TRANS)[::-1]\n    return [_int(s[i - _CODEBITS: i], 2)\n            for i in range(len(s), 0, -_CODEBITS)]\n\ndef _bytes_to_codes(b):\n    # Convert block indices to word array\n    a = memoryview(b).cast('I')\n    assert a.itemsize == _sre.CODESIZE\n    assert len(a) * a.itemsize == len(b)\n    return a.tolist()\n\ndef _simple(p):\n    # check if this subpattern is a \"simple\" operator\n    if len(p) != 1:\n        return False\n    op, av = p[0]\n    if op is SUBPATTERN:\n        return av[0] is None and _simple(av[-1])\n    return op in _UNIT_CODES\n\ndef _generate_overlap_table(prefix):\n    \"\"\"\n    Generate an overlap table for the following prefix.\n    An overlap table is a table of the same size as the prefix which\n    informs about the potential self-overlap for each index in the prefix:\n    - if overlap[i] == 0, prefix[i:] can't overlap prefix[0:...]\n    - if overlap[i] == k with 0 < k <= i, prefix[i-k+1:i+1] overlaps with\n      prefix[0:k]\n    \"\"\"\n    table = [0] * len(prefix)\n    for i in range(1, len(prefix)):\n        idx = table[i - 1]\n        while prefix[i] != prefix[idx]:\n            if idx == 0:\n                table[i] = 0\n                break\n            idx = table[idx - 1]\n        else:\n            table[i] = idx + 1\n    return table\n\ndef _get_iscased(flags):\n    if not flags & SRE_FLAG_IGNORECASE:\n        return None\n    elif flags & SRE_FLAG_UNICODE:\n        return _sre.unicode_iscased\n    else:\n        return _sre.ascii_iscased\n\ndef _get_literal_prefix(pattern, flags):\n    # look for literal prefix\n    prefix = []\n    prefixappend = prefix.append\n    prefix_skip = None\n    iscased = _get_iscased(flags)\n    for op, av in pattern.data:\n        if op is LITERAL:\n            if iscased and iscased(av):\n                break\n            prefixappend(av)\n        elif op is SUBPATTERN:\n            group, add_flags, del_flags, p = av\n            flags1 = _combine_flags(flags, add_flags, del_flags)\n            if flags1 & SRE_FLAG_IGNORECASE and flags1 & SRE_FLAG_LOCALE:\n                break\n            prefix1, prefix_skip1, got_all = _get_literal_prefix(p, flags1)\n            if prefix_skip is None:\n                if group is not None:\n                    prefix_skip = len(prefix)\n                elif prefix_skip1 is not None:\n                    prefix_skip = len(prefix) + prefix_skip1\n            prefix.extend(prefix1)\n            if not got_all:\n                break\n        else:\n            break\n    else:\n        return prefix, prefix_skip, True\n    return prefix, prefix_skip, False\n\ndef _get_charset_prefix(pattern, flags):\n    while True:\n        if not pattern.data:\n            return None\n        op, av = pattern.data[0]\n        if op is not SUBPATTERN:\n            break\n        group, add_flags, del_flags, pattern = av\n        flags = _combine_flags(flags, add_flags, del_flags)\n        if flags & SRE_FLAG_IGNORECASE and flags & SRE_FLAG_LOCALE:\n            return None\n\n    iscased = _get_iscased(flags)\n    if op is LITERAL:\n        if iscased and iscased(av):\n            return None\n        return [(op, av)]\n    elif op is BRANCH:\n        charset = []\n        charsetappend = charset.append\n        for p in av[1]:\n            if not p:\n                return None\n            op, av = p[0]\n            if op is LITERAL and not (iscased and iscased(av)):\n                charsetappend((op, av))\n            else:\n                return None\n        return charset\n    elif op is IN:\n        charset = av\n        if iscased:\n            for op, av in charset:\n                if op is LITERAL:\n                    if iscased(av):\n                        return None\n                elif op is RANGE:\n                    if av[1] > 0xffff:\n                        return None\n                    if any(map(iscased, range(av[0], av[1]+1))):\n                        return None\n        return charset\n    return None\n\ndef _compile_info(code, pattern, flags):\n    # internal: compile an info block.  in the current version,\n    # this contains min/max pattern width, and an optional literal\n    # prefix or a character map\n    lo, hi = pattern.getwidth()\n    if hi > MAXCODE:\n        hi = MAXCODE\n    if lo == 0:\n        code.extend([INFO, 4, 0, lo, hi])\n        return\n    # look for a literal prefix\n    prefix = []\n    prefix_skip = 0\n    charset = [] # not used\n    if not (flags & SRE_FLAG_IGNORECASE and flags & SRE_FLAG_LOCALE):\n        # look for literal prefix\n        prefix, prefix_skip, got_all = _get_literal_prefix(pattern, flags)\n        # if no prefix, look for charset prefix\n        if not prefix:\n            charset = _get_charset_prefix(pattern, flags)\n##     if prefix:\n##         print(\"*** PREFIX\", prefix, prefix_skip)\n##     if charset:\n##         print(\"*** CHARSET\", charset)\n    # add an info block\n    emit = code.append\n    emit(INFO)\n    skip = len(code); emit(0)\n    # literal flag\n    mask = 0\n    if prefix:\n        mask = SRE_INFO_PREFIX\n        if prefix_skip is None and got_all:\n            mask = mask | SRE_INFO_LITERAL\n    elif charset:\n        mask = mask | SRE_INFO_CHARSET\n    emit(mask)\n    # pattern length\n    if lo < MAXCODE:\n        emit(lo)\n    else:\n        emit(MAXCODE)\n        prefix = prefix[:MAXCODE]\n    emit(min(hi, MAXCODE))\n    # add literal prefix\n    if prefix:\n        emit(len(prefix)) # length\n        if prefix_skip is None:\n            prefix_skip =  len(prefix)\n        emit(prefix_skip) # skip\n        code.extend(prefix)\n        # generate overlap table\n        code.extend(_generate_overlap_table(prefix))\n    elif charset:\n        charset, hascased = _optimize_charset(charset)\n        assert not hascased\n        _compile_charset(charset, flags, code)\n    code[skip] = len(code) - skip\n\ndef isstring(obj):\n    return isinstance(obj, (str, bytes))\n\ndef _code(p, flags):\n\n    flags = p.state.flags | flags\n    code = []\n\n    # compile info block\n    _compile_info(code, p, flags)\n\n    # compile the pattern\n    _compile(code, p.data, flags)\n\n    code.append(SUCCESS)\n\n    return code\n\ndef _hex_code(code):\n    return '[%s]' % ', '.join('%#0*x' % (_sre.CODESIZE*2+2, x) for x in code)\n\ndef dis(code):\n    import sys\n\n    labels = set()\n    level = 0\n    offset_width = len(str(len(code) - 1))\n\n    def dis_(start, end):\n        def print_(*args, to=None):\n            if to is not None:\n                labels.add(to)\n                args += ('(to %d)' % (to,),)\n            print('%*d%s ' % (offset_width, start, ':' if start in labels else '.'),\n                  end='  '*(level-1))\n            print(*args)\n\n        def print_2(*args):\n            print(end=' '*(offset_width + 2*level))\n            print(*args)\n\n        nonlocal level\n        level += 1\n        i = start\n        while i < end:\n            start = i\n            op = code[i]\n            i += 1\n            op = OPCODES[op]\n            if op in (SUCCESS, FAILURE, ANY, ANY_ALL,\n                      MAX_UNTIL, MIN_UNTIL, NEGATE):\n                print_(op)\n            elif op in (LITERAL, NOT_LITERAL,\n                        LITERAL_IGNORE, NOT_LITERAL_IGNORE,\n                        LITERAL_UNI_IGNORE, NOT_LITERAL_UNI_IGNORE,\n                        LITERAL_LOC_IGNORE, NOT_LITERAL_LOC_IGNORE):\n                arg = code[i]\n                i += 1\n                print_(op, '%#02x (%r)' % (arg, chr(arg)))\n            elif op is AT:\n                arg = code[i]\n                i += 1\n                arg = str(ATCODES[arg])\n                assert arg[:3] == 'AT_'\n                print_(op, arg[3:])\n            elif op is CATEGORY:\n                arg = code[i]\n                i += 1\n                arg = str(CHCODES[arg])\n                assert arg[:9] == 'CATEGORY_'\n                print_(op, arg[9:])\n            elif op in (IN, IN_IGNORE, IN_UNI_IGNORE, IN_LOC_IGNORE):\n                skip = code[i]\n                print_(op, skip, to=i+skip)\n                dis_(i+1, i+skip)\n                i += skip\n            elif op in (RANGE, RANGE_UNI_IGNORE):\n                lo, hi = code[i: i+2]\n                i += 2\n                print_(op, '%#02x %#02x (%r-%r)' % (lo, hi, chr(lo), chr(hi)))\n            elif op is CHARSET:\n                print_(op, _hex_code(code[i: i + 256//_CODEBITS]))\n                i += 256//_CODEBITS\n            elif op is BIGCHARSET:\n                arg = code[i]\n                i += 1\n                mapping = list(b''.join(x.to_bytes(_sre.CODESIZE, sys.byteorder)\n                                        for x in code[i: i + 256//_sre.CODESIZE]))\n                print_(op, arg, mapping)\n                i += 256//_sre.CODESIZE\n                level += 1\n                for j in range(arg):\n                    print_2(_hex_code(code[i: i + 256//_CODEBITS]))\n                    i += 256//_CODEBITS\n                level -= 1\n            elif op in (MARK, GROUPREF, GROUPREF_IGNORE, GROUPREF_UNI_IGNORE,\n                        GROUPREF_LOC_IGNORE):\n                arg = code[i]\n                i += 1\n                print_(op, arg)\n            elif op is JUMP:\n                skip = code[i]\n                print_(op, skip, to=i+skip)\n                i += 1\n            elif op is BRANCH:\n                skip = code[i]\n                print_(op, skip, to=i+skip)\n                while skip:\n                    dis_(i+1, i+skip)\n                    i += skip\n                    start = i\n                    skip = code[i]\n                    if skip:\n                        print_('branch', skip, to=i+skip)\n                    else:\n                        print_(FAILURE)\n                i += 1\n            elif op in (REPEAT, REPEAT_ONE, MIN_REPEAT_ONE):\n                skip, min, max = code[i: i+3]\n                if max == MAXREPEAT:\n                    max = 'MAXREPEAT'\n                print_(op, skip, min, max, to=i+skip)\n                dis_(i+3, i+skip)\n                i += skip\n            elif op is GROUPREF_EXISTS:\n                arg, skip = code[i: i+2]\n                print_(op, arg, skip, to=i+skip)\n                i += 2\n            elif op in (ASSERT, ASSERT_NOT):\n                skip, arg = code[i: i+2]\n                print_(op, skip, arg, to=i+skip)\n                dis_(i+2, i+skip)\n                i += skip\n            elif op is INFO:\n                skip, flags, min, max = code[i: i+4]\n                if max == MAXREPEAT:\n                    max = 'MAXREPEAT'\n                print_(op, skip, bin(flags), min, max, to=i+skip)\n                start = i+4\n                if flags & SRE_INFO_PREFIX:\n                    prefix_len, prefix_skip = code[i+4: i+6]\n                    print_2('  prefix_skip', prefix_skip)\n                    start = i + 6\n                    prefix = code[start: start+prefix_len]\n                    print_2('  prefix',\n                            '[%s]' % ', '.join('%#02x' % x for x in prefix),\n                            '(%r)' % ''.join(map(chr, prefix)))\n                    start += prefix_len\n                    print_2('  overlap', code[start: start+prefix_len])\n                    start += prefix_len\n                if flags & SRE_INFO_CHARSET:\n                    level += 1\n                    print_2('in')\n                    dis_(start, i+skip)\n                    level -= 1\n                i += skip\n            else:\n                raise ValueError(op)\n\n        level -= 1\n\n    dis_(0, len(code))\n\n\ndef compile(p, flags=0):\n    # internal: convert pattern list to internal format\n\n    if isstring(p):\n        pattern = p\n        p = sre_parse.parse(p, flags)\n    else:\n        pattern = None\n\n    code = _code(p, flags)\n\n    if flags & SRE_FLAG_DEBUG:\n        print()\n        dis(code)\n\n    # map in either direction\n    groupindex = p.state.groupdict\n    indexgroup = [None] * p.state.groups\n    for k, i in groupindex.items():\n        indexgroup[i] = k\n\n    return _sre.compile(\n        pattern, flags | p.state.flags, code,\n        p.state.groups-1,\n        groupindex, tuple(indexgroup)\n        )\n", 784], "C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py": ["#\n# Secret Labs' Regular Expression Engine\n#\n# convert re-style regular expression to sre pattern\n#\n# Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\n#\n# See the sre.py file for information on usage and redistribution.\n#\n\n\"\"\"Internal support module for sre\"\"\"\n\n# XXX: show string offset and offending character for all errors\n\nfrom sre_constants import *\n\nSPECIAL_CHARS = \".\\\\[{()*+?^$|\"\nREPEAT_CHARS = \"*+?{\"\n\nDIGITS = frozenset(\"0123456789\")\n\nOCTDIGITS = frozenset(\"01234567\")\nHEXDIGITS = frozenset(\"0123456789abcdefABCDEF\")\nASCIILETTERS = frozenset(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n\nWHITESPACE = frozenset(\" \\t\\n\\r\\v\\f\")\n\n_REPEATCODES = frozenset({MIN_REPEAT, MAX_REPEAT})\n_UNITCODES = frozenset({ANY, RANGE, IN, LITERAL, NOT_LITERAL, CATEGORY})\n\nESCAPES = {\n    r\"\\a\": (LITERAL, ord(\"\\a\")),\n    r\"\\b\": (LITERAL, ord(\"\\b\")),\n    r\"\\f\": (LITERAL, ord(\"\\f\")),\n    r\"\\n\": (LITERAL, ord(\"\\n\")),\n    r\"\\r\": (LITERAL, ord(\"\\r\")),\n    r\"\\t\": (LITERAL, ord(\"\\t\")),\n    r\"\\v\": (LITERAL, ord(\"\\v\")),\n    r\"\\\\\": (LITERAL, ord(\"\\\\\"))\n}\n\nCATEGORIES = {\n    r\"\\A\": (AT, AT_BEGINNING_STRING), # start of string\n    r\"\\b\": (AT, AT_BOUNDARY),\n    r\"\\B\": (AT, AT_NON_BOUNDARY),\n    r\"\\d\": (IN, [(CATEGORY, CATEGORY_DIGIT)]),\n    r\"\\D\": (IN, [(CATEGORY, CATEGORY_NOT_DIGIT)]),\n    r\"\\s\": (IN, [(CATEGORY, CATEGORY_SPACE)]),\n    r\"\\S\": (IN, [(CATEGORY, CATEGORY_NOT_SPACE)]),\n    r\"\\w\": (IN, [(CATEGORY, CATEGORY_WORD)]),\n    r\"\\W\": (IN, [(CATEGORY, CATEGORY_NOT_WORD)]),\n    r\"\\Z\": (AT, AT_END_STRING), # end of string\n}\n\nFLAGS = {\n    # standard flags\n    \"i\": SRE_FLAG_IGNORECASE,\n    \"L\": SRE_FLAG_LOCALE,\n    \"m\": SRE_FLAG_MULTILINE,\n    \"s\": SRE_FLAG_DOTALL,\n    \"x\": SRE_FLAG_VERBOSE,\n    # extensions\n    \"a\": SRE_FLAG_ASCII,\n    \"t\": SRE_FLAG_TEMPLATE,\n    \"u\": SRE_FLAG_UNICODE,\n}\n\nTYPE_FLAGS = SRE_FLAG_ASCII | SRE_FLAG_LOCALE | SRE_FLAG_UNICODE\nGLOBAL_FLAGS = SRE_FLAG_DEBUG | SRE_FLAG_TEMPLATE\n\nclass Verbose(Exception):\n    pass\n\nclass State:\n    # keeps track of state for parsing\n    def __init__(self):\n        self.flags = 0\n        self.groupdict = {}\n        self.groupwidths = [None]  # group 0\n        self.lookbehindgroups = None\n    @property\n    def groups(self):\n        return len(self.groupwidths)\n    def opengroup(self, name=None):\n        gid = self.groups\n        self.groupwidths.append(None)\n        if self.groups > MAXGROUPS:\n            raise error(\"too many groups\")\n        if name is not None:\n            ogid = self.groupdict.get(name, None)\n            if ogid is not None:\n                raise error(\"redefinition of group name %r as group %d; \"\n                            \"was group %d\" % (name, gid,  ogid))\n            self.groupdict[name] = gid\n        return gid\n    def closegroup(self, gid, p):\n        self.groupwidths[gid] = p.getwidth()\n    def checkgroup(self, gid):\n        return gid < self.groups and self.groupwidths[gid] is not None\n\n    def checklookbehindgroup(self, gid, source):\n        if self.lookbehindgroups is not None:\n            if not self.checkgroup(gid):\n                raise source.error('cannot refer to an open group')\n            if gid >= self.lookbehindgroups:\n                raise source.error('cannot refer to group defined in the same '\n                                   'lookbehind subpattern')\n\nclass SubPattern:\n    # a subpattern, in intermediate form\n    def __init__(self, state, data=None):\n        self.state = state\n        if data is None:\n            data = []\n        self.data = data\n        self.width = None\n\n    def dump(self, level=0):\n        nl = True\n        seqtypes = (tuple, list)\n        for op, av in self.data:\n            print(level*\"  \" + str(op), end='')\n            if op is IN:\n                # member sublanguage\n                print()\n                for op, a in av:\n                    print((level+1)*\"  \" + str(op), a)\n            elif op is BRANCH:\n                print()\n                for i, a in enumerate(av[1]):\n                    if i:\n                        print(level*\"  \" + \"OR\")\n                    a.dump(level+1)\n            elif op is GROUPREF_EXISTS:\n                condgroup, item_yes, item_no = av\n                print('', condgroup)\n                item_yes.dump(level+1)\n                if item_no:\n                    print(level*\"  \" + \"ELSE\")\n                    item_no.dump(level+1)\n            elif isinstance(av, seqtypes):\n                nl = False\n                for a in av:\n                    if isinstance(a, SubPattern):\n                        if not nl:\n                            print()\n                        a.dump(level+1)\n                        nl = True\n                    else:\n                        if not nl:\n                            print(' ', end='')\n                        print(a, end='')\n                        nl = False\n                if not nl:\n                    print()\n            else:\n                print('', av)\n    def __repr__(self):\n        return repr(self.data)\n    def __len__(self):\n        return len(self.data)\n    def __delitem__(self, index):\n        del self.data[index]\n    def __getitem__(self, index):\n        if isinstance(index, slice):\n            return SubPattern(self.state, self.data[index])\n        return self.data[index]\n    def __setitem__(self, index, code):\n        self.data[index] = code\n    def insert(self, index, code):\n        self.data.insert(index, code)\n    def append(self, code):\n        self.data.append(code)\n    def getwidth(self):\n        # determine the width (min, max) for this subpattern\n        if self.width is not None:\n            return self.width\n        lo = hi = 0\n        for op, av in self.data:\n            if op is BRANCH:\n                i = MAXREPEAT - 1\n                j = 0\n                for av in av[1]:\n                    l, h = av.getwidth()\n                    i = min(i, l)\n                    j = max(j, h)\n                lo = lo + i\n                hi = hi + j\n            elif op is CALL:\n                i, j = av.getwidth()\n                lo = lo + i\n                hi = hi + j\n            elif op is SUBPATTERN:\n                i, j = av[-1].getwidth()\n                lo = lo + i\n                hi = hi + j\n            elif op in _REPEATCODES:\n                i, j = av[2].getwidth()\n                lo = lo + i * av[0]\n                hi = hi + j * av[1]\n            elif op in _UNITCODES:\n                lo = lo + 1\n                hi = hi + 1\n            elif op is GROUPREF:\n                i, j = self.state.groupwidths[av]\n                lo = lo + i\n                hi = hi + j\n            elif op is GROUPREF_EXISTS:\n                i, j = av[1].getwidth()\n                if av[2] is not None:\n                    l, h = av[2].getwidth()\n                    i = min(i, l)\n                    j = max(j, h)\n                else:\n                    i = 0\n                lo = lo + i\n                hi = hi + j\n            elif op is SUCCESS:\n                break\n        self.width = min(lo, MAXREPEAT - 1), min(hi, MAXREPEAT)\n        return self.width\n\nclass Tokenizer:\n    def __init__(self, string):\n        self.istext = isinstance(string, str)\n        self.string = string\n        if not self.istext:\n            string = str(string, 'latin1')\n        self.decoded_string = string\n        self.index = 0\n        self.next = None\n        self.__next()\n    def __next(self):\n        index = self.index\n        try:\n            char = self.decoded_string[index]\n        except IndexError:\n            self.next = None\n            return\n        if char == \"\\\\\":\n            index += 1\n            try:\n                char += self.decoded_string[index]\n            except IndexError:\n                raise error(\"bad escape (end of pattern)\",\n                            self.string, len(self.string) - 1) from None\n        self.index = index + 1\n        self.next = char\n    def match(self, char):\n        if char == self.next:\n            self.__next()\n            return True\n        return False\n    def get(self):\n        this = self.next\n        self.__next()\n        return this\n    def getwhile(self, n, charset):\n        result = ''\n        for _ in range(n):\n            c = self.next\n            if c not in charset:\n                break\n            result += c\n            self.__next()\n        return result\n    def getuntil(self, terminator, name):\n        result = ''\n        while True:\n            c = self.next\n            self.__next()\n            if c is None:\n                if not result:\n                    raise self.error(\"missing \" + name)\n                raise self.error(\"missing %s, unterminated name\" % terminator,\n                                 len(result))\n            if c == terminator:\n                if not result:\n                    raise self.error(\"missing \" + name, 1)\n                break\n            result += c\n        return result\n    @property\n    def pos(self):\n        return self.index - len(self.next or '')\n    def tell(self):\n        return self.index - len(self.next or '')\n    def seek(self, index):\n        self.index = index\n        self.__next()\n\n    def error(self, msg, offset=0):\n        return error(msg, self.string, self.tell() - offset)\n\ndef _class_escape(source, escape):\n    # handle escape code inside character class\n    code = ESCAPES.get(escape)\n    if code:\n        return code\n    code = CATEGORIES.get(escape)\n    if code and code[0] is IN:\n        return code\n    try:\n        c = escape[1:2]\n        if c == \"x\":\n            # hexadecimal escape (exactly two digits)\n            escape += source.getwhile(2, HEXDIGITS)\n            if len(escape) != 4:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            return LITERAL, int(escape[2:], 16)\n        elif c == \"u\" and source.istext:\n            # unicode escape (exactly four digits)\n            escape += source.getwhile(4, HEXDIGITS)\n            if len(escape) != 6:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            return LITERAL, int(escape[2:], 16)\n        elif c == \"U\" and source.istext:\n            # unicode escape (exactly eight digits)\n            escape += source.getwhile(8, HEXDIGITS)\n            if len(escape) != 10:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            c = int(escape[2:], 16)\n            chr(c) # raise ValueError for invalid code\n            return LITERAL, c\n        elif c == \"N\" and source.istext:\n            import unicodedata\n            # named unicode escape e.g. \\N{EM DASH}\n            if not source.match('{'):\n                raise source.error(\"missing {\")\n            charname = source.getuntil('}', 'character name')\n            try:\n                c = ord(unicodedata.lookup(charname))\n            except KeyError:\n                raise source.error(\"undefined character name %r\" % charname,\n                                   len(charname) + len(r'\\N{}'))\n            return LITERAL, c\n        elif c in OCTDIGITS:\n            # octal escape (up to three digits)\n            escape += source.getwhile(2, OCTDIGITS)\n            c = int(escape[1:], 8)\n            if c > 0o377:\n                raise source.error('octal escape value %s outside of '\n                                   'range 0-0o377' % escape, len(escape))\n            return LITERAL, c\n        elif c in DIGITS:\n            raise ValueError\n        if len(escape) == 2:\n            if c in ASCIILETTERS:\n                raise source.error('bad escape %s' % escape, len(escape))\n            return LITERAL, ord(escape[1])\n    except ValueError:\n        pass\n    raise source.error(\"bad escape %s\" % escape, len(escape))\n\ndef _escape(source, escape, state):\n    # handle escape code in expression\n    code = CATEGORIES.get(escape)\n    if code:\n        return code\n    code = ESCAPES.get(escape)\n    if code:\n        return code\n    try:\n        c = escape[1:2]\n        if c == \"x\":\n            # hexadecimal escape\n            escape += source.getwhile(2, HEXDIGITS)\n            if len(escape) != 4:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            return LITERAL, int(escape[2:], 16)\n        elif c == \"u\" and source.istext:\n            # unicode escape (exactly four digits)\n            escape += source.getwhile(4, HEXDIGITS)\n            if len(escape) != 6:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            return LITERAL, int(escape[2:], 16)\n        elif c == \"U\" and source.istext:\n            # unicode escape (exactly eight digits)\n            escape += source.getwhile(8, HEXDIGITS)\n            if len(escape) != 10:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            c = int(escape[2:], 16)\n            chr(c) # raise ValueError for invalid code\n            return LITERAL, c\n        elif c == \"N\" and source.istext:\n            import unicodedata\n            # named unicode escape e.g. \\N{EM DASH}\n            if not source.match('{'):\n                raise source.error(\"missing {\")\n            charname = source.getuntil('}', 'character name')\n            try:\n                c = ord(unicodedata.lookup(charname))\n            except KeyError:\n                raise source.error(\"undefined character name %r\" % charname,\n                                   len(charname) + len(r'\\N{}'))\n            return LITERAL, c\n        elif c == \"0\":\n            # octal escape\n            escape += source.getwhile(2, OCTDIGITS)\n            return LITERAL, int(escape[1:], 8)\n        elif c in DIGITS:\n            # octal escape *or* decimal group reference (sigh)\n            if source.next in DIGITS:\n                escape += source.get()\n                if (escape[1] in OCTDIGITS and escape[2] in OCTDIGITS and\n                    source.next in OCTDIGITS):\n                    # got three octal digits; this is an octal escape\n                    escape += source.get()\n                    c = int(escape[1:], 8)\n                    if c > 0o377:\n                        raise source.error('octal escape value %s outside of '\n                                           'range 0-0o377' % escape,\n                                           len(escape))\n                    return LITERAL, c\n            # not an octal escape, so this is a group reference\n            group = int(escape[1:])\n            if group < state.groups:\n                if not state.checkgroup(group):\n                    raise source.error(\"cannot refer to an open group\",\n                                       len(escape))\n                state.checklookbehindgroup(group, source)\n                return GROUPREF, group\n            raise source.error(\"invalid group reference %d\" % group, len(escape) - 1)\n        if len(escape) == 2:\n            if c in ASCIILETTERS:\n                raise source.error(\"bad escape %s\" % escape, len(escape))\n            return LITERAL, ord(escape[1])\n    except ValueError:\n        pass\n    raise source.error(\"bad escape %s\" % escape, len(escape))\n\ndef _uniq(items):\n    return list(dict.fromkeys(items))\n\ndef _parse_sub(source, state, verbose, nested):\n    # parse an alternation: a|b|c\n\n    items = []\n    itemsappend = items.append\n    sourcematch = source.match\n    start = source.tell()\n    while True:\n        itemsappend(_parse(source, state, verbose, nested + 1,\n                           not nested and not items))\n        if not sourcematch(\"|\"):\n            break\n\n    if len(items) == 1:\n        return items[0]\n\n    subpattern = SubPattern(state)\n\n    # check if all items share a common prefix\n    while True:\n        prefix = None\n        for item in items:\n            if not item:\n                break\n            if prefix is None:\n                prefix = item[0]\n            elif item[0] != prefix:\n                break\n        else:\n            # all subitems start with a common \"prefix\".\n            # move it out of the branch\n            for item in items:\n                del item[0]\n            subpattern.append(prefix)\n            continue # check next one\n        break\n\n    # check if the branch can be replaced by a character set\n    set = []\n    for item in items:\n        if len(item) != 1:\n            break\n        op, av = item[0]\n        if op is LITERAL:\n            set.append((op, av))\n        elif op is IN and av[0][0] is not NEGATE:\n            set.extend(av)\n        else:\n            break\n    else:\n        # we can store this as a character set instead of a\n        # branch (the compiler may optimize this even more)\n        subpattern.append((IN, _uniq(set)))\n        return subpattern\n\n    subpattern.append((BRANCH, (None, items)))\n    return subpattern\n\ndef _parse(source, state, verbose, nested, first=False):\n    # parse a simple pattern\n    subpattern = SubPattern(state)\n\n    # precompute constants into local variables\n    subpatternappend = subpattern.append\n    sourceget = source.get\n    sourcematch = source.match\n    _len = len\n    _ord = ord\n\n    while True:\n\n        this = source.next\n        if this is None:\n            break # end of pattern\n        if this in \"|)\":\n            break # end of subpattern\n        sourceget()\n\n        if verbose:\n            # skip whitespace and comments\n            if this in WHITESPACE:\n                continue\n            if this == \"#\":\n                while True:\n                    this = sourceget()\n                    if this is None or this == \"\\n\":\n                        break\n                continue\n\n        if this[0] == \"\\\\\":\n            code = _escape(source, this, state)\n            subpatternappend(code)\n\n        elif this not in SPECIAL_CHARS:\n            subpatternappend((LITERAL, _ord(this)))\n\n        elif this == \"[\":\n            here = source.tell() - 1\n            # character set\n            set = []\n            setappend = set.append\n##          if sourcematch(\":\"):\n##              pass # handle character classes\n            if source.next == '[':\n                import warnings\n                warnings.warn(\n                    'Possible nested set at position %d' % source.tell(),\n                    FutureWarning, stacklevel=nested + 6\n                )\n            negate = sourcematch(\"^\")\n            # check remaining characters\n            while True:\n                this = sourceget()\n                if this is None:\n                    raise source.error(\"unterminated character set\",\n                                       source.tell() - here)\n                if this == \"]\" and set:\n                    break\n                elif this[0] == \"\\\\\":\n                    code1 = _class_escape(source, this)\n                else:\n                    if set and this in '-&~|' and source.next == this:\n                        import warnings\n                        warnings.warn(\n                            'Possible set %s at position %d' % (\n                                'difference' if this == '-' else\n                                'intersection' if this == '&' else\n                                'symmetric difference' if this == '~' else\n                                'union',\n                                source.tell() - 1),\n                            FutureWarning, stacklevel=nested + 6\n                        )\n                    code1 = LITERAL, _ord(this)\n                if sourcematch(\"-\"):\n                    # potential range\n                    that = sourceget()\n                    if that is None:\n                        raise source.error(\"unterminated character set\",\n                                           source.tell() - here)\n                    if that == \"]\":\n                        if code1[0] is IN:\n                            code1 = code1[1][0]\n                        setappend(code1)\n                        setappend((LITERAL, _ord(\"-\")))\n                        break\n                    if that[0] == \"\\\\\":\n                        code2 = _class_escape(source, that)\n                    else:\n                        if that == '-':\n                            import warnings\n                            warnings.warn(\n                                'Possible set difference at position %d' % (\n                                    source.tell() - 2),\n                                FutureWarning, stacklevel=nested + 6\n                            )\n                        code2 = LITERAL, _ord(that)\n                    if code1[0] != LITERAL or code2[0] != LITERAL:\n                        msg = \"bad character range %s-%s\" % (this, that)\n                        raise source.error(msg, len(this) + 1 + len(that))\n                    lo = code1[1]\n                    hi = code2[1]\n                    if hi < lo:\n                        msg = \"bad character range %s-%s\" % (this, that)\n                        raise source.error(msg, len(this) + 1 + len(that))\n                    setappend((RANGE, (lo, hi)))\n                else:\n                    if code1[0] is IN:\n                        code1 = code1[1][0]\n                    setappend(code1)\n\n            set = _uniq(set)\n            # XXX: <fl> should move set optimization to compiler!\n            if _len(set) == 1 and set[0][0] is LITERAL:\n                # optimization\n                if negate:\n                    subpatternappend((NOT_LITERAL, set[0][1]))\n                else:\n                    subpatternappend(set[0])\n            else:\n                if negate:\n                    set.insert(0, (NEGATE, None))\n                # charmap optimization can't be added here because\n                # global flags still are not known\n                subpatternappend((IN, set))\n\n        elif this in REPEAT_CHARS:\n            # repeat previous item\n            here = source.tell()\n            if this == \"?\":\n                min, max = 0, 1\n            elif this == \"*\":\n                min, max = 0, MAXREPEAT\n\n            elif this == \"+\":\n                min, max = 1, MAXREPEAT\n            elif this == \"{\":\n                if source.next == \"}\":\n                    subpatternappend((LITERAL, _ord(this)))\n                    continue\n\n                min, max = 0, MAXREPEAT\n                lo = hi = \"\"\n                while source.next in DIGITS:\n                    lo += sourceget()\n                if sourcematch(\",\"):\n                    while source.next in DIGITS:\n                        hi += sourceget()\n                else:\n                    hi = lo\n                if not sourcematch(\"}\"):\n                    subpatternappend((LITERAL, _ord(this)))\n                    source.seek(here)\n                    continue\n\n                if lo:\n                    min = int(lo)\n                    if min >= MAXREPEAT:\n                        raise OverflowError(\"the repetition number is too large\")\n                if hi:\n                    max = int(hi)\n                    if max >= MAXREPEAT:\n                        raise OverflowError(\"the repetition number is too large\")\n                    if max < min:\n                        raise source.error(\"min repeat greater than max repeat\",\n                                           source.tell() - here)\n            else:\n                raise AssertionError(\"unsupported quantifier %r\" % (char,))\n            # figure out which item to repeat\n            if subpattern:\n                item = subpattern[-1:]\n            else:\n                item = None\n            if not item or item[0][0] is AT:\n                raise source.error(\"nothing to repeat\",\n                                   source.tell() - here + len(this))\n            if item[0][0] in _REPEATCODES:\n                raise source.error(\"multiple repeat\",\n                                   source.tell() - here + len(this))\n            if item[0][0] is SUBPATTERN:\n                group, add_flags, del_flags, p = item[0][1]\n                if group is None and not add_flags and not del_flags:\n                    item = p\n            if sourcematch(\"?\"):\n                subpattern[-1] = (MIN_REPEAT, (min, max, item))\n            else:\n                subpattern[-1] = (MAX_REPEAT, (min, max, item))\n\n        elif this == \".\":\n            subpatternappend((ANY, None))\n\n        elif this == \"(\":\n            start = source.tell() - 1\n            group = True\n            name = None\n            add_flags = 0\n            del_flags = 0\n            if sourcematch(\"?\"):\n                # options\n                char = sourceget()\n                if char is None:\n                    raise source.error(\"unexpected end of pattern\")\n                if char == \"P\":\n                    # python extensions\n                    if sourcematch(\"<\"):\n                        # named group: skip forward to end of name\n                        name = source.getuntil(\">\", \"group name\")\n                        if not name.isidentifier():\n                            msg = \"bad character in group name %r\" % name\n                            raise source.error(msg, len(name) + 1)\n                    elif sourcematch(\"=\"):\n                        # named backreference\n                        name = source.getuntil(\")\", \"group name\")\n                        if not name.isidentifier():\n                            msg = \"bad character in group name %r\" % name\n                            raise source.error(msg, len(name) + 1)\n                        gid = state.groupdict.get(name)\n                        if gid is None:\n                            msg = \"unknown group name %r\" % name\n                            raise source.error(msg, len(name) + 1)\n                        if not state.checkgroup(gid):\n                            raise source.error(\"cannot refer to an open group\",\n                                               len(name) + 1)\n                        state.checklookbehindgroup(gid, source)\n                        subpatternappend((GROUPREF, gid))\n                        continue\n\n                    else:\n                        char = sourceget()\n                        if char is None:\n                            raise source.error(\"unexpected end of pattern\")\n                        raise source.error(\"unknown extension ?P\" + char,\n                                           len(char) + 2)\n                elif char == \":\":\n                    # non-capturing group\n                    group = None\n                elif char == \"#\":\n                    # comment\n                    while True:\n                        if source.next is None:\n                            raise source.error(\"missing ), unterminated comment\",\n                                               source.tell() - start)\n                        if sourceget() == \")\":\n                            break\n                    continue\n\n                elif char in \"=!<\":\n                    # lookahead assertions\n                    dir = 1\n                    if char == \"<\":\n                        char = sourceget()\n                        if char is None:\n                            raise source.error(\"unexpected end of pattern\")\n                        if char not in \"=!\":\n                            raise source.error(\"unknown extension ?<\" + char,\n                                               len(char) + 2)\n                        dir = -1 # lookbehind\n                        lookbehindgroups = state.lookbehindgroups\n                        if lookbehindgroups is None:\n                            state.lookbehindgroups = state.groups\n                    p = _parse_sub(source, state, verbose, nested + 1)\n                    if dir < 0:\n                        if lookbehindgroups is None:\n                            state.lookbehindgroups = None\n                    if not sourcematch(\")\"):\n                        raise source.error(\"missing ), unterminated subpattern\",\n                                           source.tell() - start)\n                    if char == \"=\":\n                        subpatternappend((ASSERT, (dir, p)))\n                    else:\n                        subpatternappend((ASSERT_NOT, (dir, p)))\n                    continue\n\n                elif char == \"(\":\n                    # conditional backreference group\n                    condname = source.getuntil(\")\", \"group name\")\n                    if condname.isidentifier():\n                        condgroup = state.groupdict.get(condname)\n                        if condgroup is None:\n                            msg = \"unknown group name %r\" % condname\n                            raise source.error(msg, len(condname) + 1)\n                    else:\n                        try:\n                            condgroup = int(condname)\n                            if condgroup < 0:\n                                raise ValueError\n                        except ValueError:\n                            msg = \"bad character in group name %r\" % condname\n                            raise source.error(msg, len(condname) + 1) from None\n                        if not condgroup:\n                            raise source.error(\"bad group number\",\n                                               len(condname) + 1)\n                        if condgroup >= MAXGROUPS:\n                            msg = \"invalid group reference %d\" % condgroup\n                            raise source.error(msg, len(condname) + 1)\n                    state.checklookbehindgroup(condgroup, source)\n                    item_yes = _parse(source, state, verbose, nested + 1)\n                    if source.match(\"|\"):\n                        item_no = _parse(source, state, verbose, nested + 1)\n                        if source.next == \"|\":\n                            raise source.error(\"conditional backref with more than two branches\")\n                    else:\n                        item_no = None\n                    if not source.match(\")\"):\n                        raise source.error(\"missing ), unterminated subpattern\",\n                                           source.tell() - start)\n                    subpatternappend((GROUPREF_EXISTS, (condgroup, item_yes, item_no)))\n                    continue\n\n                elif char in FLAGS or char == \"-\":\n                    # flags\n                    flags = _parse_flags(source, state, char)\n                    if flags is None:  # global flags\n                        if not first or subpattern:\n                            import warnings\n                            warnings.warn(\n                                'Flags not at the start of the expression %r%s' % (\n                                    source.string[:20],  # truncate long regexes\n                                    ' (truncated)' if len(source.string) > 20 else '',\n                                ),\n                                DeprecationWarning, stacklevel=nested + 6\n                            )\n                        if (state.flags & SRE_FLAG_VERBOSE) and not verbose:\n                            raise Verbose\n                        continue\n\n                    add_flags, del_flags = flags\n                    group = None\n                else:\n                    raise source.error(\"unknown extension ?\" + char,\n                                       len(char) + 1)\n\n            # parse group contents\n            if group is not None:\n                try:\n                    group = state.opengroup(name)\n                except error as err:\n                    raise source.error(err.msg, len(name) + 1) from None\n            sub_verbose = ((verbose or (add_flags & SRE_FLAG_VERBOSE)) and\n                           not (del_flags & SRE_FLAG_VERBOSE))\n            p = _parse_sub(source, state, sub_verbose, nested + 1)\n            if not source.match(\")\"):\n                raise source.error(\"missing ), unterminated subpattern\",\n                                   source.tell() - start)\n            if group is not None:\n                state.closegroup(group, p)\n            subpatternappend((SUBPATTERN, (group, add_flags, del_flags, p)))\n\n        elif this == \"^\":\n            subpatternappend((AT, AT_BEGINNING))\n\n        elif this == \"$\":\n            subpatternappend((AT, AT_END))\n\n        else:\n            raise AssertionError(\"unsupported special character %r\" % (char,))\n\n    # unpack non-capturing groups\n    for i in range(len(subpattern))[::-1]:\n        op, av = subpattern[i]\n        if op is SUBPATTERN:\n            group, add_flags, del_flags, p = av\n            if group is None and not add_flags and not del_flags:\n                subpattern[i: i+1] = p\n\n    return subpattern\n\ndef _parse_flags(source, state, char):\n    sourceget = source.get\n    add_flags = 0\n    del_flags = 0\n    if char != \"-\":\n        while True:\n            flag = FLAGS[char]\n            if source.istext:\n                if char == 'L':\n                    msg = \"bad inline flags: cannot use 'L' flag with a str pattern\"\n                    raise source.error(msg)\n            else:\n                if char == 'u':\n                    msg = \"bad inline flags: cannot use 'u' flag with a bytes pattern\"\n                    raise source.error(msg)\n            add_flags |= flag\n            if (flag & TYPE_FLAGS) and (add_flags & TYPE_FLAGS) != flag:\n                msg = \"bad inline flags: flags 'a', 'u' and 'L' are incompatible\"\n                raise source.error(msg)\n            char = sourceget()\n            if char is None:\n                raise source.error(\"missing -, : or )\")\n            if char in \")-:\":\n                break\n            if char not in FLAGS:\n                msg = \"unknown flag\" if char.isalpha() else \"missing -, : or )\"\n                raise source.error(msg, len(char))\n    if char == \")\":\n        state.flags |= add_flags\n        return None\n    if add_flags & GLOBAL_FLAGS:\n        raise source.error(\"bad inline flags: cannot turn on global flag\", 1)\n    if char == \"-\":\n        char = sourceget()\n        if char is None:\n            raise source.error(\"missing flag\")\n        if char not in FLAGS:\n            msg = \"unknown flag\" if char.isalpha() else \"missing flag\"\n            raise source.error(msg, len(char))\n        while True:\n            flag = FLAGS[char]\n            if flag & TYPE_FLAGS:\n                msg = \"bad inline flags: cannot turn off flags 'a', 'u' and 'L'\"\n                raise source.error(msg)\n            del_flags |= flag\n            char = sourceget()\n            if char is None:\n                raise source.error(\"missing :\")\n            if char == \":\":\n                break\n            if char not in FLAGS:\n                msg = \"unknown flag\" if char.isalpha() else \"missing :\"\n                raise source.error(msg, len(char))\n    assert char == \":\"\n    if del_flags & GLOBAL_FLAGS:\n        raise source.error(\"bad inline flags: cannot turn off global flag\", 1)\n    if add_flags & del_flags:\n        raise source.error(\"bad inline flags: flag turned on and off\", 1)\n    return add_flags, del_flags\n\ndef fix_flags(src, flags):\n    # Check and fix flags according to the type of pattern (str or bytes)\n    if isinstance(src, str):\n        if flags & SRE_FLAG_LOCALE:\n            raise ValueError(\"cannot use LOCALE flag with a str pattern\")\n        if not flags & SRE_FLAG_ASCII:\n            flags |= SRE_FLAG_UNICODE\n        elif flags & SRE_FLAG_UNICODE:\n            raise ValueError(\"ASCII and UNICODE flags are incompatible\")\n    else:\n        if flags & SRE_FLAG_UNICODE:\n            raise ValueError(\"cannot use UNICODE flag with a bytes pattern\")\n        if flags & SRE_FLAG_LOCALE and flags & SRE_FLAG_ASCII:\n            raise ValueError(\"ASCII and LOCALE flags are incompatible\")\n    return flags\n\ndef parse(str, flags=0, state=None):\n    # parse 're' pattern into list of (opcode, argument) tuples\n\n    source = Tokenizer(str)\n\n    if state is None:\n        state = State()\n    state.flags = flags\n    state.str = str\n\n    try:\n        p = _parse_sub(source, state, flags & SRE_FLAG_VERBOSE, 0)\n    except Verbose:\n        # the VERBOSE flag was switched on inside the pattern.  to be\n        # on the safe side, we'll parse the whole thing again...\n        state = State()\n        state.flags = flags | SRE_FLAG_VERBOSE\n        state.str = str\n        source.seek(0)\n        p = _parse_sub(source, state, True, 0)\n\n    p.state.flags = fix_flags(str, p.state.flags)\n\n    if source.next is not None:\n        assert source.next == \")\"\n        raise source.error(\"unbalanced parenthesis\")\n\n    if flags & SRE_FLAG_DEBUG:\n        p.dump()\n\n    return p\n\ndef parse_template(source, state):\n    # parse 're' replacement string into list of literals and\n    # group references\n    s = Tokenizer(source)\n    sget = s.get\n    groups = []\n    literals = []\n    literal = []\n    lappend = literal.append\n    def addgroup(index, pos):\n        if index > state.groups:\n            raise s.error(\"invalid group reference %d\" % index, pos)\n        if literal:\n            literals.append(''.join(literal))\n            del literal[:]\n        groups.append((len(literals), index))\n        literals.append(None)\n    groupindex = state.groupindex\n    while True:\n        this = sget()\n        if this is None:\n            break # end of replacement string\n        if this[0] == \"\\\\\":\n            # group\n            c = this[1]\n            if c == \"g\":\n                name = \"\"\n                if not s.match(\"<\"):\n                    raise s.error(\"missing <\")\n                name = s.getuntil(\">\", \"group name\")\n                if name.isidentifier():\n                    try:\n                        index = groupindex[name]\n                    except KeyError:\n                        raise IndexError(\"unknown group name %r\" % name)\n                else:\n                    try:\n                        index = int(name)\n                        if index < 0:\n                            raise ValueError\n                    except ValueError:\n                        raise s.error(\"bad character in group name %r\" % name,\n                                      len(name) + 1) from None\n                    if index >= MAXGROUPS:\n                        raise s.error(\"invalid group reference %d\" % index,\n                                      len(name) + 1)\n                addgroup(index, len(name) + 1)\n            elif c == \"0\":\n                if s.next in OCTDIGITS:\n                    this += sget()\n                    if s.next in OCTDIGITS:\n                        this += sget()\n                lappend(chr(int(this[1:], 8) & 0xff))\n            elif c in DIGITS:\n                isoctal = False\n                if s.next in DIGITS:\n                    this += sget()\n                    if (c in OCTDIGITS and this[2] in OCTDIGITS and\n                        s.next in OCTDIGITS):\n                        this += sget()\n                        isoctal = True\n                        c = int(this[1:], 8)\n                        if c > 0o377:\n                            raise s.error('octal escape value %s outside of '\n                                          'range 0-0o377' % this, len(this))\n                        lappend(chr(c))\n                if not isoctal:\n                    addgroup(int(this[1:]), len(this) - 1)\n            else:\n                try:\n                    this = chr(ESCAPES[this][1])\n                except KeyError:\n                    if c in ASCIILETTERS:\n                        raise s.error('bad escape %s' % this, len(this))\n                lappend(this)\n        else:\n            lappend(this)\n    if literal:\n        literals.append(''.join(literal))\n    if not isinstance(source, str):\n        # The tokenizer implicitly decodes bytes objects as latin-1, we must\n        # therefore re-encode the final representation.\n        literals = [None if s is None else s.encode('latin-1') for s in literals]\n    return groups, literals\n\ndef expand_template(template, match):\n    g = match.group\n    empty = match.string[:0]\n    groups, literals = template\n    literals = literals[:]\n    try:\n        for index, group in groups:\n            literals[index] = g(group) or empty\n    except IndexError:\n        raise error(\"invalid group reference %d\" % index)\n    return empty.join(literals)\n", 1064], "C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py": ["import sys\nfrom types import MappingProxyType, DynamicClassAttribute\n\n\n__all__ = [\n        'EnumMeta',\n        'Enum', 'IntEnum', 'Flag', 'IntFlag',\n        'auto', 'unique',\n        ]\n\n\ndef _is_descriptor(obj):\n    \"\"\"\n    Returns True if obj is a descriptor, False otherwise.\n    \"\"\"\n    return (\n            hasattr(obj, '__get__') or\n            hasattr(obj, '__set__') or\n            hasattr(obj, '__delete__')\n            )\n\ndef _is_dunder(name):\n    \"\"\"\n    Returns True if a __dunder__ name, False otherwise.\n    \"\"\"\n    return (\n            len(name) > 4 and\n            name[:2] == name[-2:] == '__' and\n            name[2] != '_' and\n            name[-3] != '_'\n            )\n\ndef _is_sunder(name):\n    \"\"\"\n    Returns True if a _sunder_ name, False otherwise.\n    \"\"\"\n    return (\n            len(name) > 2 and\n            name[0] == name[-1] == '_' and\n            name[1:2] != '_' and\n            name[-2:-1] != '_'\n            )\n\ndef _is_private(cls_name, name):\n    # do not use `re` as `re` imports `enum`\n    pattern = '_%s__' % (cls_name, )\n    if (\n            len(name) >= 5\n            and name.startswith(pattern)\n            and name[len(pattern)] != '_'\n            and (name[-1] != '_' or name[-2] != '_')\n        ):\n        return True\n    else:\n        return False\n\ndef _make_class_unpicklable(cls):\n    \"\"\"\n    Make the given class un-picklable.\n    \"\"\"\n    def _break_on_call_reduce(self, proto):\n        raise TypeError('%r cannot be pickled' % self)\n    cls.__reduce_ex__ = _break_on_call_reduce\n    cls.__module__ = '<unknown>'\n\n_auto_null = object()\nclass auto:\n    \"\"\"\n    Instances are replaced with an appropriate value in Enum class suites.\n    \"\"\"\n    value = _auto_null\n\n\nclass _EnumDict(dict):\n    \"\"\"\n    Track enum member order and ensure member names are not reused.\n\n    EnumMeta will use the names found in self._member_names as the\n    enumeration member names.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self._member_names = []\n        self._last_values = []\n        self._ignore = []\n        self._auto_called = False\n\n    def __setitem__(self, key, value):\n        \"\"\"\n        Changes anything not dundered or not a descriptor.\n\n        If an enum member name is used twice, an error is raised; duplicate\n        values are not checked for.\n\n        Single underscore (sunder) names are reserved.\n        \"\"\"\n        if _is_private(self._cls_name, key):\n            import warnings\n            warnings.warn(\n                    \"private variables, such as %r, will be normal attributes in 3.10\"\n                        % (key, ),\n                    DeprecationWarning,\n                    stacklevel=2,\n                    )\n        if _is_sunder(key):\n            if key not in (\n                    '_order_', '_create_pseudo_member_',\n                    '_generate_next_value_', '_missing_', '_ignore_',\n                    ):\n                raise ValueError('_names_ are reserved for future Enum use')\n            if key == '_generate_next_value_':\n                # check if members already defined as auto()\n                if self._auto_called:\n                    raise TypeError(\"_generate_next_value_ must be defined before members\")\n                setattr(self, '_generate_next_value', value)\n            elif key == '_ignore_':\n                if isinstance(value, str):\n                    value = value.replace(',',' ').split()\n                else:\n                    value = list(value)\n                self._ignore = value\n                already = set(value) & set(self._member_names)\n                if already:\n                    raise ValueError(\n                            '_ignore_ cannot specify already set names: %r'\n                            % (already, )\n                            )\n        elif _is_dunder(key):\n            if key == '__order__':\n                key = '_order_'\n        elif key in self._member_names:\n            # descriptor overwriting an enum?\n            raise TypeError('Attempted to reuse key: %r' % key)\n        elif key in self._ignore:\n            pass\n        elif not _is_descriptor(value):\n            if key in self:\n                # enum overwriting a descriptor?\n                raise TypeError('%r already defined as: %r' % (key, self[key]))\n            if isinstance(value, auto):\n                if value.value == _auto_null:\n                    value.value = self._generate_next_value(\n                            key,\n                            1,\n                            len(self._member_names),\n                            self._last_values[:],\n                            )\n                    self._auto_called = True\n                value = value.value\n            self._member_names.append(key)\n            self._last_values.append(value)\n        super().__setitem__(key, value)\n\n\n# Dummy value for Enum as EnumMeta explicitly checks for it, but of course\n# until EnumMeta finishes running the first time the Enum class doesn't exist.\n# This is also why there are checks in EnumMeta like `if Enum is not None`\nEnum = None\n\nclass EnumMeta(type):\n    \"\"\"\n    Metaclass for Enum\n    \"\"\"\n    @classmethod\n    def __prepare__(metacls, cls, bases, **kwds):\n        # check that previous enum members do not exist\n        metacls._check_for_existing_members(cls, bases)\n        # create the namespace dict\n        enum_dict = _EnumDict()\n        enum_dict._cls_name = cls\n        # inherit previous flags and _generate_next_value_ function\n        member_type, first_enum = metacls._get_mixins_(cls, bases)\n        if first_enum is not None:\n            enum_dict['_generate_next_value_'] = getattr(\n                    first_enum, '_generate_next_value_', None,\n                    )\n        return enum_dict\n\n    def __new__(metacls, cls, bases, classdict, **kwds):\n        # an Enum class is final once enumeration items have been defined; it\n        # cannot be mixed with other types (int, float, etc.) if it has an\n        # inherited __new__ unless a new __new__ is defined (or the resulting\n        # class will fail).\n        #\n        # remove any keys listed in _ignore_\n        classdict.setdefault('_ignore_', []).append('_ignore_')\n        ignore = classdict['_ignore_']\n        for key in ignore:\n            classdict.pop(key, None)\n        member_type, first_enum = metacls._get_mixins_(cls, bases)\n        __new__, save_new, use_args = metacls._find_new_(\n                classdict, member_type, first_enum,\n                )\n\n        # save enum items into separate mapping so they don't get baked into\n        # the new class\n        enum_members = {k: classdict[k] for k in classdict._member_names}\n        for name in classdict._member_names:\n            del classdict[name]\n\n        # adjust the sunders\n        _order_ = classdict.pop('_order_', None)\n\n        # check for illegal enum names (any others?)\n        invalid_names = set(enum_members) & {'mro', ''}\n        if invalid_names:\n            raise ValueError('Invalid enum member name: {0}'.format(\n                ','.join(invalid_names)))\n\n        # create a default docstring if one has not been provided\n        if '__doc__' not in classdict:\n            classdict['__doc__'] = 'An enumeration.'\n\n        enum_class = super().__new__(metacls, cls, bases, classdict, **kwds)\n        enum_class._member_names_ = []               # names in definition order\n        enum_class._member_map_ = {}                 # name->value map\n        enum_class._member_type_ = member_type\n\n        # save DynamicClassAttribute attributes from super classes so we know\n        # if we can take the shortcut of storing members in the class dict\n        dynamic_attributes = {\n                k for c in enum_class.mro()\n                for k, v in c.__dict__.items()\n                if isinstance(v, DynamicClassAttribute)\n                }\n\n        # Reverse value->name map for hashable values.\n        enum_class._value2member_map_ = {}\n\n        # If a custom type is mixed into the Enum, and it does not know how\n        # to pickle itself, pickle.dumps will succeed but pickle.loads will\n        # fail.  Rather than have the error show up later and possibly far\n        # from the source, sabotage the pickle protocol for this class so\n        # that pickle.dumps also fails.\n        #\n        # However, if the new class implements its own __reduce_ex__, do not\n        # sabotage -- it's on them to make sure it works correctly.  We use\n        # __reduce_ex__ instead of any of the others as it is preferred by\n        # pickle over __reduce__, and it handles all pickle protocols.\n        if '__reduce_ex__' not in classdict:\n            if member_type is not object:\n                methods = ('__getnewargs_ex__', '__getnewargs__',\n                        '__reduce_ex__', '__reduce__')\n                if not any(m in member_type.__dict__ for m in methods):\n                    if '__new__' in classdict:\n                        # too late, sabotage\n                        _make_class_unpicklable(enum_class)\n                    else:\n                        # final attempt to verify that pickling would work:\n                        # travel mro until __new__ is found, checking for\n                        # __reduce__ and friends along the way -- if any of them\n                        # are found before/when __new__ is found, pickling should\n                        # work\n                        sabotage = None\n                        for chain in bases:\n                            for base in chain.__mro__:\n                                if base is object:\n                                    continue\n                                elif any(m in base.__dict__ for m in methods):\n                                    # found one, we're good\n                                    sabotage = False\n                                    break\n                                elif '__new__' in base.__dict__:\n                                    # not good\n                                    sabotage = True\n                                    break\n                            if sabotage is not None:\n                                break\n                        if sabotage:\n                            _make_class_unpicklable(enum_class)\n        # instantiate them, checking for duplicates as we go\n        # we instantiate first instead of checking for duplicates first in case\n        # a custom __new__ is doing something funky with the values -- such as\n        # auto-numbering ;)\n        for member_name in classdict._member_names:\n            value = enum_members[member_name]\n            if not isinstance(value, tuple):\n                args = (value, )\n            else:\n                args = value\n            if member_type is tuple:   # special case for tuple enums\n                args = (args, )     # wrap it one more time\n            if not use_args:\n                enum_member = __new__(enum_class)\n                if not hasattr(enum_member, '_value_'):\n                    enum_member._value_ = value\n            else:\n                enum_member = __new__(enum_class, *args)\n                if not hasattr(enum_member, '_value_'):\n                    if member_type is object:\n                        enum_member._value_ = value\n                    else:\n                        enum_member._value_ = member_type(*args)\n            value = enum_member._value_\n            enum_member._name_ = member_name\n            enum_member.__objclass__ = enum_class\n            enum_member.__init__(*args)\n            # If another member with the same value was already defined, the\n            # new member becomes an alias to the existing one.\n            for name, canonical_member in enum_class._member_map_.items():\n                if canonical_member._value_ == enum_member._value_:\n                    enum_member = canonical_member\n                    break\n            else:\n                # Aliases don't appear in member names (only in __members__).\n                enum_class._member_names_.append(member_name)\n            # performance boost for any member that would not shadow\n            # a DynamicClassAttribute\n            if member_name not in dynamic_attributes:\n                setattr(enum_class, member_name, enum_member)\n            # now add to _member_map_\n            enum_class._member_map_[member_name] = enum_member\n            try:\n                # This may fail if value is not hashable. We can't add the value\n                # to the map, and by-value lookups for this value will be\n                # linear.\n                enum_class._value2member_map_[value] = enum_member\n            except TypeError:\n                pass\n\n        # double check that repr and friends are not the mixin's or various\n        # things break (such as pickle)\n        # however, if the method is defined in the Enum itself, don't replace\n        # it\n        for name in ('__repr__', '__str__', '__format__', '__reduce_ex__'):\n            if name in classdict:\n                continue\n            class_method = getattr(enum_class, name)\n            obj_method = getattr(member_type, name, None)\n            enum_method = getattr(first_enum, name, None)\n            if obj_method is not None and obj_method is class_method:\n                setattr(enum_class, name, enum_method)\n\n        # replace any other __new__ with our own (as long as Enum is not None,\n        # anyway) -- again, this is to support pickle\n        if Enum is not None:\n            # if the user defined their own __new__, save it before it gets\n            # clobbered in case they subclass later\n            if save_new:\n                enum_class.__new_member__ = __new__\n            enum_class.__new__ = Enum.__new__\n\n        # py3 support for definition order (helps keep py2/py3 code in sync)\n        if _order_ is not None:\n            if isinstance(_order_, str):\n                _order_ = _order_.replace(',', ' ').split()\n            if _order_ != enum_class._member_names_:\n                raise TypeError('member order does not match _order_')\n\n        return enum_class\n\n    def __bool__(self):\n        \"\"\"\n        classes/types should always be True.\n        \"\"\"\n        return True\n\n    def __call__(cls, value, names=None, *, module=None, qualname=None, type=None, start=1):\n        \"\"\"\n        Either returns an existing member, or creates a new enum class.\n\n        This method is used both when an enum class is given a value to match\n        to an enumeration member (i.e. Color(3)) and for the functional API\n        (i.e. Color = Enum('Color', names='RED GREEN BLUE')).\n\n        When used for the functional API:\n\n        `value` will be the name of the new class.\n\n        `names` should be either a string of white-space/comma delimited names\n        (values will start at `start`), or an iterator/mapping of name, value pairs.\n\n        `module` should be set to the module this class is being created in;\n        if it is not set, an attempt to find that module will be made, but if\n        it fails the class will not be picklable.\n\n        `qualname` should be set to the actual location this class can be found\n        at in its module; by default it is set to the global scope.  If this is\n        not correct, unpickling will fail in some circumstances.\n\n        `type`, if set, will be mixed in as the first base class.\n        \"\"\"\n        if names is None:  # simple value lookup\n            return cls.__new__(cls, value)\n        # otherwise, functional API: we're creating a new Enum type\n        return cls._create_(\n                value,\n                names,\n                module=module,\n                qualname=qualname,\n                type=type,\n                start=start,\n                )\n\n    def __contains__(cls, member):\n        if not isinstance(member, Enum):\n            raise TypeError(\n                \"unsupported operand type(s) for 'in': '%s' and '%s'\" % (\n                    type(member).__qualname__, cls.__class__.__qualname__))\n        return isinstance(member, cls) and member._name_ in cls._member_map_\n\n    def __delattr__(cls, attr):\n        # nicer error message when someone tries to delete an attribute\n        # (see issue19025).\n        if attr in cls._member_map_:\n            raise AttributeError(\"%s: cannot delete Enum member.\" % cls.__name__)\n        super().__delattr__(attr)\n\n    def __dir__(self):\n        return (\n                ['__class__', '__doc__', '__members__', '__module__']\n                + self._member_names_\n                )\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n\n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n            raise AttributeError(name) from None\n\n    def __getitem__(cls, name):\n        return cls._member_map_[name]\n\n    def __iter__(cls):\n        \"\"\"\n        Returns members in definition order.\n        \"\"\"\n        return (cls._member_map_[name] for name in cls._member_names_)\n\n    def __len__(cls):\n        return len(cls._member_names_)\n\n    @property\n    def __members__(cls):\n        \"\"\"\n        Returns a mapping of member name->value.\n\n        This mapping lists all enum members, including aliases. Note that this\n        is a read-only view of the internal mapping.\n        \"\"\"\n        return MappingProxyType(cls._member_map_)\n\n    def __repr__(cls):\n        return \"<enum %r>\" % cls.__name__\n\n    def __reversed__(cls):\n        \"\"\"\n        Returns members in reverse definition order.\n        \"\"\"\n        return (cls._member_map_[name] for name in reversed(cls._member_names_))\n\n    def __setattr__(cls, name, value):\n        \"\"\"\n        Block attempts to reassign Enum members.\n\n        A simple assignment to the class namespace only changes one of the\n        several possible ways to get an Enum member from the Enum class,\n        resulting in an inconsistent Enumeration.\n        \"\"\"\n        member_map = cls.__dict__.get('_member_map_', {})\n        if name in member_map:\n            raise AttributeError('Cannot reassign members.')\n        super().__setattr__(name, value)\n\n    def _create_(cls, class_name, names, *, module=None, qualname=None, type=None, start=1):\n        \"\"\"\n        Convenience method to create a new Enum class.\n\n        `names` can be:\n\n        * A string containing member names, separated either with spaces or\n          commas.  Values are incremented by 1 from `start`.\n        * An iterable of member names.  Values are incremented by 1 from `start`.\n        * An iterable of (member name, value) pairs.\n        * A mapping of member name -> value pairs.\n        \"\"\"\n        metacls = cls.__class__\n        bases = (cls, ) if type is None else (type, cls)\n        _, first_enum = cls._get_mixins_(cls, bases)\n        classdict = metacls.__prepare__(class_name, bases)\n\n        # special processing needed for names?\n        if isinstance(names, str):\n            names = names.replace(',', ' ').split()\n        if isinstance(names, (tuple, list)) and names and isinstance(names[0], str):\n            original_names, names = names, []\n            last_values = []\n            for count, name in enumerate(original_names):\n                value = first_enum._generate_next_value_(name, start, count, last_values[:])\n                last_values.append(value)\n                names.append((name, value))\n\n        # Here, names is either an iterable of (name, value) or a mapping.\n        for item in names:\n            if isinstance(item, str):\n                member_name, member_value = item, names[item]\n            else:\n                member_name, member_value = item\n            classdict[member_name] = member_value\n        enum_class = metacls.__new__(metacls, class_name, bases, classdict)\n\n        # TODO: replace the frame hack if a blessed way to know the calling\n        # module is ever developed\n        if module is None:\n            try:\n                module = sys._getframe(2).f_globals['__name__']\n            except (AttributeError, ValueError, KeyError):\n                pass\n        if module is None:\n            _make_class_unpicklable(enum_class)\n        else:\n            enum_class.__module__ = module\n        if qualname is not None:\n            enum_class.__qualname__ = qualname\n\n        return enum_class\n\n    def _convert_(cls, name, module, filter, source=None):\n        \"\"\"\n        Create a new Enum subclass that replaces a collection of global constants\n        \"\"\"\n        # convert all constants from source (or module) that pass filter() to\n        # a new Enum called name, and export the enum and its members back to\n        # module;\n        # also, replace the __reduce_ex__ method so unpickling works in\n        # previous Python versions\n        module_globals = vars(sys.modules[module])\n        if source:\n            source = vars(source)\n        else:\n            source = module_globals\n        # _value2member_map_ is populated in the same order every time\n        # for a consistent reverse mapping of number to name when there\n        # are multiple names for the same number.\n        members = [\n                (name, value)\n                for name, value in source.items()\n                if filter(name)]\n        try:\n            # sort by value\n            members.sort(key=lambda t: (t[1], t[0]))\n        except TypeError:\n            # unless some values aren't comparable, in which case sort by name\n            members.sort(key=lambda t: t[0])\n        cls = cls(name, members, module=module)\n        cls.__reduce_ex__ = _reduce_ex_by_name\n        module_globals.update(cls.__members__)\n        module_globals[name] = cls\n        return cls\n\n    @staticmethod\n    def _check_for_existing_members(class_name, bases):\n        for chain in bases:\n            for base in chain.__mro__:\n                if issubclass(base, Enum) and base._member_names_:\n                    raise TypeError(\n                            \"%s: cannot extend enumeration %r\"\n                            % (class_name, base.__name__)\n                            )\n\n    @staticmethod\n    def _get_mixins_(class_name, bases):\n        \"\"\"\n        Returns the type for creating enum members, and the first inherited\n        enum class.\n\n        bases: the tuple of bases that was given to __new__\n        \"\"\"\n        if not bases:\n            return object, Enum\n\n        def _find_data_type(bases):\n            data_types = set()\n            for chain in bases:\n                candidate = None\n                for base in chain.__mro__:\n                    if base is object:\n                        continue\n                    elif issubclass(base, Enum):\n                        if base._member_type_ is not object:\n                            data_types.add(base._member_type_)\n                            break\n                    elif '__new__' in base.__dict__:\n                        if issubclass(base, Enum):\n                            continue\n                        data_types.add(candidate or base)\n                        break\n                    else:\n                        candidate = candidate or base\n            if len(data_types) > 1:\n                raise TypeError('%r: too many data types: %r' % (class_name, data_types))\n            elif data_types:\n                return data_types.pop()\n            else:\n                return None\n\n        # ensure final parent class is an Enum derivative, find any concrete\n        # data type, and check that Enum has no members\n        first_enum = bases[-1]\n        if not issubclass(first_enum, Enum):\n            raise TypeError(\"new enumerations should be created as \"\n                    \"`EnumName([mixin_type, ...] [data_type,] enum_type)`\")\n        member_type = _find_data_type(bases) or object\n        if first_enum._member_names_:\n            raise TypeError(\"Cannot extend enumerations\")\n        return member_type, first_enum\n\n    @staticmethod\n    def _find_new_(classdict, member_type, first_enum):\n        \"\"\"\n        Returns the __new__ to be used for creating the enum members.\n\n        classdict: the class dictionary given to __new__\n        member_type: the data type whose __new__ will be used by default\n        first_enum: enumeration to check for an overriding __new__\n        \"\"\"\n        # now find the correct __new__, checking to see of one was defined\n        # by the user; also check earlier enum classes in case a __new__ was\n        # saved as __new_member__\n        __new__ = classdict.get('__new__', None)\n\n        # should __new__ be saved as __new_member__ later?\n        save_new = __new__ is not None\n\n        if __new__ is None:\n            # check all possibles for __new_member__ before falling back to\n            # __new__\n            for method in ('__new_member__', '__new__'):\n                for possible in (member_type, first_enum):\n                    target = getattr(possible, method, None)\n                    if target not in {\n                            None,\n                            None.__new__,\n                            object.__new__,\n                            Enum.__new__,\n                            }:\n                        __new__ = target\n                        break\n                if __new__ is not None:\n                    break\n            else:\n                __new__ = object.__new__\n\n        # if a non-object.__new__ is used then whatever value/tuple was\n        # assigned to the enum member name will be passed to __new__ and to the\n        # new enum member's __init__\n        if __new__ is object.__new__:\n            use_args = False\n        else:\n            use_args = True\n        return __new__, save_new, use_args\n\n\nclass Enum(metaclass=EnumMeta):\n    \"\"\"\n    Generic enumeration.\n\n    Derive from this class to define new enumerations.\n    \"\"\"\n    def __new__(cls, value):\n        # all enum instances are actually created during class construction\n        # without calling this method; this method is called by the metaclass'\n        # __call__ (i.e. Color(3) ), and by pickle\n        if type(value) is cls:\n            # For lookups like Color(Color.RED)\n            return value\n        # by-value search for a matching enum member\n        # see if it's in the reverse mapping (for hashable values)\n        try:\n            return cls._value2member_map_[value]\n        except KeyError:\n            # Not found, no need to do long O(n) search\n            pass\n        except TypeError:\n            # not there, now do long search -- O(n) behavior\n            for member in cls._member_map_.values():\n                if member._value_ == value:\n                    return member\n        # still not found -- try _missing_ hook\n        try:\n            exc = None\n            result = cls._missing_(value)\n        except Exception as e:\n            exc = e\n            result = None\n        try:\n            if isinstance(result, cls):\n                return result\n            else:\n                ve_exc = ValueError(\"%r is not a valid %s\" % (value, cls.__qualname__))\n                if result is None and exc is None:\n                    raise ve_exc\n                elif exc is None:\n                    exc = TypeError(\n                            'error in %s._missing_: returned %r instead of None or a valid member'\n                            % (cls.__name__, result)\n                            )\n                exc.__context__ = ve_exc\n                raise exc\n        finally:\n            # ensure all variables that could hold an exception are destroyed\n            exc = None\n            ve_exc = None\n\n    def _generate_next_value_(name, start, count, last_values):\n        \"\"\"\n        Generate the next value when not given.\n\n        name: the name of the member\n        start: the initial start value or None\n        count: the number of existing members\n        last_value: the last value assigned or None\n        \"\"\"\n        for last_value in reversed(last_values):\n            try:\n                return last_value + 1\n            except TypeError:\n                pass\n        else:\n            return start\n\n    @classmethod\n    def _missing_(cls, value):\n        return None\n\n    def __repr__(self):\n        return \"<%s.%s: %r>\" % (\n                self.__class__.__name__, self._name_, self._value_)\n\n    def __str__(self):\n        return \"%s.%s\" % (self.__class__.__name__, self._name_)\n\n    def __dir__(self):\n        \"\"\"\n        Returns all members and all public methods\n        \"\"\"\n        added_behavior = [\n                m\n                for cls in self.__class__.mro()\n                for m in cls.__dict__\n                if m[0] != '_' and m not in self._member_map_\n                ] + [m for m in self.__dict__ if m[0] != '_']\n        return (['__class__', '__doc__', '__module__'] + added_behavior)\n\n    def __format__(self, format_spec):\n        \"\"\"\n        Returns format using actual value type unless __str__ has been overridden.\n        \"\"\"\n        # mixed-in Enums should use the mixed-in type's __format__, otherwise\n        # we can get strange results with the Enum name showing up instead of\n        # the value\n\n        # pure Enum branch, or branch with __str__ explicitly overridden\n        str_overridden = type(self).__str__ not in (Enum.__str__, Flag.__str__)\n        if self._member_type_ is object or str_overridden:\n            cls = str\n            val = str(self)\n        # mix-in branch\n        else:\n            cls = self._member_type_\n            val = self._value_\n        return cls.__format__(val, format_spec)\n\n    def __hash__(self):\n        return hash(self._name_)\n\n    def __reduce_ex__(self, proto):\n        return self.__class__, (self._value_, )\n\n    # DynamicClassAttribute is used to provide access to the `name` and\n    # `value` properties of enum members while keeping some measure of\n    # protection from modification, while still allowing for an enumeration\n    # to have members named `name` and `value`.  This works because enumeration\n    # members are not set directly on the enum class -- __getattr__ is\n    # used to look them up.\n\n    @DynamicClassAttribute\n    def name(self):\n        \"\"\"The name of the Enum member.\"\"\"\n        return self._name_\n\n    @DynamicClassAttribute\n    def value(self):\n        \"\"\"The value of the Enum member.\"\"\"\n        return self._value_\n\n\nclass IntEnum(int, Enum):\n    \"\"\"Enum where members are also (and must be) ints\"\"\"\n\n\ndef _reduce_ex_by_name(self, proto):\n    return self.name\n\nclass Flag(Enum):\n    \"\"\"\n    Support for flags\n    \"\"\"\n\n    def _generate_next_value_(name, start, count, last_values):\n        \"\"\"\n        Generate the next value when not given.\n\n        name: the name of the member\n        start: the initial start value or None\n        count: the number of existing members\n        last_value: the last value assigned or None\n        \"\"\"\n        if not count:\n            return start if start is not None else 1\n        for last_value in reversed(last_values):\n            try:\n                high_bit = _high_bit(last_value)\n                break\n            except Exception:\n                raise TypeError('Invalid Flag value: %r' % last_value) from None\n        return 2 ** (high_bit+1)\n\n    @classmethod\n    def _missing_(cls, value):\n        \"\"\"\n        Returns member (possibly creating it) if one can be found for value.\n        \"\"\"\n        original_value = value\n        if value < 0:\n            value = ~value\n        possible_member = cls._create_pseudo_member_(value)\n        if original_value < 0:\n            possible_member = ~possible_member\n        return possible_member\n\n    @classmethod\n    def _create_pseudo_member_(cls, value):\n        \"\"\"\n        Create a composite member iff value contains only members.\n        \"\"\"\n        pseudo_member = cls._value2member_map_.get(value, None)\n        if pseudo_member is None:\n            # verify all bits are accounted for\n            _, extra_flags = _decompose(cls, value)\n            if extra_flags:\n                raise ValueError(\"%r is not a valid %s\" % (value, cls.__qualname__))\n            # construct a singleton enum pseudo-member\n            pseudo_member = object.__new__(cls)\n            pseudo_member._name_ = None\n            pseudo_member._value_ = value\n            # use setdefault in case another thread already created a composite\n            # with this value\n            pseudo_member = cls._value2member_map_.setdefault(value, pseudo_member)\n        return pseudo_member\n\n    def __contains__(self, other):\n        \"\"\"\n        Returns True if self has at least the same flags set as other.\n        \"\"\"\n        if not isinstance(other, self.__class__):\n            raise TypeError(\n                \"unsupported operand type(s) for 'in': '%s' and '%s'\" % (\n                    type(other).__qualname__, self.__class__.__qualname__))\n        return other._value_ & self._value_ == other._value_\n\n    def __repr__(self):\n        cls = self.__class__\n        if self._name_ is not None:\n            return '<%s.%s: %r>' % (cls.__name__, self._name_, self._value_)\n        members, uncovered = _decompose(cls, self._value_)\n        return '<%s.%s: %r>' % (\n                cls.__name__,\n                '|'.join([str(m._name_ or m._value_) for m in members]),\n                self._value_,\n                )\n\n    def __str__(self):\n        cls = self.__class__\n        if self._name_ is not None:\n            return '%s.%s' % (cls.__name__, self._name_)\n        members, uncovered = _decompose(cls, self._value_)\n        if len(members) == 1 and members[0]._name_ is None:\n            return '%s.%r' % (cls.__name__, members[0]._value_)\n        else:\n            return '%s.%s' % (\n                    cls.__name__,\n                    '|'.join([str(m._name_ or m._value_) for m in members]),\n                    )\n\n    def __bool__(self):\n        return bool(self._value_)\n\n    def __or__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return self.__class__(self._value_ | other._value_)\n\n    def __and__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return self.__class__(self._value_ & other._value_)\n\n    def __xor__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return self.__class__(self._value_ ^ other._value_)\n\n    def __invert__(self):\n        members, uncovered = _decompose(self.__class__, self._value_)\n        inverted = self.__class__(0)\n        for m in self.__class__:\n            if m not in members and not (m._value_ & self._value_):\n                inverted = inverted | m\n        return self.__class__(inverted)\n\n\nclass IntFlag(int, Flag):\n    \"\"\"\n    Support for integer-based Flags\n    \"\"\"\n\n    @classmethod\n    def _missing_(cls, value):\n        \"\"\"\n        Returns member (possibly creating it) if one can be found for value.\n        \"\"\"\n        if not isinstance(value, int):\n            raise ValueError(\"%r is not a valid %s\" % (value, cls.__qualname__))\n        new_member = cls._create_pseudo_member_(value)\n        return new_member\n\n    @classmethod\n    def _create_pseudo_member_(cls, value):\n        \"\"\"\n        Create a composite member iff value contains only members.\n        \"\"\"\n        pseudo_member = cls._value2member_map_.get(value, None)\n        if pseudo_member is None:\n            need_to_create = [value]\n            # get unaccounted for bits\n            _, extra_flags = _decompose(cls, value)\n            # timer = 10\n            while extra_flags:\n                # timer -= 1\n                bit = _high_bit(extra_flags)\n                flag_value = 2 ** bit\n                if (flag_value not in cls._value2member_map_ and\n                        flag_value not in need_to_create\n                        ):\n                    need_to_create.append(flag_value)\n                if extra_flags == -flag_value:\n                    extra_flags = 0\n                else:\n                    extra_flags ^= flag_value\n            for value in reversed(need_to_create):\n                # construct singleton pseudo-members\n                pseudo_member = int.__new__(cls, value)\n                pseudo_member._name_ = None\n                pseudo_member._value_ = value\n                # use setdefault in case another thread already created a composite\n                # with this value\n                pseudo_member = cls._value2member_map_.setdefault(value, pseudo_member)\n        return pseudo_member\n\n    def __or__(self, other):\n        if not isinstance(other, (self.__class__, int)):\n            return NotImplemented\n        result = self.__class__(self._value_ | self.__class__(other)._value_)\n        return result\n\n    def __and__(self, other):\n        if not isinstance(other, (self.__class__, int)):\n            return NotImplemented\n        return self.__class__(self._value_ & self.__class__(other)._value_)\n\n    def __xor__(self, other):\n        if not isinstance(other, (self.__class__, int)):\n            return NotImplemented\n        return self.__class__(self._value_ ^ self.__class__(other)._value_)\n\n    __ror__ = __or__\n    __rand__ = __and__\n    __rxor__ = __xor__\n\n    def __invert__(self):\n        result = self.__class__(~self._value_)\n        return result\n\n\ndef _high_bit(value):\n    \"\"\"\n    returns index of highest bit, or -1 if value is zero or negative\n    \"\"\"\n    return value.bit_length() - 1\n\ndef unique(enumeration):\n    \"\"\"\n    Class decorator for enumerations ensuring unique member values.\n    \"\"\"\n    duplicates = []\n    for name, member in enumeration.__members__.items():\n        if name != member.name:\n            duplicates.append((name, member.name))\n    if duplicates:\n        alias_details = ', '.join(\n                [\"%s -> %s\" % (alias, name) for (alias, name) in duplicates])\n        raise ValueError('duplicate values found in %r: %s' %\n                (enumeration, alias_details))\n    return enumeration\n\ndef _decompose(flag, value):\n    \"\"\"\n    Extract all members from the value.\n    \"\"\"\n    # _decompose is only called if the value is not named\n    not_covered = value\n    negative = value < 0\n    members = []\n    for member in flag:\n        member_value = member.value\n        if member_value and member_value & value == member_value:\n            members.append(member)\n            not_covered &= ~member_value\n    if not negative:\n        tmp = not_covered\n        while tmp:\n            flag_value = 2 ** _high_bit(tmp)\n            if flag_value in flag._value2member_map_:\n                members.append(flag._value2member_map_[flag_value])\n                not_covered &= ~flag_value\n            tmp &= ~flag_value\n    if not members and value in flag._value2member_map_:\n        members.append(flag._value2member_map_[value])\n    members.sort(key=lambda m: m._value_, reverse=True)\n    if len(members) > 1 and members[0].value == value:\n        # we have the breakdown, don't need the value member itself\n        members.pop(0)\n    return members, not_covered\n", 1044], "C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py": ["#\n# Secret Labs' Regular Expression Engine\n#\n# re-compatible interface for the sre matching engine\n#\n# Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\n#\n# This version of the SRE library can be redistributed under CNRI's\n# Python 1.6 license.  For any other use, please contact Secret Labs\n# AB (info@pythonware.com).\n#\n# Portions of this engine have been developed in cooperation with\n# CNRI.  Hewlett-Packard provided funding for 1.6 integration and\n# other compatibility work.\n#\n\nr\"\"\"Support for regular expressions (RE).\n\nThis module provides regular expression matching operations similar to\nthose found in Perl.  It supports both 8-bit and Unicode strings; both\nthe pattern and the strings being processed can contain null bytes and\ncharacters outside the US ASCII range.\n\nRegular expressions can contain both special and ordinary characters.\nMost ordinary characters, like \"A\", \"a\", or \"0\", are the simplest\nregular expressions; they simply match themselves.  You can\nconcatenate ordinary characters, so last matches the string 'last'.\n\nThe special characters are:\n    \".\"      Matches any character except a newline.\n    \"^\"      Matches the start of the string.\n    \"$\"      Matches the end of the string or just before the newline at\n             the end of the string.\n    \"*\"      Matches 0 or more (greedy) repetitions of the preceding RE.\n             Greedy means that it will match as many repetitions as possible.\n    \"+\"      Matches 1 or more (greedy) repetitions of the preceding RE.\n    \"?\"      Matches 0 or 1 (greedy) of the preceding RE.\n    *?,+?,?? Non-greedy versions of the previous three special characters.\n    {m,n}    Matches from m to n repetitions of the preceding RE.\n    {m,n}?   Non-greedy version of the above.\n    \"\\\\\"     Either escapes special characters or signals a special sequence.\n    []       Indicates a set of characters.\n             A \"^\" as the first character indicates a complementing set.\n    \"|\"      A|B, creates an RE that will match either A or B.\n    (...)    Matches the RE inside the parentheses.\n             The contents can be retrieved or matched later in the string.\n    (?aiLmsux) The letters set the corresponding flags defined below.\n    (?:...)  Non-grouping version of regular parentheses.\n    (?P<name>...) The substring matched by the group is accessible by name.\n    (?P=name)     Matches the text matched earlier by the group named name.\n    (?#...)  A comment; ignored.\n    (?=...)  Matches if ... matches next, but doesn't consume the string.\n    (?!...)  Matches if ... doesn't match next.\n    (?<=...) Matches if preceded by ... (must be fixed length).\n    (?<!...) Matches if not preceded by ... (must be fixed length).\n    (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,\n                       the (optional) no pattern otherwise.\n\nThe special sequences consist of \"\\\\\" and a character from the list\nbelow.  If the ordinary character is not on the list, then the\nresulting RE will match the second character.\n    \\number  Matches the contents of the group of the same number.\n    \\A       Matches only at the start of the string.\n    \\Z       Matches only at the end of the string.\n    \\b       Matches the empty string, but only at the start or end of a word.\n    \\B       Matches the empty string, but not at the start or end of a word.\n    \\d       Matches any decimal digit; equivalent to the set [0-9] in\n             bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the whole\n             range of Unicode digits.\n    \\D       Matches any non-digit character; equivalent to [^\\d].\n    \\s       Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v] in\n             bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the whole\n             range of Unicode whitespace characters.\n    \\S       Matches any non-whitespace character; equivalent to [^\\s].\n    \\w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]\n             in bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the\n             range of Unicode alphanumeric characters (letters plus digits\n             plus underscore).\n             With LOCALE, it will match the set [0-9_] plus characters defined\n             as letters for the current locale.\n    \\W       Matches the complement of \\w.\n    \\\\       Matches a literal backslash.\n\nThis module exports the following functions:\n    match     Match a regular expression pattern to the beginning of a string.\n    fullmatch Match a regular expression pattern to all of a string.\n    search    Search a string for the presence of a pattern.\n    sub       Substitute occurrences of a pattern found in a string.\n    subn      Same as sub, but also return the number of substitutions made.\n    split     Split a string by the occurrences of a pattern.\n    findall   Find all occurrences of a pattern in a string.\n    finditer  Return an iterator yielding a Match object for each match.\n    compile   Compile a pattern into a Pattern object.\n    purge     Clear the regular expression cache.\n    escape    Backslash all non-alphanumerics in a string.\n\nEach function other than purge and escape can take an optional 'flags' argument\nconsisting of one or more of the following module constants, joined by \"|\".\nA, L, and U are mutually exclusive.\n    A  ASCII       For string patterns, make \\w, \\W, \\b, \\B, \\d, \\D\n                   match the corresponding ASCII character categories\n                   (rather than the whole Unicode categories, which is the\n                   default).\n                   For bytes patterns, this flag is the only available\n                   behaviour and needn't be specified.\n    I  IGNORECASE  Perform case-insensitive matching.\n    L  LOCALE      Make \\w, \\W, \\b, \\B, dependent on the current locale.\n    M  MULTILINE   \"^\" matches the beginning of lines (after a newline)\n                   as well as the string.\n                   \"$\" matches the end of lines (before a newline) as well\n                   as the end of the string.\n    S  DOTALL      \".\" matches any character at all, including the newline.\n    X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.\n    U  UNICODE     For compatibility only. Ignored for string patterns (it\n                   is the default), and forbidden for bytes patterns.\n\nThis module also defines an exception 'error'.\n\n\"\"\"\n\nimport enum\nimport sre_compile\nimport sre_parse\nimport functools\ntry:\n    import _locale\nexcept ImportError:\n    _locale = None\n\n\n# public symbols\n__all__ = [\n    \"match\", \"fullmatch\", \"search\", \"sub\", \"subn\", \"split\",\n    \"findall\", \"finditer\", \"compile\", \"purge\", \"template\", \"escape\",\n    \"error\", \"Pattern\", \"Match\", \"A\", \"I\", \"L\", \"M\", \"S\", \"X\", \"U\",\n    \"ASCII\", \"IGNORECASE\", \"LOCALE\", \"MULTILINE\", \"DOTALL\", \"VERBOSE\",\n    \"UNICODE\",\n]\n\n__version__ = \"2.2.1\"\n\nclass RegexFlag(enum.IntFlag):\n    ASCII = A = sre_compile.SRE_FLAG_ASCII # assume ascii \"locale\"\n    IGNORECASE = I = sre_compile.SRE_FLAG_IGNORECASE # ignore case\n    LOCALE = L = sre_compile.SRE_FLAG_LOCALE # assume current 8-bit locale\n    UNICODE = U = sre_compile.SRE_FLAG_UNICODE # assume unicode \"locale\"\n    MULTILINE = M = sre_compile.SRE_FLAG_MULTILINE # make anchors look for newline\n    DOTALL = S = sre_compile.SRE_FLAG_DOTALL # make dot match newline\n    VERBOSE = X = sre_compile.SRE_FLAG_VERBOSE # ignore whitespace and comments\n    # sre extensions (experimental, don't rely on these)\n    TEMPLATE = T = sre_compile.SRE_FLAG_TEMPLATE # disable backtracking\n    DEBUG = sre_compile.SRE_FLAG_DEBUG # dump pattern after compilation\n\n    def __repr__(self):\n        if self._name_ is not None:\n            return f're.{self._name_}'\n        value = self._value_\n        members = []\n        negative = value < 0\n        if negative:\n            value = ~value\n        for m in self.__class__:\n            if value & m._value_:\n                value &= ~m._value_\n                members.append(f're.{m._name_}')\n        if value:\n            members.append(hex(value))\n        res = '|'.join(members)\n        if negative:\n            if len(members) > 1:\n                res = f'~({res})'\n            else:\n                res = f'~{res}'\n        return res\n    __str__ = object.__str__\n\nglobals().update(RegexFlag.__members__)\n\n# sre exception\nerror = sre_compile.error\n\n# --------------------------------------------------------------------\n# public interface\n\ndef match(pattern, string, flags=0):\n    \"\"\"Try to apply the pattern at the start of the string, returning\n    a Match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).match(string)\n\ndef fullmatch(pattern, string, flags=0):\n    \"\"\"Try to apply the pattern to all of the string, returning\n    a Match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).fullmatch(string)\n\ndef search(pattern, string, flags=0):\n    \"\"\"Scan through string looking for a match to the pattern, returning\n    a Match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).search(string)\n\ndef sub(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in string by the\n    replacement repl.  repl can be either a string or a callable;\n    if a string, backslash escapes in it are processed.  If it is\n    a callable, it's passed the Match object and must return\n    a replacement string to be used.\"\"\"\n    return _compile(pattern, flags).sub(repl, string, count)\n\ndef subn(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return a 2-tuple containing (new_string, number).\n    new_string is the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in the source\n    string by the replacement repl.  number is the number of\n    substitutions that were made. repl can be either a string or a\n    callable; if a string, backslash escapes in it are processed.\n    If it is a callable, it's passed the Match object and must\n    return a replacement string to be used.\"\"\"\n    return _compile(pattern, flags).subn(repl, string, count)\n\ndef split(pattern, string, maxsplit=0, flags=0):\n    \"\"\"Split the source string by the occurrences of the pattern,\n    returning a list containing the resulting substrings.  If\n    capturing parentheses are used in pattern, then the text of all\n    groups in the pattern are also returned as part of the resulting\n    list.  If maxsplit is nonzero, at most maxsplit splits occur,\n    and the remainder of the string is returned as the final element\n    of the list.\"\"\"\n    return _compile(pattern, flags).split(string, maxsplit)\n\ndef findall(pattern, string, flags=0):\n    \"\"\"Return a list of all non-overlapping matches in the string.\n\n    If one or more capturing groups are present in the pattern, return\n    a list of groups; this will be a list of tuples if the pattern\n    has more than one group.\n\n    Empty matches are included in the result.\"\"\"\n    return _compile(pattern, flags).findall(string)\n\ndef finditer(pattern, string, flags=0):\n    \"\"\"Return an iterator over all non-overlapping matches in the\n    string.  For each match, the iterator returns a Match object.\n\n    Empty matches are included in the result.\"\"\"\n    return _compile(pattern, flags).finditer(string)\n\ndef compile(pattern, flags=0):\n    \"Compile a regular expression pattern, returning a Pattern object.\"\n    return _compile(pattern, flags)\n\ndef purge():\n    \"Clear the regular expression caches\"\n    _cache.clear()\n    _compile_repl.cache_clear()\n\ndef template(pattern, flags=0):\n    \"Compile a template pattern, returning a Pattern object\"\n    return _compile(pattern, flags|T)\n\n# SPECIAL_CHARS\n# closing ')', '}' and ']'\n# '-' (a range in character set)\n# '&', '~', (extended character set operations)\n# '#' (comment) and WHITESPACE (ignored) in verbose mode\n_special_chars_map = {i: '\\\\' + chr(i) for i in b'()[]{}?*+-|^$\\\\.&~# \\t\\n\\r\\v\\f'}\n\ndef escape(pattern):\n    \"\"\"\n    Escape special characters in a string.\n    \"\"\"\n    if isinstance(pattern, str):\n        return pattern.translate(_special_chars_map)\n    else:\n        pattern = str(pattern, 'latin1')\n        return pattern.translate(_special_chars_map).encode('latin1')\n\nPattern = type(sre_compile.compile('', 0))\nMatch = type(sre_compile.compile('', 0).match(''))\n\n# --------------------------------------------------------------------\n# internals\n\n_cache = {}  # ordered!\n\n_MAXCACHE = 512\ndef _compile(pattern, flags):\n    # internal: compile pattern\n    if isinstance(flags, RegexFlag):\n        flags = flags.value\n    try:\n        return _cache[type(pattern), pattern, flags]\n    except KeyError:\n        pass\n    if isinstance(pattern, Pattern):\n        if flags:\n            raise ValueError(\n                \"cannot process flags argument with a compiled pattern\")\n        return pattern\n    if not sre_compile.isstring(pattern):\n        raise TypeError(\"first argument must be string or compiled pattern\")\n    p = sre_compile.compile(pattern, flags)\n    if not (flags & DEBUG):\n        if len(_cache) >= _MAXCACHE:\n            # Drop the oldest item\n            try:\n                del _cache[next(iter(_cache))]\n            except (StopIteration, RuntimeError, KeyError):\n                pass\n        _cache[type(pattern), pattern, flags] = p\n    return p\n\n@functools.lru_cache(_MAXCACHE)\ndef _compile_repl(repl, pattern):\n    # internal: compile replacement pattern\n    return sre_parse.parse_template(repl, pattern)\n\ndef _expand(pattern, match, template):\n    # internal: Match.expand implementation hook\n    template = sre_parse.parse_template(template, pattern)\n    return sre_parse.expand_template(template, match)\n\ndef _subx(pattern, template):\n    # internal: Pattern.sub/subn implementation helper\n    template = _compile_repl(template, pattern)\n    if not template[0] and len(template[1]) == 1:\n        # literal replacement\n        return template[1][0]\n    def filter(match, template=template):\n        return sre_parse.expand_template(template, match)\n    return filter\n\n# register myself for pickling\n\nimport copyreg\n\ndef _pickle(p):\n    return _compile, (p.pattern, p.flags)\n\ncopyreg.pickle(Pattern, _pickle, _compile)\n\n# --------------------------------------------------------------------\n# experimental stuff (see python-dev discussions for details)\n\nclass Scanner:\n    def __init__(self, lexicon, flags=0):\n        from sre_constants import BRANCH, SUBPATTERN\n        if isinstance(flags, RegexFlag):\n            flags = flags.value\n        self.lexicon = lexicon\n        # combine phrases into a compound pattern\n        p = []\n        s = sre_parse.State()\n        s.flags = flags\n        for phrase, action in lexicon:\n            gid = s.opengroup()\n            p.append(sre_parse.SubPattern(s, [\n                (SUBPATTERN, (gid, 0, 0, sre_parse.parse(phrase, flags))),\n                ]))\n            s.closegroup(gid, p[-1])\n        p = sre_parse.SubPattern(s, [(BRANCH, (None, p))])\n        self.scanner = sre_compile.compile(p)\n    def scan(self, string):\n        result = []\n        append = result.append\n        match = self.scanner.scanner(string).match\n        i = 0\n        while True:\n            m = match()\n            if not m:\n                break\n            j = m.end()\n            if i == j:\n                break\n            action = self.lexicon[m.lastindex-1][1]\n            if callable(action):\n                self.match = m\n                action = action(self, m.group())\n            if action is not None:\n                append(action)\n            i = j\n        return result, string[i:]\n", 384], "C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py": ["# Copyright 2007 Google, Inc. All Rights Reserved.\n# Licensed to PSF under a Contributor Agreement.\n\n\"\"\"Abstract Base Classes (ABCs) for collections, according to PEP 3119.\n\nUnit tests are in test_collections.\n\"\"\"\n\nfrom abc import ABCMeta, abstractmethod\nimport sys\n\nGenericAlias = type(list[int])\nEllipsisType = type(...)\ndef _f(): pass\nFunctionType = type(_f)\ndel _f\n\n__all__ = [\"Awaitable\", \"Coroutine\",\n           \"AsyncIterable\", \"AsyncIterator\", \"AsyncGenerator\",\n           \"Hashable\", \"Iterable\", \"Iterator\", \"Generator\", \"Reversible\",\n           \"Sized\", \"Container\", \"Callable\", \"Collection\",\n           \"Set\", \"MutableSet\",\n           \"Mapping\", \"MutableMapping\",\n           \"MappingView\", \"KeysView\", \"ItemsView\", \"ValuesView\",\n           \"Sequence\", \"MutableSequence\",\n           \"ByteString\",\n           ]\n\n# This module has been renamed from collections.abc to _collections_abc to\n# speed up interpreter startup. Some of the types such as MutableMapping are\n# required early but collections module imports a lot of other modules.\n# See issue #19218\n__name__ = \"collections.abc\"\n\n# Private list of types that we want to register with the various ABCs\n# so that they will pass tests like:\n#       it = iter(somebytearray)\n#       assert isinstance(it, Iterable)\n# Note:  in other implementations, these types might not be distinct\n# and they may have their own implementation specific types that\n# are not included on this list.\nbytes_iterator = type(iter(b''))\nbytearray_iterator = type(iter(bytearray()))\n#callable_iterator = ???\ndict_keyiterator = type(iter({}.keys()))\ndict_valueiterator = type(iter({}.values()))\ndict_itemiterator = type(iter({}.items()))\nlist_iterator = type(iter([]))\nlist_reverseiterator = type(iter(reversed([])))\nrange_iterator = type(iter(range(0)))\nlongrange_iterator = type(iter(range(1 << 1000)))\nset_iterator = type(iter(set()))\nstr_iterator = type(iter(\"\"))\ntuple_iterator = type(iter(()))\nzip_iterator = type(iter(zip()))\n## views ##\ndict_keys = type({}.keys())\ndict_values = type({}.values())\ndict_items = type({}.items())\n## misc ##\nmappingproxy = type(type.__dict__)\ngenerator = type((lambda: (yield))())\n## coroutine ##\nasync def _coro(): pass\n_coro = _coro()\ncoroutine = type(_coro)\n_coro.close()  # Prevent ResourceWarning\ndel _coro\n## asynchronous generator ##\nasync def _ag(): yield\n_ag = _ag()\nasync_generator = type(_ag)\ndel _ag\n\n\n### ONE-TRICK PONIES ###\n\ndef _check_methods(C, *methods):\n    mro = C.__mro__\n    for method in methods:\n        for B in mro:\n            if method in B.__dict__:\n                if B.__dict__[method] is None:\n                    return NotImplemented\n                break\n        else:\n            return NotImplemented\n    return True\n\nclass Hashable(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __hash__(self):\n        return 0\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Hashable:\n            return _check_methods(C, \"__hash__\")\n        return NotImplemented\n\n\nclass Awaitable(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __await__(self):\n        yield\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Awaitable:\n            return _check_methods(C, \"__await__\")\n        return NotImplemented\n\n    __class_getitem__ = classmethod(GenericAlias)\n\n\nclass Coroutine(Awaitable):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def send(self, value):\n        \"\"\"Send a value into the coroutine.\n        Return next yielded value or raise StopIteration.\n        \"\"\"\n        raise StopIteration\n\n    @abstractmethod\n    def throw(self, typ, val=None, tb=None):\n        \"\"\"Raise an exception in the coroutine.\n        Return next yielded value or raise StopIteration.\n        \"\"\"\n        if val is None:\n            if tb is None:\n                raise typ\n            val = typ()\n        if tb is not None:\n            val = val.with_traceback(tb)\n        raise val\n\n    def close(self):\n        \"\"\"Raise GeneratorExit inside coroutine.\n        \"\"\"\n        try:\n            self.throw(GeneratorExit)\n        except (GeneratorExit, StopIteration):\n            pass\n        else:\n            raise RuntimeError(\"coroutine ignored GeneratorExit\")\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Coroutine:\n            return _check_methods(C, '__await__', 'send', 'throw', 'close')\n        return NotImplemented\n\n\nCoroutine.register(coroutine)\n\n\nclass AsyncIterable(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __aiter__(self):\n        return AsyncIterator()\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is AsyncIterable:\n            return _check_methods(C, \"__aiter__\")\n        return NotImplemented\n\n    __class_getitem__ = classmethod(GenericAlias)\n\n\nclass AsyncIterator(AsyncIterable):\n\n    __slots__ = ()\n\n    @abstractmethod\n    async def __anext__(self):\n        \"\"\"Return the next item or raise StopAsyncIteration when exhausted.\"\"\"\n        raise StopAsyncIteration\n\n    def __aiter__(self):\n        return self\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is AsyncIterator:\n            return _check_methods(C, \"__anext__\", \"__aiter__\")\n        return NotImplemented\n\n\nclass AsyncGenerator(AsyncIterator):\n\n    __slots__ = ()\n\n    async def __anext__(self):\n        \"\"\"Return the next item from the asynchronous generator.\n        When exhausted, raise StopAsyncIteration.\n        \"\"\"\n        return await self.asend(None)\n\n    @abstractmethod\n    async def asend(self, value):\n        \"\"\"Send a value into the asynchronous generator.\n        Return next yielded value or raise StopAsyncIteration.\n        \"\"\"\n        raise StopAsyncIteration\n\n    @abstractmethod\n    async def athrow(self, typ, val=None, tb=None):\n        \"\"\"Raise an exception in the asynchronous generator.\n        Return next yielded value or raise StopAsyncIteration.\n        \"\"\"\n        if val is None:\n            if tb is None:\n                raise typ\n            val = typ()\n        if tb is not None:\n            val = val.with_traceback(tb)\n        raise val\n\n    async def aclose(self):\n        \"\"\"Raise GeneratorExit inside coroutine.\n        \"\"\"\n        try:\n            await self.athrow(GeneratorExit)\n        except (GeneratorExit, StopAsyncIteration):\n            pass\n        else:\n            raise RuntimeError(\"asynchronous generator ignored GeneratorExit\")\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is AsyncGenerator:\n            return _check_methods(C, '__aiter__', '__anext__',\n                                  'asend', 'athrow', 'aclose')\n        return NotImplemented\n\n\nAsyncGenerator.register(async_generator)\n\n\nclass Iterable(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __iter__(self):\n        while False:\n            yield None\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Iterable:\n            return _check_methods(C, \"__iter__\")\n        return NotImplemented\n\n    __class_getitem__ = classmethod(GenericAlias)\n\n\nclass Iterator(Iterable):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __next__(self):\n        'Return the next item from the iterator. When exhausted, raise StopIteration'\n        raise StopIteration\n\n    def __iter__(self):\n        return self\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Iterator:\n            return _check_methods(C, '__iter__', '__next__')\n        return NotImplemented\n\n\nIterator.register(bytes_iterator)\nIterator.register(bytearray_iterator)\n#Iterator.register(callable_iterator)\nIterator.register(dict_keyiterator)\nIterator.register(dict_valueiterator)\nIterator.register(dict_itemiterator)\nIterator.register(list_iterator)\nIterator.register(list_reverseiterator)\nIterator.register(range_iterator)\nIterator.register(longrange_iterator)\nIterator.register(set_iterator)\nIterator.register(str_iterator)\nIterator.register(tuple_iterator)\nIterator.register(zip_iterator)\n\n\nclass Reversible(Iterable):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __reversed__(self):\n        while False:\n            yield None\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Reversible:\n            return _check_methods(C, \"__reversed__\", \"__iter__\")\n        return NotImplemented\n\n\nclass Generator(Iterator):\n\n    __slots__ = ()\n\n    def __next__(self):\n        \"\"\"Return the next item from the generator.\n        When exhausted, raise StopIteration.\n        \"\"\"\n        return self.send(None)\n\n    @abstractmethod\n    def send(self, value):\n        \"\"\"Send a value into the generator.\n        Return next yielded value or raise StopIteration.\n        \"\"\"\n        raise StopIteration\n\n    @abstractmethod\n    def throw(self, typ, val=None, tb=None):\n        \"\"\"Raise an exception in the generator.\n        Return next yielded value or raise StopIteration.\n        \"\"\"\n        if val is None:\n            if tb is None:\n                raise typ\n            val = typ()\n        if tb is not None:\n            val = val.with_traceback(tb)\n        raise val\n\n    def close(self):\n        \"\"\"Raise GeneratorExit inside generator.\n        \"\"\"\n        try:\n            self.throw(GeneratorExit)\n        except (GeneratorExit, StopIteration):\n            pass\n        else:\n            raise RuntimeError(\"generator ignored GeneratorExit\")\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Generator:\n            return _check_methods(C, '__iter__', '__next__',\n                                  'send', 'throw', 'close')\n        return NotImplemented\n\n\nGenerator.register(generator)\n\n\nclass Sized(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __len__(self):\n        return 0\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Sized:\n            return _check_methods(C, \"__len__\")\n        return NotImplemented\n\n\nclass Container(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __contains__(self, x):\n        return False\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Container:\n            return _check_methods(C, \"__contains__\")\n        return NotImplemented\n\n    __class_getitem__ = classmethod(GenericAlias)\n\n\nclass Collection(Sized, Iterable, Container):\n\n    __slots__ = ()\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Collection:\n            return _check_methods(C,  \"__len__\", \"__iter__\", \"__contains__\")\n        return NotImplemented\n\n\nclass _CallableGenericAlias(GenericAlias):\n    \"\"\" Represent `Callable[argtypes, resulttype]`.\n\n    This sets ``__args__`` to a tuple containing the flattened``argtypes``\n    followed by ``resulttype``.\n\n    Example: ``Callable[[int, str], float]`` sets ``__args__`` to\n    ``(int, str, float)``.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __new__(cls, origin, args):\n        try:\n            return cls.__create_ga(origin, args)\n        except TypeError as exc:\n            import warnings\n            warnings.warn(f'{str(exc)} '\n                          f'(This will raise a TypeError in Python 3.10.)',\n                          DeprecationWarning)\n            return GenericAlias(origin, args)\n\n    @classmethod\n    def __create_ga(cls, origin, args):\n        if not isinstance(args, tuple) or len(args) != 2:\n            raise TypeError(\n                \"Callable must be used as Callable[[arg, ...], result].\")\n        t_args, t_result = args\n        if isinstance(t_args, (list, tuple)):\n            ga_args = tuple(t_args) + (t_result,)\n        # This relaxes what t_args can be on purpose to allow things like\n        # PEP 612 ParamSpec.  Responsibility for whether a user is using\n        # Callable[...] properly is deferred to static type checkers.\n        else:\n            ga_args = args\n        return super().__new__(cls, origin, ga_args)\n\n    def __repr__(self):\n        if len(self.__args__) == 2 and self.__args__[0] is Ellipsis:\n            return super().__repr__()\n        return (f'collections.abc.Callable'\n                f'[[{\", \".join([_type_repr(a) for a in self.__args__[:-1]])}], '\n                f'{_type_repr(self.__args__[-1])}]')\n\n    def __reduce__(self):\n        args = self.__args__\n        if not (len(args) == 2 and args[0] is Ellipsis):\n            args = list(args[:-1]), args[-1]\n        return _CallableGenericAlias, (Callable, args)\n\n    def __getitem__(self, item):\n        # Called during TypeVar substitution, returns the custom subclass\n        # rather than the default types.GenericAlias object.\n        ga = super().__getitem__(item)\n        args = ga.__args__\n        t_result = args[-1]\n        t_args = args[:-1]\n        args = (t_args, t_result)\n        return _CallableGenericAlias(Callable, args)\n\n\ndef _type_repr(obj):\n    \"\"\"Return the repr() of an object, special-casing types (internal helper).\n\n    Copied from :mod:`typing` since collections.abc\n    shouldn't depend on that module.\n    \"\"\"\n    if isinstance(obj, GenericAlias):\n        return repr(obj)\n    if isinstance(obj, type):\n        if obj.__module__ == 'builtins':\n            return obj.__qualname__\n        return f'{obj.__module__}.{obj.__qualname__}'\n    if obj is Ellipsis:\n        return '...'\n    if isinstance(obj, FunctionType):\n        return obj.__name__\n    return repr(obj)\n\n\nclass Callable(metaclass=ABCMeta):\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __call__(self, *args, **kwds):\n        return False\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is Callable:\n            return _check_methods(C, \"__call__\")\n        return NotImplemented\n\n    __class_getitem__ = classmethod(_CallableGenericAlias)\n\n\n### SETS ###\n\n\nclass Set(Collection):\n\n    \"\"\"A set is a finite, iterable container.\n\n    This class provides concrete generic implementations of all\n    methods except for __contains__, __iter__ and __len__.\n\n    To override the comparisons (presumably for speed, as the\n    semantics are fixed), redefine __le__ and __ge__,\n    then the other operations will automatically follow suit.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __le__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        if len(self) > len(other):\n            return False\n        for elem in self:\n            if elem not in other:\n                return False\n        return True\n\n    def __lt__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        return len(self) < len(other) and self.__le__(other)\n\n    def __gt__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        return len(self) > len(other) and self.__ge__(other)\n\n    def __ge__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        if len(self) < len(other):\n            return False\n        for elem in other:\n            if elem not in self:\n                return False\n        return True\n\n    def __eq__(self, other):\n        if not isinstance(other, Set):\n            return NotImplemented\n        return len(self) == len(other) and self.__le__(other)\n\n    @classmethod\n    def _from_iterable(cls, it):\n        '''Construct an instance of the class from any iterable input.\n\n        Must override this method if the class constructor signature\n        does not accept an iterable for an input.\n        '''\n        return cls(it)\n\n    def __and__(self, other):\n        if not isinstance(other, Iterable):\n            return NotImplemented\n        return self._from_iterable(value for value in other if value in self)\n\n    __rand__ = __and__\n\n    def isdisjoint(self, other):\n        'Return True if two sets have a null intersection.'\n        for value in other:\n            if value in self:\n                return False\n        return True\n\n    def __or__(self, other):\n        if not isinstance(other, Iterable):\n            return NotImplemented\n        chain = (e for s in (self, other) for e in s)\n        return self._from_iterable(chain)\n\n    __ror__ = __or__\n\n    def __sub__(self, other):\n        if not isinstance(other, Set):\n            if not isinstance(other, Iterable):\n                return NotImplemented\n            other = self._from_iterable(other)\n        return self._from_iterable(value for value in self\n                                   if value not in other)\n\n    def __rsub__(self, other):\n        if not isinstance(other, Set):\n            if not isinstance(other, Iterable):\n                return NotImplemented\n            other = self._from_iterable(other)\n        return self._from_iterable(value for value in other\n                                   if value not in self)\n\n    def __xor__(self, other):\n        if not isinstance(other, Set):\n            if not isinstance(other, Iterable):\n                return NotImplemented\n            other = self._from_iterable(other)\n        return (self - other) | (other - self)\n\n    __rxor__ = __xor__\n\n    def _hash(self):\n        \"\"\"Compute the hash value of a set.\n\n        Note that we don't define __hash__: not all sets are hashable.\n        But if you define a hashable set type, its __hash__ should\n        call this function.\n\n        This must be compatible __eq__.\n\n        All sets ought to compare equal if they contain the same\n        elements, regardless of how they are implemented, and\n        regardless of the order of the elements; so there's not much\n        freedom for __eq__ or __hash__.  We match the algorithm used\n        by the built-in frozenset type.\n        \"\"\"\n        MAX = sys.maxsize\n        MASK = 2 * MAX + 1\n        n = len(self)\n        h = 1927868237 * (n + 1)\n        h &= MASK\n        for x in self:\n            hx = hash(x)\n            h ^= (hx ^ (hx << 16) ^ 89869747)  * 3644798167\n            h &= MASK\n        h ^= (h >> 11) ^ (h >> 25)\n        h = h * 69069 + 907133923\n        h &= MASK\n        if h > MAX:\n            h -= MASK + 1\n        if h == -1:\n            h = 590923713\n        return h\n\n\nSet.register(frozenset)\n\n\nclass MutableSet(Set):\n    \"\"\"A mutable set is a finite, iterable container.\n\n    This class provides concrete generic implementations of all\n    methods except for __contains__, __iter__, __len__,\n    add(), and discard().\n\n    To override the comparisons (presumably for speed, as the\n    semantics are fixed), all you have to do is redefine __le__ and\n    then the other operations will automatically follow suit.\n    \"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def add(self, value):\n        \"\"\"Add an element.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def discard(self, value):\n        \"\"\"Remove an element.  Do not raise an exception if absent.\"\"\"\n        raise NotImplementedError\n\n    def remove(self, value):\n        \"\"\"Remove an element. If not a member, raise a KeyError.\"\"\"\n        if value not in self:\n            raise KeyError(value)\n        self.discard(value)\n\n    def pop(self):\n        \"\"\"Return the popped value.  Raise KeyError if empty.\"\"\"\n        it = iter(self)\n        try:\n            value = next(it)\n        except StopIteration:\n            raise KeyError from None\n        self.discard(value)\n        return value\n\n    def clear(self):\n        \"\"\"This is slow (creates N new iterators!) but effective.\"\"\"\n        try:\n            while True:\n                self.pop()\n        except KeyError:\n            pass\n\n    def __ior__(self, it):\n        for value in it:\n            self.add(value)\n        return self\n\n    def __iand__(self, it):\n        for value in (self - it):\n            self.discard(value)\n        return self\n\n    def __ixor__(self, it):\n        if it is self:\n            self.clear()\n        else:\n            if not isinstance(it, Set):\n                it = self._from_iterable(it)\n            for value in it:\n                if value in self:\n                    self.discard(value)\n                else:\n                    self.add(value)\n        return self\n\n    def __isub__(self, it):\n        if it is self:\n            self.clear()\n        else:\n            for value in it:\n                self.discard(value)\n        return self\n\n\nMutableSet.register(set)\n\n\n### MAPPINGS ###\n\n\nclass Mapping(Collection):\n\n    __slots__ = ()\n\n    \"\"\"A Mapping is a generic container for associating key/value\n    pairs.\n\n    This class provides concrete generic implementations of all\n    methods except for __getitem__, __iter__, and __len__.\n\n    \"\"\"\n\n    @abstractmethod\n    def __getitem__(self, key):\n        raise KeyError\n\n    def get(self, key, default=None):\n        'D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.'\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def __contains__(self, key):\n        try:\n            self[key]\n        except KeyError:\n            return False\n        else:\n            return True\n\n    def keys(self):\n        \"D.keys() -> a set-like object providing a view on D's keys\"\n        return KeysView(self)\n\n    def items(self):\n        \"D.items() -> a set-like object providing a view on D's items\"\n        return ItemsView(self)\n\n    def values(self):\n        \"D.values() -> an object providing a view on D's values\"\n        return ValuesView(self)\n\n    def __eq__(self, other):\n        if not isinstance(other, Mapping):\n            return NotImplemented\n        return dict(self.items()) == dict(other.items())\n\n    __reversed__ = None\n\n\nMapping.register(mappingproxy)\n\n\nclass MappingView(Sized):\n\n    __slots__ = '_mapping',\n\n    def __init__(self, mapping):\n        self._mapping = mapping\n\n    def __len__(self):\n        return len(self._mapping)\n\n    def __repr__(self):\n        return '{0.__class__.__name__}({0._mapping!r})'.format(self)\n\n    __class_getitem__ = classmethod(GenericAlias)\n\n\nclass KeysView(MappingView, Set):\n\n    __slots__ = ()\n\n    @classmethod\n    def _from_iterable(self, it):\n        return set(it)\n\n    def __contains__(self, key):\n        return key in self._mapping\n\n    def __iter__(self):\n        yield from self._mapping\n\n\nKeysView.register(dict_keys)\n\n\nclass ItemsView(MappingView, Set):\n\n    __slots__ = ()\n\n    @classmethod\n    def _from_iterable(self, it):\n        return set(it)\n\n    def __contains__(self, item):\n        key, value = item\n        try:\n            v = self._mapping[key]\n        except KeyError:\n            return False\n        else:\n            return v is value or v == value\n\n    def __iter__(self):\n        for key in self._mapping:\n            yield (key, self._mapping[key])\n\n\nItemsView.register(dict_items)\n\n\nclass ValuesView(MappingView, Collection):\n\n    __slots__ = ()\n\n    def __contains__(self, value):\n        for key in self._mapping:\n            v = self._mapping[key]\n            if v is value or v == value:\n                return True\n        return False\n\n    def __iter__(self):\n        for key in self._mapping:\n            yield self._mapping[key]\n\n\nValuesView.register(dict_values)\n\n\nclass MutableMapping(Mapping):\n\n    __slots__ = ()\n\n    \"\"\"A MutableMapping is a generic container for associating\n    key/value pairs.\n\n    This class provides concrete generic implementations of all\n    methods except for __getitem__, __setitem__, __delitem__,\n    __iter__, and __len__.\n\n    \"\"\"\n\n    @abstractmethod\n    def __setitem__(self, key, value):\n        raise KeyError\n\n    @abstractmethod\n    def __delitem__(self, key):\n        raise KeyError\n\n    __marker = object()\n\n    def pop(self, key, default=__marker):\n        '''D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n          If key is not found, d is returned if given, otherwise KeyError is raised.\n        '''\n        try:\n            value = self[key]\n        except KeyError:\n            if default is self.__marker:\n                raise\n            return default\n        else:\n            del self[key]\n            return value\n\n    def popitem(self):\n        '''D.popitem() -> (k, v), remove and return some (key, value) pair\n           as a 2-tuple; but raise KeyError if D is empty.\n        '''\n        try:\n            key = next(iter(self))\n        except StopIteration:\n            raise KeyError from None\n        value = self[key]\n        del self[key]\n        return key, value\n\n    def clear(self):\n        'D.clear() -> None.  Remove all items from D.'\n        try:\n            while True:\n                self.popitem()\n        except KeyError:\n            pass\n\n    def update(self, other=(), /, **kwds):\n        ''' D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n            If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n            If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n            In either case, this is followed by: for k, v in F.items(): D[k] = v\n        '''\n        if isinstance(other, Mapping):\n            for key in other:\n                self[key] = other[key]\n        elif hasattr(other, \"keys\"):\n            for key in other.keys():\n                self[key] = other[key]\n        else:\n            for key, value in other:\n                self[key] = value\n        for key, value in kwds.items():\n            self[key] = value\n\n    def setdefault(self, key, default=None):\n        'D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D'\n        try:\n            return self[key]\n        except KeyError:\n            self[key] = default\n        return default\n\n\nMutableMapping.register(dict)\n\n\n### SEQUENCES ###\n\n\nclass Sequence(Reversible, Collection):\n\n    \"\"\"All the operations on a read-only sequence.\n\n    Concrete subclasses must override __new__ or __init__,\n    __getitem__, and __len__.\n    \"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __getitem__(self, index):\n        raise IndexError\n\n    def __iter__(self):\n        i = 0\n        try:\n            while True:\n                v = self[i]\n                yield v\n                i += 1\n        except IndexError:\n            return\n\n    def __contains__(self, value):\n        for v in self:\n            if v is value or v == value:\n                return True\n        return False\n\n    def __reversed__(self):\n        for i in reversed(range(len(self))):\n            yield self[i]\n\n    def index(self, value, start=0, stop=None):\n        '''S.index(value, [start, [stop]]) -> integer -- return first index of value.\n           Raises ValueError if the value is not present.\n\n           Supporting start and stop arguments is optional, but\n           recommended.\n        '''\n        if start is not None and start < 0:\n            start = max(len(self) + start, 0)\n        if stop is not None and stop < 0:\n            stop += len(self)\n\n        i = start\n        while stop is None or i < stop:\n            try:\n                v = self[i]\n                if v is value or v == value:\n                    return i\n            except IndexError:\n                break\n            i += 1\n        raise ValueError\n\n    def count(self, value):\n        'S.count(value) -> integer -- return number of occurrences of value'\n        return sum(1 for v in self if v is value or v == value)\n\n\nSequence.register(tuple)\nSequence.register(str)\nSequence.register(range)\nSequence.register(memoryview)\n\n\nclass ByteString(Sequence):\n\n    \"\"\"This unifies bytes and bytearray.\n\n    XXX Should add all their methods.\n    \"\"\"\n\n    __slots__ = ()\n\nByteString.register(bytes)\nByteString.register(bytearray)\n\n\nclass MutableSequence(Sequence):\n\n    __slots__ = ()\n\n    \"\"\"All the operations on a read-write sequence.\n\n    Concrete subclasses must provide __new__ or __init__,\n    __getitem__, __setitem__, __delitem__, __len__, and insert().\n\n    \"\"\"\n\n    @abstractmethod\n    def __setitem__(self, index, value):\n        raise IndexError\n\n    @abstractmethod\n    def __delitem__(self, index):\n        raise IndexError\n\n    @abstractmethod\n    def insert(self, index, value):\n        'S.insert(index, value) -- insert value before index'\n        raise IndexError\n\n    def append(self, value):\n        'S.append(value) -- append value to the end of the sequence'\n        self.insert(len(self), value)\n\n    def clear(self):\n        'S.clear() -> None -- remove all items from S'\n        try:\n            while True:\n                self.pop()\n        except IndexError:\n            pass\n\n    def reverse(self):\n        'S.reverse() -- reverse *IN PLACE*'\n        n = len(self)\n        for i in range(n//2):\n            self[i], self[n-i-1] = self[n-i-1], self[i]\n\n    def extend(self, values):\n        'S.extend(iterable) -- extend sequence by appending elements from the iterable'\n        if values is self:\n            values = list(values)\n        for v in values:\n            self.append(v)\n\n    def pop(self, index=-1):\n        '''S.pop([index]) -> item -- remove and return item at index (default last).\n           Raise IndexError if list is empty or index is out of range.\n        '''\n        v = self[index]\n        del self[index]\n        return v\n\n    def remove(self, value):\n        '''S.remove(value) -- remove first occurrence of value.\n           Raise ValueError if the value is not present.\n        '''\n        del self[self.index(value)]\n\n    def __iadd__(self, values):\n        self.extend(values)\n        return self\n\n\nMutableSequence.register(list)\nMutableSequence.register(bytearray)  # Multiply inheriting, see ByteString\n", 1116], "C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py": ["# Copyright 2007 Google, Inc. All Rights Reserved.\n# Licensed to PSF under a Contributor Agreement.\n\n\"\"\"Abstract Base Classes (ABCs) according to PEP 3119.\"\"\"\n\n\ndef abstractmethod(funcobj):\n    \"\"\"A decorator indicating abstract methods.\n\n    Requires that the metaclass is ABCMeta or derived from it.  A\n    class that has a metaclass derived from ABCMeta cannot be\n    instantiated unless all of its abstract methods are overridden.\n    The abstract methods can be called using any of the normal\n    'super' call mechanisms.  abstractmethod() may be used to declare\n    abstract methods for properties and descriptors.\n\n    Usage:\n\n        class C(metaclass=ABCMeta):\n            @abstractmethod\n            def my_abstract_method(self, ...):\n                ...\n    \"\"\"\n    funcobj.__isabstractmethod__ = True\n    return funcobj\n\n\nclass abstractclassmethod(classmethod):\n    \"\"\"A decorator indicating abstract classmethods.\n\n    Deprecated, use 'classmethod' with 'abstractmethod' instead:\n\n        class C(ABC):\n            @classmethod\n            @abstractmethod\n            def my_abstract_classmethod(cls, ...):\n                ...\n\n    \"\"\"\n\n    __isabstractmethod__ = True\n\n    def __init__(self, callable):\n        callable.__isabstractmethod__ = True\n        super().__init__(callable)\n\n\nclass abstractstaticmethod(staticmethod):\n    \"\"\"A decorator indicating abstract staticmethods.\n\n    Deprecated, use 'staticmethod' with 'abstractmethod' instead:\n\n        class C(ABC):\n            @staticmethod\n            @abstractmethod\n            def my_abstract_staticmethod(...):\n                ...\n\n    \"\"\"\n\n    __isabstractmethod__ = True\n\n    def __init__(self, callable):\n        callable.__isabstractmethod__ = True\n        super().__init__(callable)\n\n\nclass abstractproperty(property):\n    \"\"\"A decorator indicating abstract properties.\n\n    Deprecated, use 'property' with 'abstractmethod' instead:\n\n        class C(ABC):\n            @property\n            @abstractmethod\n            def my_abstract_property(self):\n                ...\n\n    \"\"\"\n\n    __isabstractmethod__ = True\n\n\ntry:\n    from _abc import (get_cache_token, _abc_init, _abc_register,\n                      _abc_instancecheck, _abc_subclasscheck, _get_dump,\n                      _reset_registry, _reset_caches)\nexcept ImportError:\n    from _py_abc import ABCMeta, get_cache_token\n    ABCMeta.__module__ = 'abc'\nelse:\n    class ABCMeta(type):\n        \"\"\"Metaclass for defining Abstract Base Classes (ABCs).\n\n        Use this metaclass to create an ABC.  An ABC can be subclassed\n        directly, and then acts as a mix-in class.  You can also register\n        unrelated concrete classes (even built-in classes) and unrelated\n        ABCs as 'virtual subclasses' -- these and their descendants will\n        be considered subclasses of the registering ABC by the built-in\n        issubclass() function, but the registering ABC won't show up in\n        their MRO (Method Resolution Order) nor will method\n        implementations defined by the registering ABC be callable (not\n        even via super()).\n        \"\"\"\n        def __new__(mcls, name, bases, namespace, **kwargs):\n            cls = super().__new__(mcls, name, bases, namespace, **kwargs)\n            _abc_init(cls)\n            return cls\n\n        def register(cls, subclass):\n            \"\"\"Register a virtual subclass of an ABC.\n\n            Returns the subclass, to allow usage as a class decorator.\n            \"\"\"\n            return _abc_register(cls, subclass)\n\n        def __instancecheck__(cls, instance):\n            \"\"\"Override for isinstance(instance, cls).\"\"\"\n            return _abc_instancecheck(cls, instance)\n\n        def __subclasscheck__(cls, subclass):\n            \"\"\"Override for issubclass(subclass, cls).\"\"\"\n            return _abc_subclasscheck(cls, subclass)\n\n        def _dump_registry(cls, file=None):\n            \"\"\"Debug helper to print the ABC registry.\"\"\"\n            print(f\"Class: {cls.__module__}.{cls.__qualname__}\", file=file)\n            print(f\"Inv. counter: {get_cache_token()}\", file=file)\n            (_abc_registry, _abc_cache, _abc_negative_cache,\n             _abc_negative_cache_version) = _get_dump(cls)\n            print(f\"_abc_registry: {_abc_registry!r}\", file=file)\n            print(f\"_abc_cache: {_abc_cache!r}\", file=file)\n            print(f\"_abc_negative_cache: {_abc_negative_cache!r}\", file=file)\n            print(f\"_abc_negative_cache_version: {_abc_negative_cache_version!r}\",\n                  file=file)\n\n        def _abc_registry_clear(cls):\n            \"\"\"Clear the registry (for debugging or testing).\"\"\"\n            _reset_registry(cls)\n\n        def _abc_caches_clear(cls):\n            \"\"\"Clear the caches (for debugging or testing).\"\"\"\n            _reset_caches(cls)\n\n\nclass ABC(metaclass=ABCMeta):\n    \"\"\"Helper class that provides a standard way to create an ABC using\n    inheritance.\n    \"\"\"\n    __slots__ = ()\n", 150], "C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py": ["'''This module implements specialized container datatypes providing\nalternatives to Python's general purpose built-in containers, dict,\nlist, set, and tuple.\n\n* namedtuple   factory function for creating tuple subclasses with named fields\n* deque        list-like container with fast appends and pops on either end\n* ChainMap     dict-like class for creating a single view of multiple mappings\n* Counter      dict subclass for counting hashable objects\n* OrderedDict  dict subclass that remembers the order entries were added\n* defaultdict  dict subclass that calls a factory function to supply missing values\n* UserDict     wrapper around dictionary objects for easier dict subclassing\n* UserList     wrapper around list objects for easier list subclassing\n* UserString   wrapper around string objects for easier string subclassing\n\n'''\n\n__all__ = [\n    'ChainMap',\n    'Counter',\n    'OrderedDict',\n    'UserDict',\n    'UserList',\n    'UserString',\n    'defaultdict',\n    'deque',\n    'namedtuple',\n]\n\nimport _collections_abc\nimport heapq as _heapq\nimport sys as _sys\n\nfrom itertools import chain as _chain\nfrom itertools import repeat as _repeat\nfrom itertools import starmap as _starmap\nfrom keyword import iskeyword as _iskeyword\nfrom operator import eq as _eq\nfrom operator import itemgetter as _itemgetter\nfrom reprlib import recursive_repr as _recursive_repr\nfrom _weakref import proxy as _proxy\n\ntry:\n    from _collections import deque\nexcept ImportError:\n    pass\nelse:\n    _collections_abc.MutableSequence.register(deque)\n\ntry:\n    from _collections import defaultdict\nexcept ImportError:\n    pass\n\n\ndef __getattr__(name):\n    # For backwards compatibility, continue to make the collections ABCs\n    # through Python 3.6 available through the collections module.\n    # Note, no new collections ABCs were added in Python 3.7\n    if name in _collections_abc.__all__:\n        obj = getattr(_collections_abc, name)\n        import warnings\n        warnings.warn(\"Using or importing the ABCs from 'collections' instead \"\n                      \"of from 'collections.abc' is deprecated since Python 3.3, \"\n                      \"and in 3.10 it will stop working\",\n                      DeprecationWarning, stacklevel=2)\n        globals()[name] = obj\n        return obj\n    raise AttributeError(f'module {__name__!r} has no attribute {name!r}')\n\n\n################################################################################\n### OrderedDict\n################################################################################\n\nclass _OrderedDictKeysView(_collections_abc.KeysView):\n\n    def __reversed__(self):\n        yield from reversed(self._mapping)\n\nclass _OrderedDictItemsView(_collections_abc.ItemsView):\n\n    def __reversed__(self):\n        for key in reversed(self._mapping):\n            yield (key, self._mapping[key])\n\nclass _OrderedDictValuesView(_collections_abc.ValuesView):\n\n    def __reversed__(self):\n        for key in reversed(self._mapping):\n            yield self._mapping[key]\n\nclass _Link(object):\n    __slots__ = 'prev', 'next', 'key', '__weakref__'\n\nclass OrderedDict(dict):\n    'Dictionary that remembers insertion order'\n    # An inherited dict maps keys to values.\n    # The inherited dict provides __getitem__, __len__, __contains__, and get.\n    # The remaining methods are order-aware.\n    # Big-O running times for all methods are the same as regular dictionaries.\n\n    # The internal self.__map dict maps keys to links in a doubly linked list.\n    # The circular doubly linked list starts and ends with a sentinel element.\n    # The sentinel element never gets deleted (this simplifies the algorithm).\n    # The sentinel is in self.__hardroot with a weakref proxy in self.__root.\n    # The prev links are weakref proxies (to prevent circular references).\n    # Individual links are kept alive by the hard reference in self.__map.\n    # Those hard references disappear when a key is deleted from an OrderedDict.\n\n    def __init__(self, other=(), /, **kwds):\n        '''Initialize an ordered dictionary.  The signature is the same as\n        regular dictionaries.  Keyword argument order is preserved.\n        '''\n        try:\n            self.__root\n        except AttributeError:\n            self.__hardroot = _Link()\n            self.__root = root = _proxy(self.__hardroot)\n            root.prev = root.next = root\n            self.__map = {}\n        self.__update(other, **kwds)\n\n    def __setitem__(self, key, value,\n                    dict_setitem=dict.__setitem__, proxy=_proxy, Link=_Link):\n        'od.__setitem__(i, y) <==> od[i]=y'\n        # Setting a new item creates a new link at the end of the linked list,\n        # and the inherited dictionary is updated with the new key/value pair.\n        if key not in self:\n            self.__map[key] = link = Link()\n            root = self.__root\n            last = root.prev\n            link.prev, link.next, link.key = last, root, key\n            last.next = link\n            root.prev = proxy(link)\n        dict_setitem(self, key, value)\n\n    def __delitem__(self, key, dict_delitem=dict.__delitem__):\n        'od.__delitem__(y) <==> del od[y]'\n        # Deleting an existing item uses self.__map to find the link which gets\n        # removed by updating the links in the predecessor and successor nodes.\n        dict_delitem(self, key)\n        link = self.__map.pop(key)\n        link_prev = link.prev\n        link_next = link.next\n        link_prev.next = link_next\n        link_next.prev = link_prev\n        link.prev = None\n        link.next = None\n\n    def __iter__(self):\n        'od.__iter__() <==> iter(od)'\n        # Traverse the linked list in order.\n        root = self.__root\n        curr = root.next\n        while curr is not root:\n            yield curr.key\n            curr = curr.next\n\n    def __reversed__(self):\n        'od.__reversed__() <==> reversed(od)'\n        # Traverse the linked list in reverse order.\n        root = self.__root\n        curr = root.prev\n        while curr is not root:\n            yield curr.key\n            curr = curr.prev\n\n    def clear(self):\n        'od.clear() -> None.  Remove all items from od.'\n        root = self.__root\n        root.prev = root.next = root\n        self.__map.clear()\n        dict.clear(self)\n\n    def popitem(self, last=True):\n        '''Remove and return a (key, value) pair from the dictionary.\n\n        Pairs are returned in LIFO order if last is true or FIFO order if false.\n        '''\n        if not self:\n            raise KeyError('dictionary is empty')\n        root = self.__root\n        if last:\n            link = root.prev\n            link_prev = link.prev\n            link_prev.next = root\n            root.prev = link_prev\n        else:\n            link = root.next\n            link_next = link.next\n            root.next = link_next\n            link_next.prev = root\n        key = link.key\n        del self.__map[key]\n        value = dict.pop(self, key)\n        return key, value\n\n    def move_to_end(self, key, last=True):\n        '''Move an existing element to the end (or beginning if last is false).\n\n        Raise KeyError if the element does not exist.\n        '''\n        link = self.__map[key]\n        link_prev = link.prev\n        link_next = link.next\n        soft_link = link_next.prev\n        link_prev.next = link_next\n        link_next.prev = link_prev\n        root = self.__root\n        if last:\n            last = root.prev\n            link.prev = last\n            link.next = root\n            root.prev = soft_link\n            last.next = link\n        else:\n            first = root.next\n            link.prev = root\n            link.next = first\n            first.prev = soft_link\n            root.next = link\n\n    def __sizeof__(self):\n        sizeof = _sys.getsizeof\n        n = len(self) + 1                       # number of links including root\n        size = sizeof(self.__dict__)            # instance dictionary\n        size += sizeof(self.__map) * 2          # internal dict and inherited dict\n        size += sizeof(self.__hardroot) * n     # link objects\n        size += sizeof(self.__root) * n         # proxy objects\n        return size\n\n    update = __update = _collections_abc.MutableMapping.update\n\n    def keys(self):\n        \"D.keys() -> a set-like object providing a view on D's keys\"\n        return _OrderedDictKeysView(self)\n\n    def items(self):\n        \"D.items() -> a set-like object providing a view on D's items\"\n        return _OrderedDictItemsView(self)\n\n    def values(self):\n        \"D.values() -> an object providing a view on D's values\"\n        return _OrderedDictValuesView(self)\n\n    __ne__ = _collections_abc.MutableMapping.__ne__\n\n    __marker = object()\n\n    def pop(self, key, default=__marker):\n        '''od.pop(k[,d]) -> v, remove specified key and return the corresponding\n        value.  If key is not found, d is returned if given, otherwise KeyError\n        is raised.\n\n        '''\n        if key in self:\n            result = self[key]\n            del self[key]\n            return result\n        if default is self.__marker:\n            raise KeyError(key)\n        return default\n\n    def setdefault(self, key, default=None):\n        '''Insert key with a value of default if key is not in the dictionary.\n\n        Return the value for key if key is in the dictionary, else default.\n        '''\n        if key in self:\n            return self[key]\n        self[key] = default\n        return default\n\n    @_recursive_repr()\n    def __repr__(self):\n        'od.__repr__() <==> repr(od)'\n        if not self:\n            return '%s()' % (self.__class__.__name__,)\n        return '%s(%r)' % (self.__class__.__name__, list(self.items()))\n\n    def __reduce__(self):\n        'Return state information for pickling'\n        inst_dict = vars(self).copy()\n        for k in vars(OrderedDict()):\n            inst_dict.pop(k, None)\n        return self.__class__, (), inst_dict or None, None, iter(self.items())\n\n    def copy(self):\n        'od.copy() -> a shallow copy of od'\n        return self.__class__(self)\n\n    @classmethod\n    def fromkeys(cls, iterable, value=None):\n        '''Create a new ordered dictionary with keys from iterable and values set to value.\n        '''\n        self = cls()\n        for key in iterable:\n            self[key] = value\n        return self\n\n    def __eq__(self, other):\n        '''od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive\n        while comparison to a regular mapping is order-insensitive.\n\n        '''\n        if isinstance(other, OrderedDict):\n            return dict.__eq__(self, other) and all(map(_eq, self, other))\n        return dict.__eq__(self, other)\n\n    def __ior__(self, other):\n        self.update(other)\n        return self\n\n    def __or__(self, other):\n        if not isinstance(other, dict):\n            return NotImplemented\n        new = self.__class__(self)\n        new.update(other)\n        return new\n\n    def __ror__(self, other):\n        if not isinstance(other, dict):\n            return NotImplemented\n        new = self.__class__(other)\n        new.update(self)\n        return new\n\n\ntry:\n    from _collections import OrderedDict\nexcept ImportError:\n    # Leave the pure Python version in place.\n    pass\n\n\n################################################################################\n### namedtuple\n################################################################################\n\ntry:\n    from _collections import _tuplegetter\nexcept ImportError:\n    _tuplegetter = lambda index, doc: property(_itemgetter(index), doc=doc)\n\ndef namedtuple(typename, field_names, *, rename=False, defaults=None, module=None):\n    \"\"\"Returns a new subclass of tuple with named fields.\n\n    >>> Point = namedtuple('Point', ['x', 'y'])\n    >>> Point.__doc__                   # docstring for the new class\n    'Point(x, y)'\n    >>> p = Point(11, y=22)             # instantiate with positional args or keywords\n    >>> p[0] + p[1]                     # indexable like a plain tuple\n    33\n    >>> x, y = p                        # unpack like a regular tuple\n    >>> x, y\n    (11, 22)\n    >>> p.x + p.y                       # fields also accessible by name\n    33\n    >>> d = p._asdict()                 # convert to a dictionary\n    >>> d['x']\n    11\n    >>> Point(**d)                      # convert from a dictionary\n    Point(x=11, y=22)\n    >>> p._replace(x=100)               # _replace() is like str.replace() but targets named fields\n    Point(x=100, y=22)\n\n    \"\"\"\n\n    # Validate the field names.  At the user's option, either generate an error\n    # message or automatically replace the field name with a valid name.\n    if isinstance(field_names, str):\n        field_names = field_names.replace(',', ' ').split()\n    field_names = list(map(str, field_names))\n    typename = _sys.intern(str(typename))\n\n    if rename:\n        seen = set()\n        for index, name in enumerate(field_names):\n            if (not name.isidentifier()\n                or _iskeyword(name)\n                or name.startswith('_')\n                or name in seen):\n                field_names[index] = f'_{index}'\n            seen.add(name)\n\n    for name in [typename] + field_names:\n        if type(name) is not str:\n            raise TypeError('Type names and field names must be strings')\n        if not name.isidentifier():\n            raise ValueError('Type names and field names must be valid '\n                             f'identifiers: {name!r}')\n        if _iskeyword(name):\n            raise ValueError('Type names and field names cannot be a '\n                             f'keyword: {name!r}')\n\n    seen = set()\n    for name in field_names:\n        if name.startswith('_') and not rename:\n            raise ValueError('Field names cannot start with an underscore: '\n                             f'{name!r}')\n        if name in seen:\n            raise ValueError(f'Encountered duplicate field name: {name!r}')\n        seen.add(name)\n\n    field_defaults = {}\n    if defaults is not None:\n        defaults = tuple(defaults)\n        if len(defaults) > len(field_names):\n            raise TypeError('Got more default values than field names')\n        field_defaults = dict(reversed(list(zip(reversed(field_names),\n                                                reversed(defaults)))))\n\n    # Variables used in the methods and docstrings\n    field_names = tuple(map(_sys.intern, field_names))\n    num_fields = len(field_names)\n    arg_list = ', '.join(field_names)\n    if num_fields == 1:\n        arg_list += ','\n    repr_fmt = '(' + ', '.join(f'{name}=%r' for name in field_names) + ')'\n    tuple_new = tuple.__new__\n    _dict, _tuple, _len, _map, _zip = dict, tuple, len, map, zip\n\n    # Create all the named tuple methods to be added to the class namespace\n\n    namespace = {\n        '_tuple_new': tuple_new,\n        '__builtins__': {},\n        '__name__': f'namedtuple_{typename}',\n    }\n    code = f'lambda _cls, {arg_list}: _tuple_new(_cls, ({arg_list}))'\n    __new__ = eval(code, namespace)\n    __new__.__name__ = '__new__'\n    __new__.__doc__ = f'Create new instance of {typename}({arg_list})'\n    if defaults is not None:\n        __new__.__defaults__ = defaults\n\n    @classmethod\n    def _make(cls, iterable):\n        result = tuple_new(cls, iterable)\n        if _len(result) != num_fields:\n            raise TypeError(f'Expected {num_fields} arguments, got {len(result)}')\n        return result\n\n    _make.__func__.__doc__ = (f'Make a new {typename} object from a sequence '\n                              'or iterable')\n\n    def _replace(self, /, **kwds):\n        result = self._make(_map(kwds.pop, field_names, self))\n        if kwds:\n            raise ValueError(f'Got unexpected field names: {list(kwds)!r}')\n        return result\n\n    _replace.__doc__ = (f'Return a new {typename} object replacing specified '\n                        'fields with new values')\n\n    def __repr__(self):\n        'Return a nicely formatted representation string'\n        return self.__class__.__name__ + repr_fmt % self\n\n    def _asdict(self):\n        'Return a new dict which maps field names to their values.'\n        return _dict(_zip(self._fields, self))\n\n    def __getnewargs__(self):\n        'Return self as a plain tuple.  Used by copy and pickle.'\n        return _tuple(self)\n\n    # Modify function metadata to help with introspection and debugging\n    for method in (\n        __new__,\n        _make.__func__,\n        _replace,\n        __repr__,\n        _asdict,\n        __getnewargs__,\n    ):\n        method.__qualname__ = f'{typename}.{method.__name__}'\n\n    # Build-up the class namespace dictionary\n    # and use type() to build the result class\n    class_namespace = {\n        '__doc__': f'{typename}({arg_list})',\n        '__slots__': (),\n        '_fields': field_names,\n        '_field_defaults': field_defaults,\n        '__new__': __new__,\n        '_make': _make,\n        '_replace': _replace,\n        '__repr__': __repr__,\n        '_asdict': _asdict,\n        '__getnewargs__': __getnewargs__,\n    }\n    for index, name in enumerate(field_names):\n        doc = _sys.intern(f'Alias for field number {index}')\n        class_namespace[name] = _tuplegetter(index, doc)\n\n    result = type(typename, (tuple,), class_namespace)\n\n    # For pickling to work, the __module__ variable needs to be set to the frame\n    # where the named tuple is created.  Bypass this step in environments where\n    # sys._getframe is not defined (Jython for example) or sys._getframe is not\n    # defined for arguments greater than 0 (IronPython), or where the user has\n    # specified a particular module.\n    if module is None:\n        try:\n            module = _sys._getframe(1).f_globals.get('__name__', '__main__')\n        except (AttributeError, ValueError):\n            pass\n    if module is not None:\n        result.__module__ = module\n\n    return result\n\n\n########################################################################\n###  Counter\n########################################################################\n\ndef _count_elements(mapping, iterable):\n    'Tally elements from the iterable.'\n    mapping_get = mapping.get\n    for elem in iterable:\n        mapping[elem] = mapping_get(elem, 0) + 1\n\ntry:                                    # Load C helper function if available\n    from _collections import _count_elements\nexcept ImportError:\n    pass\n\nclass Counter(dict):\n    '''Dict subclass for counting hashable items.  Sometimes called a bag\n    or multiset.  Elements are stored as dictionary keys and their counts\n    are stored as dictionary values.\n\n    >>> c = Counter('abcdeabcdabcaba')  # count elements from a string\n\n    >>> c.most_common(3)                # three most common elements\n    [('a', 5), ('b', 4), ('c', 3)]\n    >>> sorted(c)                       # list all unique elements\n    ['a', 'b', 'c', 'd', 'e']\n    >>> ''.join(sorted(c.elements()))   # list elements with repetitions\n    'aaaaabbbbcccdde'\n    >>> sum(c.values())                 # total of all counts\n    15\n\n    >>> c['a']                          # count of letter 'a'\n    5\n    >>> for elem in 'shazam':           # update counts from an iterable\n    ...     c[elem] += 1                # by adding 1 to each element's count\n    >>> c['a']                          # now there are seven 'a'\n    7\n    >>> del c['b']                      # remove all 'b'\n    >>> c['b']                          # now there are zero 'b'\n    0\n\n    >>> d = Counter('simsalabim')       # make another counter\n    >>> c.update(d)                     # add in the second counter\n    >>> c['a']                          # now there are nine 'a'\n    9\n\n    >>> c.clear()                       # empty the counter\n    >>> c\n    Counter()\n\n    Note:  If a count is set to zero or reduced to zero, it will remain\n    in the counter until the entry is deleted or the counter is cleared:\n\n    >>> c = Counter('aaabbc')\n    >>> c['b'] -= 2                     # reduce the count of 'b' by two\n    >>> c.most_common()                 # 'b' is still in, but its count is zero\n    [('a', 3), ('c', 1), ('b', 0)]\n\n    '''\n    # References:\n    #   http://en.wikipedia.org/wiki/Multiset\n    #   http://www.gnu.org/software/smalltalk/manual-base/html_node/Bag.html\n    #   http://www.demo2s.com/Tutorial/Cpp/0380__set-multiset/Catalog0380__set-multiset.htm\n    #   http://code.activestate.com/recipes/259174/\n    #   Knuth, TAOCP Vol. II section 4.6.3\n\n    def __init__(self, iterable=None, /, **kwds):\n        '''Create a new, empty Counter object.  And if given, count elements\n        from an input iterable.  Or, initialize the count from another mapping\n        of elements to their counts.\n\n        >>> c = Counter()                           # a new, empty counter\n        >>> c = Counter('gallahad')                 # a new counter from an iterable\n        >>> c = Counter({'a': 4, 'b': 2})           # a new counter from a mapping\n        >>> c = Counter(a=4, b=2)                   # a new counter from keyword args\n\n        '''\n        super().__init__()\n        self.update(iterable, **kwds)\n\n    def __missing__(self, key):\n        'The count of elements not in the Counter is zero.'\n        # Needed so that self[missing_item] does not raise KeyError\n        return 0\n\n    def most_common(self, n=None):\n        '''List the n most common elements and their counts from the most\n        common to the least.  If n is None, then list all element counts.\n\n        >>> Counter('abracadabra').most_common(3)\n        [('a', 5), ('b', 2), ('r', 2)]\n\n        '''\n        # Emulate Bag.sortedByCount from Smalltalk\n        if n is None:\n            return sorted(self.items(), key=_itemgetter(1), reverse=True)\n        return _heapq.nlargest(n, self.items(), key=_itemgetter(1))\n\n    def elements(self):\n        '''Iterator over elements repeating each as many times as its count.\n\n        >>> c = Counter('ABCABC')\n        >>> sorted(c.elements())\n        ['A', 'A', 'B', 'B', 'C', 'C']\n\n        # Knuth's example for prime factors of 1836:  2**2 * 3**3 * 17**1\n        >>> prime_factors = Counter({2: 2, 3: 3, 17: 1})\n        >>> product = 1\n        >>> for factor in prime_factors.elements():     # loop over factors\n        ...     product *= factor                       # and multiply them\n        >>> product\n        1836\n\n        Note, if an element's count has been set to zero or is a negative\n        number, elements() will ignore it.\n\n        '''\n        # Emulate Bag.do from Smalltalk and Multiset.begin from C++.\n        return _chain.from_iterable(_starmap(_repeat, self.items()))\n\n    # Override dict methods where necessary\n\n    @classmethod\n    def fromkeys(cls, iterable, v=None):\n        # There is no equivalent method for counters because the semantics\n        # would be ambiguous in cases such as Counter.fromkeys('aaabbc', v=2).\n        # Initializing counters to zero values isn't necessary because zero\n        # is already the default value for counter lookups.  Initializing\n        # to one is easily accomplished with Counter(set(iterable)).  For\n        # more exotic cases, create a dictionary first using a dictionary\n        # comprehension or dict.fromkeys().\n        raise NotImplementedError(\n            'Counter.fromkeys() is undefined.  Use Counter(iterable) instead.')\n\n    def update(self, iterable=None, /, **kwds):\n        '''Like dict.update() but add counts instead of replacing them.\n\n        Source can be an iterable, a dictionary, or another Counter instance.\n\n        >>> c = Counter('which')\n        >>> c.update('witch')           # add elements from another iterable\n        >>> d = Counter('watch')\n        >>> c.update(d)                 # add elements from another counter\n        >>> c['h']                      # four 'h' in which, witch, and watch\n        4\n\n        '''\n        # The regular dict.update() operation makes no sense here because the\n        # replace behavior results in the some of original untouched counts\n        # being mixed-in with all of the other counts for a mismash that\n        # doesn't have a straight-forward interpretation in most counting\n        # contexts.  Instead, we implement straight-addition.  Both the inputs\n        # and outputs are allowed to contain zero and negative counts.\n\n        if iterable is not None:\n            if isinstance(iterable, _collections_abc.Mapping):\n                if self:\n                    self_get = self.get\n                    for elem, count in iterable.items():\n                        self[elem] = count + self_get(elem, 0)\n                else:\n                    # fast path when counter is empty\n                    super().update(iterable)\n            else:\n                _count_elements(self, iterable)\n        if kwds:\n            self.update(kwds)\n\n    def subtract(self, iterable=None, /, **kwds):\n        '''Like dict.update() but subtracts counts instead of replacing them.\n        Counts can be reduced below zero.  Both the inputs and outputs are\n        allowed to contain zero and negative counts.\n\n        Source can be an iterable, a dictionary, or another Counter instance.\n\n        >>> c = Counter('which')\n        >>> c.subtract('witch')             # subtract elements from another iterable\n        >>> c.subtract(Counter('watch'))    # subtract elements from another counter\n        >>> c['h']                          # 2 in which, minus 1 in witch, minus 1 in watch\n        0\n        >>> c['w']                          # 1 in which, minus 1 in witch, minus 1 in watch\n        -1\n\n        '''\n        if iterable is not None:\n            self_get = self.get\n            if isinstance(iterable, _collections_abc.Mapping):\n                for elem, count in iterable.items():\n                    self[elem] = self_get(elem, 0) - count\n            else:\n                for elem in iterable:\n                    self[elem] = self_get(elem, 0) - 1\n        if kwds:\n            self.subtract(kwds)\n\n    def copy(self):\n        'Return a shallow copy.'\n        return self.__class__(self)\n\n    def __reduce__(self):\n        return self.__class__, (dict(self),)\n\n    def __delitem__(self, elem):\n        'Like dict.__delitem__() but does not raise KeyError for missing values.'\n        if elem in self:\n            super().__delitem__(elem)\n\n    def __repr__(self):\n        if not self:\n            return f'{self.__class__.__name__}()'\n        try:\n            # dict() preserves the ordering returned by most_common()\n            d = dict(self.most_common())\n        except TypeError:\n            # handle case where values are not orderable\n            d = dict(self)\n        return f'{self.__class__.__name__}({d!r})'\n\n    # Multiset-style mathematical operations discussed in:\n    #       Knuth TAOCP Volume II section 4.6.3 exercise 19\n    #       and at http://en.wikipedia.org/wiki/Multiset\n    #\n    # Outputs guaranteed to only include positive counts.\n    #\n    # To strip negative and zero counts, add-in an empty counter:\n    #       c += Counter()\n    #\n    # Rich comparison operators for multiset subset and superset tests\n    # are deliberately omitted due to semantic conflicts with the\n    # existing inherited dict equality method.  Subset and superset\n    # semantics ignore zero counts and require that p\u2264q \u2227 p\u2265q \u2192 p=q;\n    # however, that would not be the case for p=Counter(a=1, b=0)\n    # and q=Counter(a=1) where the dictionaries are not equal.\n\n    def __add__(self, other):\n        '''Add counts from two counters.\n\n        >>> Counter('abbb') + Counter('bcc')\n        Counter({'b': 4, 'c': 2, 'a': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            newcount = count + other[elem]\n            if newcount > 0:\n                result[elem] = newcount\n        for elem, count in other.items():\n            if elem not in self and count > 0:\n                result[elem] = count\n        return result\n\n    def __sub__(self, other):\n        ''' Subtract count, but keep only results with positive counts.\n\n        >>> Counter('abbbc') - Counter('bccd')\n        Counter({'b': 2, 'a': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            newcount = count - other[elem]\n            if newcount > 0:\n                result[elem] = newcount\n        for elem, count in other.items():\n            if elem not in self and count < 0:\n                result[elem] = 0 - count\n        return result\n\n    def __or__(self, other):\n        '''Union is the maximum of value in either of the input counters.\n\n        >>> Counter('abbb') | Counter('bcc')\n        Counter({'b': 3, 'c': 2, 'a': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            other_count = other[elem]\n            newcount = other_count if count < other_count else count\n            if newcount > 0:\n                result[elem] = newcount\n        for elem, count in other.items():\n            if elem not in self and count > 0:\n                result[elem] = count\n        return result\n\n    def __and__(self, other):\n        ''' Intersection is the minimum of corresponding counts.\n\n        >>> Counter('abbb') & Counter('bcc')\n        Counter({'b': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            other_count = other[elem]\n            newcount = count if count < other_count else other_count\n            if newcount > 0:\n                result[elem] = newcount\n        return result\n\n    def __pos__(self):\n        'Adds an empty counter, effectively stripping negative and zero counts'\n        result = Counter()\n        for elem, count in self.items():\n            if count > 0:\n                result[elem] = count\n        return result\n\n    def __neg__(self):\n        '''Subtracts from an empty counter.  Strips positive and zero counts,\n        and flips the sign on negative counts.\n\n        '''\n        result = Counter()\n        for elem, count in self.items():\n            if count < 0:\n                result[elem] = 0 - count\n        return result\n\n    def _keep_positive(self):\n        '''Internal method to strip elements with a negative or zero count'''\n        nonpositive = [elem for elem, count in self.items() if not count > 0]\n        for elem in nonpositive:\n            del self[elem]\n        return self\n\n    def __iadd__(self, other):\n        '''Inplace add from another counter, keeping only positive counts.\n\n        >>> c = Counter('abbb')\n        >>> c += Counter('bcc')\n        >>> c\n        Counter({'b': 4, 'c': 2, 'a': 1})\n\n        '''\n        for elem, count in other.items():\n            self[elem] += count\n        return self._keep_positive()\n\n    def __isub__(self, other):\n        '''Inplace subtract counter, but keep only results with positive counts.\n\n        >>> c = Counter('abbbc')\n        >>> c -= Counter('bccd')\n        >>> c\n        Counter({'b': 2, 'a': 1})\n\n        '''\n        for elem, count in other.items():\n            self[elem] -= count\n        return self._keep_positive()\n\n    def __ior__(self, other):\n        '''Inplace union is the maximum of value from either counter.\n\n        >>> c = Counter('abbb')\n        >>> c |= Counter('bcc')\n        >>> c\n        Counter({'b': 3, 'c': 2, 'a': 1})\n\n        '''\n        for elem, other_count in other.items():\n            count = self[elem]\n            if other_count > count:\n                self[elem] = other_count\n        return self._keep_positive()\n\n    def __iand__(self, other):\n        '''Inplace intersection is the minimum of corresponding counts.\n\n        >>> c = Counter('abbb')\n        >>> c &= Counter('bcc')\n        >>> c\n        Counter({'b': 1})\n\n        '''\n        for elem, count in self.items():\n            other_count = other[elem]\n            if other_count < count:\n                self[elem] = other_count\n        return self._keep_positive()\n\n\n########################################################################\n###  ChainMap\n########################################################################\n\nclass ChainMap(_collections_abc.MutableMapping):\n    ''' A ChainMap groups multiple dicts (or other mappings) together\n    to create a single, updateable view.\n\n    The underlying mappings are stored in a list.  That list is public and can\n    be accessed or updated using the *maps* attribute.  There is no other\n    state.\n\n    Lookups search the underlying mappings successively until a key is found.\n    In contrast, writes, updates, and deletions only operate on the first\n    mapping.\n\n    '''\n\n    def __init__(self, *maps):\n        '''Initialize a ChainMap by setting *maps* to the given mappings.\n        If no mappings are provided, a single empty dictionary is used.\n\n        '''\n        self.maps = list(maps) or [{}]          # always at least one map\n\n    def __missing__(self, key):\n        raise KeyError(key)\n\n    def __getitem__(self, key):\n        for mapping in self.maps:\n            try:\n                return mapping[key]             # can't use 'key in mapping' with defaultdict\n            except KeyError:\n                pass\n        return self.__missing__(key)            # support subclasses that define __missing__\n\n    def get(self, key, default=None):\n        return self[key] if key in self else default\n\n    def __len__(self):\n        return len(set().union(*self.maps))     # reuses stored hash values if possible\n\n    def __iter__(self):\n        d = {}\n        for mapping in reversed(self.maps):\n            d.update(dict.fromkeys(mapping))    # reuses stored hash values if possible\n        return iter(d)\n\n    def __contains__(self, key):\n        return any(key in m for m in self.maps)\n\n    def __bool__(self):\n        return any(self.maps)\n\n    @_recursive_repr()\n    def __repr__(self):\n        return f'{self.__class__.__name__}({\", \".join(map(repr, self.maps))})'\n\n    @classmethod\n    def fromkeys(cls, iterable, *args):\n        'Create a ChainMap with a single dict created from the iterable.'\n        return cls(dict.fromkeys(iterable, *args))\n\n    def copy(self):\n        'New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]'\n        return self.__class__(self.maps[0].copy(), *self.maps[1:])\n\n    __copy__ = copy\n\n    def new_child(self, m=None):                # like Django's Context.push()\n        '''New ChainMap with a new map followed by all previous maps.\n        If no map is provided, an empty dict is used.\n        '''\n        if m is None:\n            m = {}\n        return self.__class__(m, *self.maps)\n\n    @property\n    def parents(self):                          # like Django's Context.pop()\n        'New ChainMap from maps[1:].'\n        return self.__class__(*self.maps[1:])\n\n    def __setitem__(self, key, value):\n        self.maps[0][key] = value\n\n    def __delitem__(self, key):\n        try:\n            del self.maps[0][key]\n        except KeyError:\n            raise KeyError(f'Key not found in the first mapping: {key!r}')\n\n    def popitem(self):\n        'Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.'\n        try:\n            return self.maps[0].popitem()\n        except KeyError:\n            raise KeyError('No keys found in the first mapping.')\n\n    def pop(self, key, *args):\n        'Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0].'\n        try:\n            return self.maps[0].pop(key, *args)\n        except KeyError:\n            raise KeyError(f'Key not found in the first mapping: {key!r}')\n\n    def clear(self):\n        'Clear maps[0], leaving maps[1:] intact.'\n        self.maps[0].clear()\n\n    def __ior__(self, other):\n        self.maps[0].update(other)\n        return self\n\n    def __or__(self, other):\n        if not isinstance(other, _collections_abc.Mapping):\n            return NotImplemented\n        m = self.copy()\n        m.maps[0].update(other)\n        return m\n\n    def __ror__(self, other):\n        if not isinstance(other, _collections_abc.Mapping):\n            return NotImplemented\n        m = dict(other)\n        for child in reversed(self.maps):\n            m.update(child)\n        return self.__class__(m)\n\n\n################################################################################\n### UserDict\n################################################################################\n\nclass UserDict(_collections_abc.MutableMapping):\n\n    # Start by filling-out the abstract methods\n    def __init__(self, dict=None, /, **kwargs):\n        self.data = {}\n        if dict is not None:\n            self.update(dict)\n        if kwargs:\n            self.update(kwargs)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, key):\n        if key in self.data:\n            return self.data[key]\n        if hasattr(self.__class__, \"__missing__\"):\n            return self.__class__.__missing__(self, key)\n        raise KeyError(key)\n\n    def __setitem__(self, key, item):\n        self.data[key] = item\n\n    def __delitem__(self, key):\n        del self.data[key]\n\n    def __iter__(self):\n        return iter(self.data)\n\n    # Modify __contains__ to work correctly when __missing__ is present\n    def __contains__(self, key):\n        return key in self.data\n\n    # Now, add the methods in dicts but not in MutableMapping\n    def __repr__(self):\n        return repr(self.data)\n\n    def __or__(self, other):\n        if isinstance(other, UserDict):\n            return self.__class__(self.data | other.data)\n        if isinstance(other, dict):\n            return self.__class__(self.data | other)\n        return NotImplemented\n\n    def __ror__(self, other):\n        if isinstance(other, UserDict):\n            return self.__class__(other.data | self.data)\n        if isinstance(other, dict):\n            return self.__class__(other | self.data)\n        return NotImplemented\n\n    def __ior__(self, other):\n        if isinstance(other, UserDict):\n            self.data |= other.data\n        else:\n            self.data |= other\n        return self\n\n    def __copy__(self):\n        inst = self.__class__.__new__(self.__class__)\n        inst.__dict__.update(self.__dict__)\n        # Create a copy and avoid triggering descriptors\n        inst.__dict__[\"data\"] = self.__dict__[\"data\"].copy()\n        return inst\n\n    def copy(self):\n        if self.__class__ is UserDict:\n            return UserDict(self.data.copy())\n        import copy\n        data = self.data\n        try:\n            self.data = {}\n            c = copy.copy(self)\n        finally:\n            self.data = data\n        c.update(self)\n        return c\n\n    @classmethod\n    def fromkeys(cls, iterable, value=None):\n        d = cls()\n        for key in iterable:\n            d[key] = value\n        return d\n\n\n################################################################################\n### UserList\n################################################################################\n\nclass UserList(_collections_abc.MutableSequence):\n    \"\"\"A more or less complete user-defined wrapper around list objects.\"\"\"\n\n    def __init__(self, initlist=None):\n        self.data = []\n        if initlist is not None:\n            # XXX should this accept an arbitrary sequence?\n            if type(initlist) == type(self.data):\n                self.data[:] = initlist\n            elif isinstance(initlist, UserList):\n                self.data[:] = initlist.data[:]\n            else:\n                self.data = list(initlist)\n\n    def __repr__(self):\n        return repr(self.data)\n\n    def __lt__(self, other):\n        return self.data < self.__cast(other)\n\n    def __le__(self, other):\n        return self.data <= self.__cast(other)\n\n    def __eq__(self, other):\n        return self.data == self.__cast(other)\n\n    def __gt__(self, other):\n        return self.data > self.__cast(other)\n\n    def __ge__(self, other):\n        return self.data >= self.__cast(other)\n\n    def __cast(self, other):\n        return other.data if isinstance(other, UserList) else other\n\n    def __contains__(self, item):\n        return item in self.data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i):\n        if isinstance(i, slice):\n            return self.__class__(self.data[i])\n        else:\n            return self.data[i]\n\n    def __setitem__(self, i, item):\n        self.data[i] = item\n\n    def __delitem__(self, i):\n        del self.data[i]\n\n    def __add__(self, other):\n        if isinstance(other, UserList):\n            return self.__class__(self.data + other.data)\n        elif isinstance(other, type(self.data)):\n            return self.__class__(self.data + other)\n        return self.__class__(self.data + list(other))\n\n    def __radd__(self, other):\n        if isinstance(other, UserList):\n            return self.__class__(other.data + self.data)\n        elif isinstance(other, type(self.data)):\n            return self.__class__(other + self.data)\n        return self.__class__(list(other) + self.data)\n\n    def __iadd__(self, other):\n        if isinstance(other, UserList):\n            self.data += other.data\n        elif isinstance(other, type(self.data)):\n            self.data += other\n        else:\n            self.data += list(other)\n        return self\n\n    def __mul__(self, n):\n        return self.__class__(self.data * n)\n\n    __rmul__ = __mul__\n\n    def __imul__(self, n):\n        self.data *= n\n        return self\n\n    def __copy__(self):\n        inst = self.__class__.__new__(self.__class__)\n        inst.__dict__.update(self.__dict__)\n        # Create a copy and avoid triggering descriptors\n        inst.__dict__[\"data\"] = self.__dict__[\"data\"][:]\n        return inst\n\n    def append(self, item):\n        self.data.append(item)\n\n    def insert(self, i, item):\n        self.data.insert(i, item)\n\n    def pop(self, i=-1):\n        return self.data.pop(i)\n\n    def remove(self, item):\n        self.data.remove(item)\n\n    def clear(self):\n        self.data.clear()\n\n    def copy(self):\n        return self.__class__(self)\n\n    def count(self, item):\n        return self.data.count(item)\n\n    def index(self, item, *args):\n        return self.data.index(item, *args)\n\n    def reverse(self):\n        self.data.reverse()\n\n    def sort(self, /, *args, **kwds):\n        self.data.sort(*args, **kwds)\n\n    def extend(self, other):\n        if isinstance(other, UserList):\n            self.data.extend(other.data)\n        else:\n            self.data.extend(other)\n\n\n################################################################################\n### UserString\n################################################################################\n\nclass UserString(_collections_abc.Sequence):\n\n    def __init__(self, seq):\n        if isinstance(seq, str):\n            self.data = seq\n        elif isinstance(seq, UserString):\n            self.data = seq.data[:]\n        else:\n            self.data = str(seq)\n\n    def __str__(self):\n        return str(self.data)\n\n    def __repr__(self):\n        return repr(self.data)\n\n    def __int__(self):\n        return int(self.data)\n\n    def __float__(self):\n        return float(self.data)\n\n    def __complex__(self):\n        return complex(self.data)\n\n    def __hash__(self):\n        return hash(self.data)\n\n    def __getnewargs__(self):\n        return (self.data[:],)\n\n    def __eq__(self, string):\n        if isinstance(string, UserString):\n            return self.data == string.data\n        return self.data == string\n\n    def __lt__(self, string):\n        if isinstance(string, UserString):\n            return self.data < string.data\n        return self.data < string\n\n    def __le__(self, string):\n        if isinstance(string, UserString):\n            return self.data <= string.data\n        return self.data <= string\n\n    def __gt__(self, string):\n        if isinstance(string, UserString):\n            return self.data > string.data\n        return self.data > string\n\n    def __ge__(self, string):\n        if isinstance(string, UserString):\n            return self.data >= string.data\n        return self.data >= string\n\n    def __contains__(self, char):\n        if isinstance(char, UserString):\n            char = char.data\n        return char in self.data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        return self.__class__(self.data[index])\n\n    def __add__(self, other):\n        if isinstance(other, UserString):\n            return self.__class__(self.data + other.data)\n        elif isinstance(other, str):\n            return self.__class__(self.data + other)\n        return self.__class__(self.data + str(other))\n\n    def __radd__(self, other):\n        if isinstance(other, str):\n            return self.__class__(other + self.data)\n        return self.__class__(str(other) + self.data)\n\n    def __mul__(self, n):\n        return self.__class__(self.data * n)\n\n    __rmul__ = __mul__\n\n    def __mod__(self, args):\n        return self.__class__(self.data % args)\n\n    def __rmod__(self, template):\n        return self.__class__(str(template) % self)\n\n    # the following methods are defined in alphabetical order:\n    def capitalize(self):\n        return self.__class__(self.data.capitalize())\n\n    def casefold(self):\n        return self.__class__(self.data.casefold())\n\n    def center(self, width, *args):\n        return self.__class__(self.data.center(width, *args))\n\n    def count(self, sub, start=0, end=_sys.maxsize):\n        if isinstance(sub, UserString):\n            sub = sub.data\n        return self.data.count(sub, start, end)\n\n    def removeprefix(self, prefix, /):\n        if isinstance(prefix, UserString):\n            prefix = prefix.data\n        return self.__class__(self.data.removeprefix(prefix))\n\n    def removesuffix(self, suffix, /):\n        if isinstance(suffix, UserString):\n            suffix = suffix.data\n        return self.__class__(self.data.removesuffix(suffix))\n\n    def encode(self, encoding='utf-8', errors='strict'):\n        encoding = 'utf-8' if encoding is None else encoding\n        errors = 'strict' if errors is None else errors\n        return self.data.encode(encoding, errors)\n\n    def endswith(self, suffix, start=0, end=_sys.maxsize):\n        return self.data.endswith(suffix, start, end)\n\n    def expandtabs(self, tabsize=8):\n        return self.__class__(self.data.expandtabs(tabsize))\n\n    def find(self, sub, start=0, end=_sys.maxsize):\n        if isinstance(sub, UserString):\n            sub = sub.data\n        return self.data.find(sub, start, end)\n\n    def format(self, /, *args, **kwds):\n        return self.data.format(*args, **kwds)\n\n    def format_map(self, mapping):\n        return self.data.format_map(mapping)\n\n    def index(self, sub, start=0, end=_sys.maxsize):\n        return self.data.index(sub, start, end)\n\n    def isalpha(self):\n        return self.data.isalpha()\n\n    def isalnum(self):\n        return self.data.isalnum()\n\n    def isascii(self):\n        return self.data.isascii()\n\n    def isdecimal(self):\n        return self.data.isdecimal()\n\n    def isdigit(self):\n        return self.data.isdigit()\n\n    def isidentifier(self):\n        return self.data.isidentifier()\n\n    def islower(self):\n        return self.data.islower()\n\n    def isnumeric(self):\n        return self.data.isnumeric()\n\n    def isprintable(self):\n        return self.data.isprintable()\n\n    def isspace(self):\n        return self.data.isspace()\n\n    def istitle(self):\n        return self.data.istitle()\n\n    def isupper(self):\n        return self.data.isupper()\n\n    def join(self, seq):\n        return self.data.join(seq)\n\n    def ljust(self, width, *args):\n        return self.__class__(self.data.ljust(width, *args))\n\n    def lower(self):\n        return self.__class__(self.data.lower())\n\n    def lstrip(self, chars=None):\n        return self.__class__(self.data.lstrip(chars))\n\n    maketrans = str.maketrans\n\n    def partition(self, sep):\n        return self.data.partition(sep)\n\n    def replace(self, old, new, maxsplit=-1):\n        if isinstance(old, UserString):\n            old = old.data\n        if isinstance(new, UserString):\n            new = new.data\n        return self.__class__(self.data.replace(old, new, maxsplit))\n\n    def rfind(self, sub, start=0, end=_sys.maxsize):\n        if isinstance(sub, UserString):\n            sub = sub.data\n        return self.data.rfind(sub, start, end)\n\n    def rindex(self, sub, start=0, end=_sys.maxsize):\n        return self.data.rindex(sub, start, end)\n\n    def rjust(self, width, *args):\n        return self.__class__(self.data.rjust(width, *args))\n\n    def rpartition(self, sep):\n        return self.data.rpartition(sep)\n\n    def rstrip(self, chars=None):\n        return self.__class__(self.data.rstrip(chars))\n\n    def split(self, sep=None, maxsplit=-1):\n        return self.data.split(sep, maxsplit)\n\n    def rsplit(self, sep=None, maxsplit=-1):\n        return self.data.rsplit(sep, maxsplit)\n\n    def splitlines(self, keepends=False):\n        return self.data.splitlines(keepends)\n\n    def startswith(self, prefix, start=0, end=_sys.maxsize):\n        return self.data.startswith(prefix, start, end)\n\n    def strip(self, chars=None):\n        return self.__class__(self.data.strip(chars))\n\n    def swapcase(self):\n        return self.__class__(self.data.swapcase())\n\n    def title(self):\n        return self.__class__(self.data.title())\n\n    def translate(self, *args):\n        return self.__class__(self.data.translate(*args))\n\n    def upper(self):\n        return self.__class__(self.data.upper())\n\n    def zfill(self, width):\n        return self.__class__(self.data.zfill(width))\n", 1508], "C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py": ["\"\"\"Heap queue algorithm (a.k.a. priority queue).\n\nHeaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for\nall k, counting elements from 0.  For the sake of comparison,\nnon-existing elements are considered to be infinite.  The interesting\nproperty of a heap is that a[0] is always its smallest element.\n\nUsage:\n\nheap = []            # creates an empty heap\nheappush(heap, item) # pushes a new item on the heap\nitem = heappop(heap) # pops the smallest item from the heap\nitem = heap[0]       # smallest item on the heap without popping it\nheapify(x)           # transforms list into a heap, in-place, in linear time\nitem = heapreplace(heap, item) # pops and returns smallest item, and adds\n                               # new item; the heap size is unchanged\n\nOur API differs from textbook heap algorithms as follows:\n\n- We use 0-based indexing.  This makes the relationship between the\n  index for a node and the indexes for its children slightly less\n  obvious, but is more suitable since Python uses 0-based indexing.\n\n- Our heappop() method returns the smallest item, not the largest.\n\nThese two make it possible to view the heap as a regular Python list\nwithout surprises: heap[0] is the smallest item, and heap.sort()\nmaintains the heap invariant!\n\"\"\"\n\n# Original code by Kevin O'Connor, augmented by Tim Peters and Raymond Hettinger\n\n__about__ = \"\"\"Heap queues\n\n[explanation by Fran\u00e7ois Pinard]\n\nHeaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for\nall k, counting elements from 0.  For the sake of comparison,\nnon-existing elements are considered to be infinite.  The interesting\nproperty of a heap is that a[0] is always its smallest element.\n\nThe strange invariant above is meant to be an efficient memory\nrepresentation for a tournament.  The numbers below are `k', not a[k]:\n\n                                   0\n\n                  1                                 2\n\n          3               4                5               6\n\n      7       8       9       10      11      12      13      14\n\n    15 16   17 18   19 20   21 22   23 24   25 26   27 28   29 30\n\n\nIn the tree above, each cell `k' is topping `2*k+1' and `2*k+2'.  In\na usual binary tournament we see in sports, each cell is the winner\nover the two cells it tops, and we can trace the winner down the tree\nto see all opponents s/he had.  However, in many computer applications\nof such tournaments, we do not need to trace the history of a winner.\nTo be more memory efficient, when a winner is promoted, we try to\nreplace it by something else at a lower level, and the rule becomes\nthat a cell and the two cells it tops contain three different items,\nbut the top cell \"wins\" over the two topped cells.\n\nIf this heap invariant is protected at all time, index 0 is clearly\nthe overall winner.  The simplest algorithmic way to remove it and\nfind the \"next\" winner is to move some loser (let's say cell 30 in the\ndiagram above) into the 0 position, and then percolate this new 0 down\nthe tree, exchanging values, until the invariant is re-established.\nThis is clearly logarithmic on the total number of items in the tree.\nBy iterating over all items, you get an O(n ln n) sort.\n\nA nice feature of this sort is that you can efficiently insert new\nitems while the sort is going on, provided that the inserted items are\nnot \"better\" than the last 0'th element you extracted.  This is\nespecially useful in simulation contexts, where the tree holds all\nincoming events, and the \"win\" condition means the smallest scheduled\ntime.  When an event schedule other events for execution, they are\nscheduled into the future, so they can easily go into the heap.  So, a\nheap is a good structure for implementing schedulers (this is what I\nused for my MIDI sequencer :-).\n\nVarious structures for implementing schedulers have been extensively\nstudied, and heaps are good for this, as they are reasonably speedy,\nthe speed is almost constant, and the worst case is not much different\nthan the average case.  However, there are other representations which\nare more efficient overall, yet the worst cases might be terrible.\n\nHeaps are also very useful in big disk sorts.  You most probably all\nknow that a big sort implies producing \"runs\" (which are pre-sorted\nsequences, which size is usually related to the amount of CPU memory),\nfollowed by a merging passes for these runs, which merging is often\nvery cleverly organised[1].  It is very important that the initial\nsort produces the longest runs possible.  Tournaments are a good way\nto that.  If, using all the memory available to hold a tournament, you\nreplace and percolate items that happen to fit the current run, you'll\nproduce runs which are twice the size of the memory for random input,\nand much better for input fuzzily ordered.\n\nMoreover, if you output the 0'th item on disk and get an input which\nmay not fit in the current tournament (because the value \"wins\" over\nthe last output value), it cannot fit in the heap, so the size of the\nheap decreases.  The freed memory could be cleverly reused immediately\nfor progressively building a second heap, which grows at exactly the\nsame rate the first heap is melting.  When the first heap completely\nvanishes, you switch heaps and start a new run.  Clever and quite\neffective!\n\nIn a word, heaps are useful memory structures to know.  I use them in\na few applications, and I think it is good to keep a `heap' module\naround. :-)\n\n--------------------\n[1] The disk balancing algorithms which are current, nowadays, are\nmore annoying than clever, and this is a consequence of the seeking\ncapabilities of the disks.  On devices which cannot seek, like big\ntape drives, the story was quite different, and one had to be very\nclever to ensure (far in advance) that each tape movement will be the\nmost effective possible (that is, will best participate at\n\"progressing\" the merge).  Some tapes were even able to read\nbackwards, and this was also used to avoid the rewinding time.\nBelieve me, real good tape sorts were quite spectacular to watch!\nFrom all times, sorting has always been a Great Art! :-)\n\"\"\"\n\n__all__ = ['heappush', 'heappop', 'heapify', 'heapreplace', 'merge',\n           'nlargest', 'nsmallest', 'heappushpop']\n\ndef heappush(heap, item):\n    \"\"\"Push item onto heap, maintaining the heap invariant.\"\"\"\n    heap.append(item)\n    _siftdown(heap, 0, len(heap)-1)\n\ndef heappop(heap):\n    \"\"\"Pop the smallest item off the heap, maintaining the heap invariant.\"\"\"\n    lastelt = heap.pop()    # raises appropriate IndexError if heap is empty\n    if heap:\n        returnitem = heap[0]\n        heap[0] = lastelt\n        _siftup(heap, 0)\n        return returnitem\n    return lastelt\n\ndef heapreplace(heap, item):\n    \"\"\"Pop and return the current smallest value, and add the new item.\n\n    This is more efficient than heappop() followed by heappush(), and can be\n    more appropriate when using a fixed-size heap.  Note that the value\n    returned may be larger than item!  That constrains reasonable uses of\n    this routine unless written as part of a conditional replacement:\n\n        if item > heap[0]:\n            item = heapreplace(heap, item)\n    \"\"\"\n    returnitem = heap[0]    # raises appropriate IndexError if heap is empty\n    heap[0] = item\n    _siftup(heap, 0)\n    return returnitem\n\ndef heappushpop(heap, item):\n    \"\"\"Fast version of a heappush followed by a heappop.\"\"\"\n    if heap and heap[0] < item:\n        item, heap[0] = heap[0], item\n        _siftup(heap, 0)\n    return item\n\ndef heapify(x):\n    \"\"\"Transform list into a heap, in-place, in O(len(x)) time.\"\"\"\n    n = len(x)\n    # Transform bottom-up.  The largest index there's any point to looking at\n    # is the largest with a child index in-range, so must have 2*i + 1 < n,\n    # or i < (n-1)/2.  If n is even = 2*j, this is (2*j-1)/2 = j-1/2 so\n    # j-1 is the largest, which is n//2 - 1.  If n is odd = 2*j+1, this is\n    # (2*j+1-1)/2 = j so j-1 is the largest, and that's again n//2-1.\n    for i in reversed(range(n//2)):\n        _siftup(x, i)\n\ndef _heappop_max(heap):\n    \"\"\"Maxheap version of a heappop.\"\"\"\n    lastelt = heap.pop()    # raises appropriate IndexError if heap is empty\n    if heap:\n        returnitem = heap[0]\n        heap[0] = lastelt\n        _siftup_max(heap, 0)\n        return returnitem\n    return lastelt\n\ndef _heapreplace_max(heap, item):\n    \"\"\"Maxheap version of a heappop followed by a heappush.\"\"\"\n    returnitem = heap[0]    # raises appropriate IndexError if heap is empty\n    heap[0] = item\n    _siftup_max(heap, 0)\n    return returnitem\n\ndef _heapify_max(x):\n    \"\"\"Transform list into a maxheap, in-place, in O(len(x)) time.\"\"\"\n    n = len(x)\n    for i in reversed(range(n//2)):\n        _siftup_max(x, i)\n\n# 'heap' is a heap at all indices >= startpos, except possibly for pos.  pos\n# is the index of a leaf with a possibly out-of-order value.  Restore the\n# heap invariant.\ndef _siftdown(heap, startpos, pos):\n    newitem = heap[pos]\n    # Follow the path to the root, moving parents down until finding a place\n    # newitem fits.\n    while pos > startpos:\n        parentpos = (pos - 1) >> 1\n        parent = heap[parentpos]\n        if newitem < parent:\n            heap[pos] = parent\n            pos = parentpos\n            continue\n        break\n    heap[pos] = newitem\n\n# The child indices of heap index pos are already heaps, and we want to make\n# a heap at index pos too.  We do this by bubbling the smaller child of\n# pos up (and so on with that child's children, etc) until hitting a leaf,\n# then using _siftdown to move the oddball originally at index pos into place.\n#\n# We *could* break out of the loop as soon as we find a pos where newitem <=\n# both its children, but turns out that's not a good idea, and despite that\n# many books write the algorithm that way.  During a heap pop, the last array\n# element is sifted in, and that tends to be large, so that comparing it\n# against values starting from the root usually doesn't pay (= usually doesn't\n# get us out of the loop early).  See Knuth, Volume 3, where this is\n# explained and quantified in an exercise.\n#\n# Cutting the # of comparisons is important, since these routines have no\n# way to extract \"the priority\" from an array element, so that intelligence\n# is likely to be hiding in custom comparison methods, or in array elements\n# storing (priority, record) tuples.  Comparisons are thus potentially\n# expensive.\n#\n# On random arrays of length 1000, making this change cut the number of\n# comparisons made by heapify() a little, and those made by exhaustive\n# heappop() a lot, in accord with theory.  Here are typical results from 3\n# runs (3 just to demonstrate how small the variance is):\n#\n# Compares needed by heapify     Compares needed by 1000 heappops\n# --------------------------     --------------------------------\n# 1837 cut to 1663               14996 cut to 8680\n# 1855 cut to 1659               14966 cut to 8678\n# 1847 cut to 1660               15024 cut to 8703\n#\n# Building the heap by using heappush() 1000 times instead required\n# 2198, 2148, and 2219 compares:  heapify() is more efficient, when\n# you can use it.\n#\n# The total compares needed by list.sort() on the same lists were 8627,\n# 8627, and 8632 (this should be compared to the sum of heapify() and\n# heappop() compares):  list.sort() is (unsurprisingly!) more efficient\n# for sorting.\n\ndef _siftup(heap, pos):\n    endpos = len(heap)\n    startpos = pos\n    newitem = heap[pos]\n    # Bubble up the smaller child until hitting a leaf.\n    childpos = 2*pos + 1    # leftmost child position\n    while childpos < endpos:\n        # Set childpos to index of smaller child.\n        rightpos = childpos + 1\n        if rightpos < endpos and not heap[childpos] < heap[rightpos]:\n            childpos = rightpos\n        # Move the smaller child up.\n        heap[pos] = heap[childpos]\n        pos = childpos\n        childpos = 2*pos + 1\n    # The leaf at pos is empty now.  Put newitem there, and bubble it up\n    # to its final resting place (by sifting its parents down).\n    heap[pos] = newitem\n    _siftdown(heap, startpos, pos)\n\ndef _siftdown_max(heap, startpos, pos):\n    'Maxheap variant of _siftdown'\n    newitem = heap[pos]\n    # Follow the path to the root, moving parents down until finding a place\n    # newitem fits.\n    while pos > startpos:\n        parentpos = (pos - 1) >> 1\n        parent = heap[parentpos]\n        if parent < newitem:\n            heap[pos] = parent\n            pos = parentpos\n            continue\n        break\n    heap[pos] = newitem\n\ndef _siftup_max(heap, pos):\n    'Maxheap variant of _siftup'\n    endpos = len(heap)\n    startpos = pos\n    newitem = heap[pos]\n    # Bubble up the larger child until hitting a leaf.\n    childpos = 2*pos + 1    # leftmost child position\n    while childpos < endpos:\n        # Set childpos to index of larger child.\n        rightpos = childpos + 1\n        if rightpos < endpos and not heap[rightpos] < heap[childpos]:\n            childpos = rightpos\n        # Move the larger child up.\n        heap[pos] = heap[childpos]\n        pos = childpos\n        childpos = 2*pos + 1\n    # The leaf at pos is empty now.  Put newitem there, and bubble it up\n    # to its final resting place (by sifting its parents down).\n    heap[pos] = newitem\n    _siftdown_max(heap, startpos, pos)\n\ndef merge(*iterables, key=None, reverse=False):\n    '''Merge multiple sorted inputs into a single sorted output.\n\n    Similar to sorted(itertools.chain(*iterables)) but returns a generator,\n    does not pull the data into memory all at once, and assumes that each of\n    the input streams is already sorted (smallest to largest).\n\n    >>> list(merge([1,3,5,7], [0,2,4,8], [5,10,15,20], [], [25]))\n    [0, 1, 2, 3, 4, 5, 5, 7, 8, 10, 15, 20, 25]\n\n    If *key* is not None, applies a key function to each element to determine\n    its sort order.\n\n    >>> list(merge(['dog', 'horse'], ['cat', 'fish', 'kangaroo'], key=len))\n    ['dog', 'cat', 'fish', 'horse', 'kangaroo']\n\n    '''\n\n    h = []\n    h_append = h.append\n\n    if reverse:\n        _heapify = _heapify_max\n        _heappop = _heappop_max\n        _heapreplace = _heapreplace_max\n        direction = -1\n    else:\n        _heapify = heapify\n        _heappop = heappop\n        _heapreplace = heapreplace\n        direction = 1\n\n    if key is None:\n        for order, it in enumerate(map(iter, iterables)):\n            try:\n                next = it.__next__\n                h_append([next(), order * direction, next])\n            except StopIteration:\n                pass\n        _heapify(h)\n        while len(h) > 1:\n            try:\n                while True:\n                    value, order, next = s = h[0]\n                    yield value\n                    s[0] = next()           # raises StopIteration when exhausted\n                    _heapreplace(h, s)      # restore heap condition\n            except StopIteration:\n                _heappop(h)                 # remove empty iterator\n        if h:\n            # fast case when only a single iterator remains\n            value, order, next = h[0]\n            yield value\n            yield from next.__self__\n        return\n\n    for order, it in enumerate(map(iter, iterables)):\n        try:\n            next = it.__next__\n            value = next()\n            h_append([key(value), order * direction, value, next])\n        except StopIteration:\n            pass\n    _heapify(h)\n    while len(h) > 1:\n        try:\n            while True:\n                key_value, order, value, next = s = h[0]\n                yield value\n                value = next()\n                s[0] = key(value)\n                s[2] = value\n                _heapreplace(h, s)\n        except StopIteration:\n            _heappop(h)\n    if h:\n        key_value, order, value, next = h[0]\n        yield value\n        yield from next.__self__\n\n\n# Algorithm notes for nlargest() and nsmallest()\n# ==============================================\n#\n# Make a single pass over the data while keeping the k most extreme values\n# in a heap.  Memory consumption is limited to keeping k values in a list.\n#\n# Measured performance for random inputs:\n#\n#                                   number of comparisons\n#    n inputs     k-extreme values  (average of 5 trials)   % more than min()\n# -------------   ----------------  ---------------------   -----------------\n#      1,000           100                  3,317               231.7%\n#     10,000           100                 14,046                40.5%\n#    100,000           100                105,749                 5.7%\n#  1,000,000           100              1,007,751                 0.8%\n# 10,000,000           100             10,009,401                 0.1%\n#\n# Theoretical number of comparisons for k smallest of n random inputs:\n#\n# Step   Comparisons                  Action\n# ----   --------------------------   ---------------------------\n#  1     1.66 * k                     heapify the first k-inputs\n#  2     n - k                        compare remaining elements to top of heap\n#  3     k * (1 + lg2(k)) * ln(n/k)   replace the topmost value on the heap\n#  4     k * lg2(k) - (k/2)           final sort of the k most extreme values\n#\n# Combining and simplifying for a rough estimate gives:\n#\n#        comparisons = n + k * (log(k, 2) * log(n/k) + log(k, 2) + log(n/k))\n#\n# Computing the number of comparisons for step 3:\n# -----------------------------------------------\n# * For the i-th new value from the iterable, the probability of being in the\n#   k most extreme values is k/i.  For example, the probability of the 101st\n#   value seen being in the 100 most extreme values is 100/101.\n# * If the value is a new extreme value, the cost of inserting it into the\n#   heap is 1 + log(k, 2).\n# * The probability times the cost gives:\n#            (k/i) * (1 + log(k, 2))\n# * Summing across the remaining n-k elements gives:\n#            sum((k/i) * (1 + log(k, 2)) for i in range(k+1, n+1))\n# * This reduces to:\n#            (H(n) - H(k)) * k * (1 + log(k, 2))\n# * Where H(n) is the n-th harmonic number estimated by:\n#            gamma = 0.5772156649\n#            H(n) = log(n, e) + gamma + 1 / (2 * n)\n#   http://en.wikipedia.org/wiki/Harmonic_series_(mathematics)#Rate_of_divergence\n# * Substituting the H(n) formula:\n#            comparisons = k * (1 + log(k, 2)) * (log(n/k, e) + (1/n - 1/k) / 2)\n#\n# Worst-case for step 3:\n# ----------------------\n# In the worst case, the input data is reversed sorted so that every new element\n# must be inserted in the heap:\n#\n#             comparisons = 1.66 * k + log(k, 2) * (n - k)\n#\n# Alternative Algorithms\n# ----------------------\n# Other algorithms were not used because they:\n# 1) Took much more auxiliary memory,\n# 2) Made multiple passes over the data.\n# 3) Made more comparisons in common cases (small k, large n, semi-random input).\n# See the more detailed comparison of approach at:\n# http://code.activestate.com/recipes/577573-compare-algorithms-for-heapqsmallest\n\ndef nsmallest(n, iterable, key=None):\n    \"\"\"Find the n smallest elements in a dataset.\n\n    Equivalent to:  sorted(iterable, key=key)[:n]\n    \"\"\"\n\n    # Short-cut for n==1 is to use min()\n    if n == 1:\n        it = iter(iterable)\n        sentinel = object()\n        result = min(it, default=sentinel, key=key)\n        return [] if result is sentinel else [result]\n\n    # When n>=size, it's faster to use sorted()\n    try:\n        size = len(iterable)\n    except (TypeError, AttributeError):\n        pass\n    else:\n        if n >= size:\n            return sorted(iterable, key=key)[:n]\n\n    # When key is none, use simpler decoration\n    if key is None:\n        it = iter(iterable)\n        # put the range(n) first so that zip() doesn't\n        # consume one too many elements from the iterator\n        result = [(elem, i) for i, elem in zip(range(n), it)]\n        if not result:\n            return result\n        _heapify_max(result)\n        top = result[0][0]\n        order = n\n        _heapreplace = _heapreplace_max\n        for elem in it:\n            if elem < top:\n                _heapreplace(result, (elem, order))\n                top, _order = result[0]\n                order += 1\n        result.sort()\n        return [elem for (elem, order) in result]\n\n    # General case, slowest method\n    it = iter(iterable)\n    result = [(key(elem), i, elem) for i, elem in zip(range(n), it)]\n    if not result:\n        return result\n    _heapify_max(result)\n    top = result[0][0]\n    order = n\n    _heapreplace = _heapreplace_max\n    for elem in it:\n        k = key(elem)\n        if k < top:\n            _heapreplace(result, (k, order, elem))\n            top, _order, _elem = result[0]\n            order += 1\n    result.sort()\n    return [elem for (k, order, elem) in result]\n\ndef nlargest(n, iterable, key=None):\n    \"\"\"Find the n largest elements in a dataset.\n\n    Equivalent to:  sorted(iterable, key=key, reverse=True)[:n]\n    \"\"\"\n\n    # Short-cut for n==1 is to use max()\n    if n == 1:\n        it = iter(iterable)\n        sentinel = object()\n        result = max(it, default=sentinel, key=key)\n        return [] if result is sentinel else [result]\n\n    # When n>=size, it's faster to use sorted()\n    try:\n        size = len(iterable)\n    except (TypeError, AttributeError):\n        pass\n    else:\n        if n >= size:\n            return sorted(iterable, key=key, reverse=True)[:n]\n\n    # When key is none, use simpler decoration\n    if key is None:\n        it = iter(iterable)\n        result = [(elem, i) for i, elem in zip(range(0, -n, -1), it)]\n        if not result:\n            return result\n        heapify(result)\n        top = result[0][0]\n        order = -n\n        _heapreplace = heapreplace\n        for elem in it:\n            if top < elem:\n                _heapreplace(result, (elem, order))\n                top, _order = result[0]\n                order -= 1\n        result.sort(reverse=True)\n        return [elem for (elem, order) in result]\n\n    # General case, slowest method\n    it = iter(iterable)\n    result = [(key(elem), i, elem) for i, elem in zip(range(0, -n, -1), it)]\n    if not result:\n        return result\n    heapify(result)\n    top = result[0][0]\n    order = -n\n    _heapreplace = heapreplace\n    for elem in it:\n        k = key(elem)\n        if top < k:\n            _heapreplace(result, (k, order, elem))\n            top, _order, _elem = result[0]\n            order -= 1\n    result.sort(reverse=True)\n    return [elem for (k, order, elem) in result]\n\n# If available, use C implementation\ntry:\n    from _heapq import *\nexcept ImportError:\n    pass\ntry:\n    from _heapq import _heapreplace_max\nexcept ImportError:\n    pass\ntry:\n    from _heapq import _heapify_max\nexcept ImportError:\n    pass\ntry:\n    from _heapq import _heappop_max\nexcept ImportError:\n    pass\n\n\nif __name__ == \"__main__\":\n\n    import doctest # pragma: no cover\n    print(doctest.testmod()) # pragma: no cover\n", 601]}, "functions": {"splitdrive (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:124)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py", 124], "normpath (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:450)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py", 450], "normcase (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:44)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py", 44], "_get_bothseps (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:34)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py", 34], "isabs (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:61)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py", 61], "realpath (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:625)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py", 625], "split (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:180)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py", 180], "dirname (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:221)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py", 221], "join (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py:77)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\ntpath.py", 77], "getpreferredencoding (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_bootlocale.py:11)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_bootlocale.py", 11], "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\codecs.py:260)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\codecs.py", 260], "decode (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\encodings\\cp1252.py:22)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\encodings\\cp1252.py", 22], "readInData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:44)": ["C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py", 44], "isstring (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:595)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py", 595], "__next (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:233)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 233], "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:224)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 224], "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:76)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 76], "tell (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:286)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 286], "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:111)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 111], "get (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:254)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 254], "match (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:249)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 249], "_class_escape (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:295)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 295], "_uniq (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:432)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 432], "append (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:172)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 172], "__len__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:160)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 160], "__getitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:164)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 164], "__setitem__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:168)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 168], "_parse (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:493)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 493], "_parse_sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:435)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 435], "fix_flags (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:921)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 921], "parse (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:937)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 937], "getwidth (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:174)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 174], "_get_iscased (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:453)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py", 453], "_get_literal_prefix (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:461)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py", 461], "_get_charset_prefix (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:492)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py", 492], "_compile_info (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:536)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py", 536], "_simple (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:423)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py", 423], "_optimize_charset (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:276)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py", 276], "_compile_charset (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:249)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py", 249], "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:71)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py", 71], "_code (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:598)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py", 598], "groups (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py:81)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_parse.py", 81], "compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py:759)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\sre_compile.py", 759], "__new__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:670)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py", 670], "__call__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:358)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py", 358], "__and__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py:977)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\enum.py", 977], "_compile (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:289)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py", 289], "sub (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py:203)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\re.py", 203], "cleanAndTokenize (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:61)": ["C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py", 61], "__subclasshook__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py:409)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\_collections_abc.py", 409], "__subclasscheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:121)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py", 121], "__instancecheck__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py:117)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\abc.py", 117], "update (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:649)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py", 649], "__init__ (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:581)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py", 581], "getWordCount (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:78)": ["C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py", 78], "getWordFrequencies (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:96)": ["C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py", 96], "getWordData (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:122)": ["C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py", 122], "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:563)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py", 563], "<listcomp> (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:577)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py", 577], "nlargest (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py:521)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\heapq.py", 521], "most_common (C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py:600)": ["C:\\Users\\Matt\\anaconda3\\envs\\CS337-Operating-Systems\\lib\\collections\\__init__.py", 600], "<listcomp> (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:175)": ["C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py", 175], "printTopNWords (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:156)": ["C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py", 156], "printWordFrequencyOverYears (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:183)": ["C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py", 183], "runWordCounter (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:214)": ["C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py", 214], "main (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:255)": ["C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py", 255], "<module> (C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py:1)": ["C:\\Users\\Matt\\PycharmProjects\\CS337-Operating-Systems\\Projects\\Proj5\\serial_code_4.py", 1]}}}